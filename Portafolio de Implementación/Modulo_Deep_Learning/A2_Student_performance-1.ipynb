{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Statement\n",
    "You are a data scientist working for a school\n",
    "\n",
    "You are asked to predict the GPA of the current students based on the following provided data: \n",
    "\n",
    " 0   StudentID  int64  \n",
    " 1   Age    int64  \n",
    " 2   Gender int64  \n",
    " 3   Ethnicity  int64  \n",
    " 4   ParentalEducation  int64  \n",
    " 5   StudyTimeWeekly    float64\n",
    " 6   Absences   int64  \n",
    " 7   Tutoring   int64  \n",
    " 8   ParentalSupport    int64  \n",
    " 9   Extracurricular    int64  \n",
    " 10  Sports int64  \n",
    " 11  Music  int64  \n",
    " 12  Volunteering   int64  \n",
    " 13  GPA    float64\n",
    " 14  GradeClass float64\n",
    "\n",
    "The GPA is the Grade Point Average, typically ranges from 0.0 to 4.0 in most educational systems, with 4.0 representing an 'A' or excellent performance.\n",
    "\n",
    "The minimum passing GPA can vary by institution, but it's often around 2.0. This usually corresponds to a 'C' grade, which is considered satisfactory.\n",
    "\n",
    "You need to create a Deep Learning model capable to predict the GPA of a Student based on a set of provided features.\n",
    "The data provided represents 2,392 students.\n",
    "\n",
    "In this excersice you will be requested to create a total of three models and select the most performant one.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Import Libraries\n",
    "\n",
    "First let's import the following libraries, if there is any library that you need and is not in the list bellow feel free to include it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Load Data\n",
    "\n",
    "- You will be provided with a cvs (comma separated value) file.\n",
    "- You will need to add that file into a pandas dataframe, you can use the following code as reference\n",
    "- The file will be available in canvas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StudentID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>ParentalEducation</th>\n",
       "      <th>StudyTimeWeekly</th>\n",
       "      <th>Absences</th>\n",
       "      <th>Tutoring</th>\n",
       "      <th>ParentalSupport</th>\n",
       "      <th>Extracurricular</th>\n",
       "      <th>Sports</th>\n",
       "      <th>Music</th>\n",
       "      <th>Volunteering</th>\n",
       "      <th>GPA</th>\n",
       "      <th>GradeClass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>19.833723</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.929196</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1002</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15.408756</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.042915</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1003</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4.210570</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.112602</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1004</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>10.028829</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.054218</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1005</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4.672495</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.288061</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2387</th>\n",
       "      <td>3388</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>10.680555</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.455509</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2388</th>\n",
       "      <td>3389</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.583217</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.279150</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2389</th>\n",
       "      <td>3390</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6.805500</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.142333</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2390</th>\n",
       "      <td>3391</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12.416653</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.803297</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2391</th>\n",
       "      <td>3392</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>17.819907</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.140014</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2392 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      StudentID  Age  Gender  Ethnicity  ParentalEducation  StudyTimeWeekly  \\\n",
       "0          1001   17       1          0                  2        19.833723   \n",
       "1          1002   18       0          0                  1        15.408756   \n",
       "2          1003   15       0          2                  3         4.210570   \n",
       "3          1004   17       1          0                  3        10.028829   \n",
       "4          1005   17       1          0                  2         4.672495   \n",
       "...         ...  ...     ...        ...                ...              ...   \n",
       "2387       3388   18       1          0                  3        10.680555   \n",
       "2388       3389   17       0          0                  1         7.583217   \n",
       "2389       3390   16       1          0                  2         6.805500   \n",
       "2390       3391   16       1          1                  0        12.416653   \n",
       "2391       3392   16       1          0                  2        17.819907   \n",
       "\n",
       "      Absences  Tutoring  ParentalSupport  Extracurricular  Sports  Music  \\\n",
       "0            7         1                2                0       0      1   \n",
       "1            0         0                1                0       0      0   \n",
       "2           26         0                2                0       0      0   \n",
       "3           14         0                3                1       0      0   \n",
       "4           17         1                3                0       0      0   \n",
       "...        ...       ...              ...              ...     ...    ...   \n",
       "2387         2         0                4                1       0      0   \n",
       "2388         4         1                4                0       1      0   \n",
       "2389        20         0                2                0       0      0   \n",
       "2390        17         0                2                0       1      1   \n",
       "2391        13         0                2                0       0      0   \n",
       "\n",
       "      Volunteering       GPA  GradeClass  \n",
       "0                0  2.929196         2.0  \n",
       "1                0  3.042915         1.0  \n",
       "2                0  0.112602         4.0  \n",
       "3                0  2.054218         3.0  \n",
       "4                0  1.288061         4.0  \n",
       "...            ...       ...         ...  \n",
       "2387             0  3.455509         0.0  \n",
       "2388             0  3.279150         4.0  \n",
       "2389             1  1.142333         2.0  \n",
       "2390             0  1.803297         1.0  \n",
       "2391             1  2.140014         1.0  \n",
       "\n",
       "[2392 rows x 15 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('C:\\\\Users\\\\adria\\\\Downloads\\\\Student_performance_data.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Review you data:\n",
    "\n",
    "Make sure you review your data.\n",
    "Place special attention of null or empty values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2392 entries, 0 to 2391\n",
      "Data columns (total 15 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   StudentID          2392 non-null   int64  \n",
      " 1   Age                2392 non-null   int64  \n",
      " 2   Gender             2392 non-null   int64  \n",
      " 3   Ethnicity          2392 non-null   int64  \n",
      " 4   ParentalEducation  2392 non-null   int64  \n",
      " 5   StudyTimeWeekly    2392 non-null   float64\n",
      " 6   Absences           2392 non-null   int64  \n",
      " 7   Tutoring           2392 non-null   int64  \n",
      " 8   ParentalSupport    2392 non-null   int64  \n",
      " 9   Extracurricular    2392 non-null   int64  \n",
      " 10  Sports             2392 non-null   int64  \n",
      " 11  Music              2392 non-null   int64  \n",
      " 12  Volunteering       2392 non-null   int64  \n",
      " 13  GPA                2392 non-null   float64\n",
      " 14  GradeClass         2392 non-null   float64\n",
      "dtypes: float64(3), int64(12)\n",
      "memory usage: 280.4 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Remove the columns not needed for Student performance prediction\n",
    "\n",
    "- Choose only the columns you consider to be valuable for your model training.\n",
    "- For example, StudentID might not be a good feature for your model, and thus should be removed from your main dataset, which other columns should also be removed?\n",
    "- You can name that final dataset as 'dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_remove = ['StudentID', 'GradeClass', 'Volunteering', 'Ethnicity'] # Añade las columnas que no son útiles\n",
    "dataset = data.drop(columns=columns_to_remove)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Check if the columns has any null values:\n",
    "- Here you now have your final dataset to use in your model training.\n",
    "- Before moving foward review your data check for any null or empty value that might be needed to be removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "# Check for null values\n",
    "null_values = dataset.isnull().sum()\n",
    "print(null_values[null_values > 0])  # Print columns with null values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Prepare your data for training and for testing set:\n",
    " - First create a dataset named X, with all columns but GPA. These are the features\n",
    " - Next create another dataset named y, with only GPA column. This is the label\n",
    " - If you go to your Imports, you will see the following import: **'from sklearn.model_selection import train_test_split'**\n",
    " - Use that *train_test_split* function to create: X_train, X_test, y_train and y_test respectively. Use X and y datasets as parameters. Other parameters to use are: Test Size = 0.2, Random State = 42.\n",
    " \n",
    " - Standarize your features (X_train and X_test) by using the StandardScaler (investigate how to use fit_transform and transform functions). This will help the training process by dealing with normilized data.\n",
    "\n",
    " Note: Your X_train shape should be around (1913, 10). This means the dataset has 10 columns which should be the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1913, 10)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Step 1: Create X and y\n",
    "X = dataset.drop(columns=['GPA'])  # All features except GPA\n",
    "y = dataset['GPA']                   # Label is GPA\n",
    "\n",
    "# Step 2: Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 3: Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Check the shape of X_train\n",
    "print(X_train.shape)  # Should be around (1913, 10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Define your Deep Neural Network.\n",
    "- This will be a Sequential Neural Network.\n",
    "- With a Dense input layer with 64 units, and input dimention of 10 and Relu as the activation function.\n",
    "- A Dense hidden layer with 32 units, and Relu as the activation function.\n",
    "- And a Dense output layer with 1 unit, do not define an activation function so it defaults to linear, suitable for regression tasks. e.g. Dense(1)\n",
    "\n",
    "This last part of the output layer is super important, since we want to predict the GPA, this means that we want a regression and not a classification. Linear activation function is best for regression and Sigmoid is best for Binary Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\adria\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">704</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m704\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,817</span> (11.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,817\u001b[0m (11.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,817</span> (11.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,817\u001b[0m (11.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the model\n",
    "model = Sequential()\n",
    "\n",
    "# Input layer\n",
    "model.add(Dense(64, input_dim=10, activation='relu'))\n",
    "\n",
    "# Hidden layer\n",
    "model.add(Dense(32, activation='relu'))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(1))  # Linear activation is default, suitable for regressionS\n",
    "\n",
    "# Summary of the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Compile your Neural Network\n",
    "- Choose Adam as the optimizer\n",
    "- And MSE as the Loss function\n",
    "- Also add the following metrics: Mean Absolute Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', \n",
    "              loss='mean_squared_error', \n",
    "              metrics=['mae'])  # Mean Absolute Error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Fit (or train) your model\n",
    "- Use the X_train and y_train datasets for the training\n",
    "- Do 50 data iterations\n",
    "- Choose the batch size = 10\n",
    "- Also select a validation_split of 0.2\n",
    "- Save the result of the fit function in a variable called 'history'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1913, 10)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.0854 - mae: 0.7949 - val_loss: 0.0922 - val_mae: 0.2514\n",
      "Epoch 2/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 852us/step - loss: 0.0806 - mae: 0.2240 - val_loss: 0.0671 - val_mae: 0.2133\n",
      "Epoch 3/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0557 - mae: 0.1856 - val_loss: 0.0575 - val_mae: 0.2000\n",
      "Epoch 4/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 909us/step - loss: 0.0506 - mae: 0.1802 - val_loss: 0.0532 - val_mae: 0.1886\n",
      "Epoch 5/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 886us/step - loss: 0.0442 - mae: 0.1671 - val_loss: 0.0506 - val_mae: 0.1838\n",
      "Epoch 6/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 820us/step - loss: 0.0422 - mae: 0.1630 - val_loss: 0.0574 - val_mae: 0.1947\n",
      "Epoch 7/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 972us/step - loss: 0.0403 - mae: 0.1579 - val_loss: 0.0507 - val_mae: 0.1807\n",
      "Epoch 8/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0392 - mae: 0.1576 - val_loss: 0.0504 - val_mae: 0.1831\n",
      "Epoch 9/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0363 - mae: 0.1518 - val_loss: 0.0492 - val_mae: 0.1800\n",
      "Epoch 10/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 898us/step - loss: 0.0366 - mae: 0.1512 - val_loss: 0.0473 - val_mae: 0.1773\n",
      "Epoch 11/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 850us/step - loss: 0.0338 - mae: 0.1472 - val_loss: 0.0498 - val_mae: 0.1780\n",
      "Epoch 12/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 846us/step - loss: 0.0324 - mae: 0.1439 - val_loss: 0.0499 - val_mae: 0.1760\n",
      "Epoch 13/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 821us/step - loss: 0.0324 - mae: 0.1437 - val_loss: 0.0513 - val_mae: 0.1811\n",
      "Epoch 14/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 832us/step - loss: 0.0322 - mae: 0.1434 - val_loss: 0.0485 - val_mae: 0.1769\n",
      "Epoch 15/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 879us/step - loss: 0.0341 - mae: 0.1477 - val_loss: 0.0519 - val_mae: 0.1821\n",
      "Epoch 16/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 907us/step - loss: 0.0321 - mae: 0.1417 - val_loss: 0.0542 - val_mae: 0.1828\n",
      "Epoch 17/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 880us/step - loss: 0.0307 - mae: 0.1385 - val_loss: 0.0544 - val_mae: 0.1876\n",
      "Epoch 18/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 850us/step - loss: 0.0313 - mae: 0.1410 - val_loss: 0.0602 - val_mae: 0.1988\n",
      "Epoch 19/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 849us/step - loss: 0.0281 - mae: 0.1335 - val_loss: 0.0541 - val_mae: 0.1903\n",
      "Epoch 20/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 821us/step - loss: 0.0304 - mae: 0.1383 - val_loss: 0.0528 - val_mae: 0.1859\n",
      "Epoch 21/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 840us/step - loss: 0.0306 - mae: 0.1388 - val_loss: 0.0547 - val_mae: 0.1862\n",
      "Epoch 22/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 919us/step - loss: 0.0290 - mae: 0.1341 - val_loss: 0.0515 - val_mae: 0.1827\n",
      "Epoch 23/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 830us/step - loss: 0.0270 - mae: 0.1316 - val_loss: 0.0578 - val_mae: 0.1939\n",
      "Epoch 24/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0310 - mae: 0.1391 - val_loss: 0.0579 - val_mae: 0.1915\n",
      "Epoch 25/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 862us/step - loss: 0.0303 - mae: 0.1381 - val_loss: 0.0538 - val_mae: 0.1863\n",
      "Epoch 26/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 854us/step - loss: 0.0266 - mae: 0.1301 - val_loss: 0.0535 - val_mae: 0.1853\n",
      "Epoch 27/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 894us/step - loss: 0.0254 - mae: 0.1251 - val_loss: 0.0544 - val_mae: 0.1885\n",
      "Epoch 28/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 824us/step - loss: 0.0250 - mae: 0.1255 - val_loss: 0.0534 - val_mae: 0.1856\n",
      "Epoch 29/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 851us/step - loss: 0.0252 - mae: 0.1255 - val_loss: 0.0550 - val_mae: 0.1878\n",
      "Epoch 30/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 830us/step - loss: 0.0252 - mae: 0.1246 - val_loss: 0.0563 - val_mae: 0.1859\n",
      "Epoch 31/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 893us/step - loss: 0.0251 - mae: 0.1253 - val_loss: 0.0540 - val_mae: 0.1887\n",
      "Epoch 32/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 838us/step - loss: 0.0245 - mae: 0.1239 - val_loss: 0.0542 - val_mae: 0.1901\n",
      "Epoch 33/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 888us/step - loss: 0.0259 - mae: 0.1291 - val_loss: 0.0595 - val_mae: 0.1943\n",
      "Epoch 34/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 877us/step - loss: 0.0237 - mae: 0.1212 - val_loss: 0.0540 - val_mae: 0.1903\n",
      "Epoch 35/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 875us/step - loss: 0.0245 - mae: 0.1241 - val_loss: 0.0528 - val_mae: 0.1847\n",
      "Epoch 36/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 876us/step - loss: 0.0237 - mae: 0.1229 - val_loss: 0.0547 - val_mae: 0.1887\n",
      "Epoch 37/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 939us/step - loss: 0.0232 - mae: 0.1196 - val_loss: 0.0544 - val_mae: 0.1871\n",
      "Epoch 38/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 884us/step - loss: 0.0243 - mae: 0.1248 - val_loss: 0.0565 - val_mae: 0.1892\n",
      "Epoch 39/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 875us/step - loss: 0.0222 - mae: 0.1186 - val_loss: 0.0552 - val_mae: 0.1875\n",
      "Epoch 40/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 825us/step - loss: 0.0226 - mae: 0.1170 - val_loss: 0.0576 - val_mae: 0.1915\n",
      "Epoch 41/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 877us/step - loss: 0.0239 - mae: 0.1239 - val_loss: 0.0563 - val_mae: 0.1907\n",
      "Epoch 42/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 928us/step - loss: 0.0216 - mae: 0.1158 - val_loss: 0.0614 - val_mae: 0.1962\n",
      "Epoch 43/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 834us/step - loss: 0.0231 - mae: 0.1219 - val_loss: 0.0575 - val_mae: 0.1953\n",
      "Epoch 44/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 889us/step - loss: 0.0229 - mae: 0.1190 - val_loss: 0.0590 - val_mae: 0.1944\n",
      "Epoch 45/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0215 - mae: 0.1166 - val_loss: 0.0603 - val_mae: 0.1963\n",
      "Epoch 46/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 868us/step - loss: 0.0241 - mae: 0.1235 - val_loss: 0.0585 - val_mae: 0.1941\n",
      "Epoch 47/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 862us/step - loss: 0.0212 - mae: 0.1145 - val_loss: 0.0577 - val_mae: 0.1915\n",
      "Epoch 48/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 841us/step - loss: 0.0208 - mae: 0.1141 - val_loss: 0.0641 - val_mae: 0.2027\n",
      "Epoch 49/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step - loss: 0.0212 - mae: 0.1146 - val_loss: 0.0609 - val_mae: 0.1961\n",
      "Epoch 50/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 819us/step - loss: 0.0219 - mae: 0.1171 - val_loss: 0.0607 - val_mae: 0.1980\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "history = model.fit(X_train, y_train, \n",
    "                    epochs=50, \n",
    "                    batch_size=10, \n",
    "                    validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. View your history variable:\n",
    "- Use Matplotlib.pyplot to show graphs of your model traning history\n",
    "- In one graph:\n",
    "   - Plot the Training Loss and the Validation Loss\n",
    "   - X Label = Epochs\n",
    "   - Y Label = Loss\n",
    "   - Title = Training and Validation Loss over Epochs\n",
    "- In a second graph:\n",
    "   - Plot the Training MAE and the Validation MAE\n",
    "   - X Label = Epochs\n",
    "   - Y Label = Mean Absolute Error (MAE)\n",
    "   - Title = Training and Validation MAE over Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA/IAAAIjCAYAAACgdyAGAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAColElEQVR4nOzdd3xT5eLH8W/SXTooqy1YKJS9lSUqAlopoCiuCwiyFO91XkVE+XllieK6igKKl8tSWaLIVVEUEFSUoSxBhuzdMrvpSvL74zSB0BZampImfN6v13k1OXnOyXPaUPo9zzLZbDabAAAAAACARzC7uwIAAAAAAKD4CPIAAAAAAHgQgjwAAAAAAB6EIA8AAAAAgAchyAMAAAAA4EEI8gAAAAAAeBCCPAAAAAAAHoQgDwAAAACAByHIAwAAAADgQQjyAIBCDRw4ULGxsZd17OjRo2UymVxboXJm//79MplMmjlz5hV/b5PJpNGjRzuez5w5UyaTSfv377/ksbGxsRo4cKBL61OazwpQXPbP+e+//+7uqgCA2xHkAcDDmEymYm0rV650d1Wvek899ZRMJpN2795dZJkXX3xRJpNJf/zxxxWsWckdPXpUo0eP1qZNm9xdFQf7zRSTyaRx48YVWqZv374ymUwKCQkp8jxt27aVyWTSBx98UOjr9gBZ1LZmzRqXXI+7XS3XCQDewNfdFQAAlMzHH3/s9Pyjjz7S0qVLC+xv1KhRqd5n6tSpslqtl3Xsv/71L73wwgulen9v0LdvX02cOFFz5szRyJEjCy0zd+5cNWvWTM2bN7/s93nwwQfVu3dvBQQEXPY5LuXo0aMaM2aMYmNj1bJlS6fXSvNZcYXAwEDNnTtX//rXv5z2Z2Rk6H//+58CAwOLPHbXrl367bffFBsbq9mzZ+vRRx8tsuzYsWNVu3btAvvr1q17+ZUvh66W6wQAT0aQBwAP069fP6fna9as0dKlSwvsv1BmZqaCg4OL/T5+fn6XVT9J8vX1la8v/8W0a9dOdevW1dy5cwsN8qtXr9a+ffv02muvlep9fHx85OPjU6pzlEZpPiuu0L17dy1cuFCbN29WixYtHPv/97//KScnR127dtUPP/xQ6LGffPKJqlWrpn//+9+67777tH///iKHCXTr1k2tW7cui0u4YjIyMlShQoWLlvGG6wQAb0fXegDwQp06dVLTpk21fv163XzzzQoODtb//d//STLCze23367q1asrICBAcXFxevnll2WxWJzOceG4Z3s35rfeekv/+c9/FBcXp4CAALVp00a//fab07GFjZE3mUx64okntGjRIjVt2lQBAQFq0qSJlixZUqD+K1euVOvWrRUYGKi4uDh9+OGHxR53//PPP+v+++9XzZo1FRAQoJiYGD3zzDM6e/ZsgesLCQnRkSNH1LNnT4WEhKhq1aoaNmxYge9FcnKyBg4cqPDwcFWsWFEDBgxQcnLyJesiGa3yO3bs0IYNGwq8NmfOHJlMJvXp00c5OTkaOXKkWrVqpfDwcFWoUEEdOnTQihUrLvkehY2Rt9lsGjdunK655hoFBwerc+fO+vPPPwsce/r0aQ0bNkzNmjVTSEiIwsLC1K1bN23evNlRZuXKlWrTpo0kadCgQY6u1vb5AQobI5+RkaFnn31WMTExCggIUIMGDfTWW2/JZrM5lSvJ56Io7du3V+3atTVnzhyn/bNnz1bXrl1VqVKlIo+dM2eO7rvvPt1xxx0KDw8vcA5Xef/999WkSRMFBASoevXqevzxx50+Q0888YRCQkKUmZlZ4Ng+ffooKirK6XP57bffqkOHDqpQoYJCQ0N1++23F/j52j/je/bsUffu3RUaGqq+ffuW+lrO/13wzjvvqFatWgoKClLHjh21devWAuV/+OEHR10rVqyou+66S9u3by9Q7siRI3rooYccv5tq166tRx99VDk5OU7lsrOzNXToUFWtWlUVKlTQ3XffrRMnTjiV+f3335WQkKAqVaooKChItWvX1uDBg0t97QBQXtBcAgBe6tSpU+rWrZt69+6tfv36KTIyUpIR+kJCQjR06FCFhITohx9+0MiRI5Wamqo333zzkuedM2eO0tLS9Pe//10mk0lvvPGG7rnnHu3du/eSLbOrVq3SwoUL9dhjjyk0NFTvvfee7r33Xh08eFCVK1eWJG3cuFFdu3ZVdHS0xowZI4vForFjx6pq1arFuu4FCxYoMzNTjz76qCpXrqx169Zp4sSJOnz4sBYsWOBU1mKxKCEhQe3atdNbb72lZcuW6d///rfi4uIcXaxtNpvuuusurVq1Sv/4xz/UqFEjffHFFxowYECx6tO3b1+NGTNGc+bM0XXXXef03p9++qk6dOigmjVr6uTJk/rvf/+rPn36aMiQIUpLS9O0adOUkJCgdevWFejOfikjR47UuHHj1L17d3Xv3l0bNmxQly5dCoSivXv3atGiRbr//vtVu3ZtJSUl6cMPP1THjh21bds2Va9eXY0aNdLYsWM1cuRIPfLII+rQoYMk6YYbbij0vW02m+68806tWLFCDz30kFq2bKnvvvtOzz33nI4cOaJ33nnHqXxxPheX0qdPH33yySd67bXXZDKZdPLkSX3//ff6+OOPi7wpsHbtWu3evVszZsyQv7+/7rnnHs2ePdtx0+tCKSkpOnnypNM+k8l0yTqOHj1aY8aMUXx8vB599FHt3LlTH3zwgX777Tf98ssv8vPzU69evTR58mQtXrxY999/v+PYzMxMffXVVxo4cKCj18XHH3+sAQMGKCEhQa+//royMzP1wQcf6KabbtLGjRudbqrk5eUpISFBN910k956661i9cop7nV+9NFHSktL0+OPP66srCy9++67uuWWW7RlyxbH75tly5apW7duqlOnjkaPHq2zZ89q4sSJuvHGG7VhwwZHXY8ePaq2bdsqOTlZjzzyiBo2bKgjR47os88+U2Zmpvz9/R3v++STTyoiIkKjRo3S/v37NWHCBD3xxBOaP3++JOn48ePq0qWLqlatqhdeeEEVK1bU/v37tXDhwkteOwB4DBsAwKM9/vjjtgt/nXfs2NEmyTZlypQC5TMzMwvs+/vf/24LDg62ZWVlOfYNGDDAVqtWLcfzffv22STZKleubDt9+rRj///+9z+bJNtXX33l2Ddq1KgCdZJk8/f3t+3evduxb/PmzTZJtokTJzr29ejRwxYcHGw7cuSIY9+uXbtsvr6+Bc5ZmMKub/z48TaTyWQ7cOCA0/VJso0dO9ap7LXXXmtr1aqV4/miRYtskmxvvPGGY19eXp6tQ4cONkm2GTNmXLJObdq0sV1zzTU2i8Xi2LdkyRKbJNuHH37oOGd2drbTcWfOnLFFRkbaBg8e7LRfkm3UqFGO5zNmzLBJsu3bt89ms9lsx48ft/n7+9tuv/12m9VqdZT7v//7P5sk24ABAxz7srKynOplsxk/64CAAKfvzW+//Vbk9V74WbF/z8aNG+dU7r777rOZTCanz0BxPxeFsX8m33zzTdvWrVttkmw///yzzWaz2SZPnmwLCQmxZWRk2AYMGGCrUKFCgeOfeOIJW0xMjON79P3339sk2TZu3OhUzv79LWwLCAi4aB3tP4suXbo4fZ8nTZpkk2SbPn26zWaz2axWq61GjRq2e++91+n4Tz/91CbJ9tNPP9lsNpstLS3NVrFiRduQIUOcyiUmJtrCw8Od9ts/4y+88MJF61jS67R/34OCgmyHDx927F+7dq1Nku2ZZ55x7GvZsqWtWrVqtlOnTjn2bd682WY2m239+/d37Ovfv7/NbDbbfvvttwL1sv987PWLj493+lw/88wzNh8fH1tycrLNZrPZvvjiC5ukQs8FAN6CrvUA4KUCAgI0aNCgAvuDgoIcj9PS0nTy5El16NBBmZmZ2rFjxyXP26tXL0VERDie21tn9+7de8lj4+PjFRcX53jevHlzhYWFOY61WCxatmyZevbsqerVqzvK1a1bV926dbvk+SXn68vIyNDJkyd1ww03yGazaePGjQXK/+Mf/3B63qFDB6dr+eabb+Tr6+s0CZqPj4+efPLJYtVHMuY1OHz4sH766SfHvjlz5sjf39/R+urj4+NodbRarTp9+rTy8vLUunXrQrvlX8yyZcuUk5OjJ5980mk4wtNPP12gbEBAgMxm488Bi8WiU6dOKSQkRA0aNCjx+9p988038vHx0VNPPeW0/9lnn5XNZtO3337rtP9Sn4viaNKkiZo3b665c+dKMr6/d911V5Et0Hl5eZo/f7569erl+B7dcsstqlatmmbPnl3oMZMnT9bSpUudtguv5UL2n8XTTz/t+D5L0pAhQxQWFqbFixdLMlq877//fn3zzTdKT093lJs/f75q1Kihm266SZK0dOlSJScnq0+fPjp58qRj8/HxUbt27QodinGxCfxKc509e/ZUjRo1HM/btm2rdu3a6ZtvvpEkHTt2TJs2bdLAgQOdhjc0b95ct912m6Oc1WrVokWL1KNHj0LH5l84pOaRRx5x2tehQwdZLBYdOHBAklSxYkVJ0tdff63c3NwSXTsAeAqCPAB4qRo1ajh1R7X7888/dffddys8PFxhYWGqWrWqY6K8lJSUS563Zs2aTs/tof7MmTMlPtZ+vP3Y48eP6+zZs4XOjl3cGbMPHjzoCA72ce8dO3aUVPD6AgMDC3TZP78+knTgwAFFR0cXWL6sQYMGxaqPJPXu3Vs+Pj6O8ddZWVn64osv1K1bN6ebIrNmzVLz5s0VGBioypUrq2rVqlq8eHGxfi7nsweaevXqOe2vWrWq0/tJRoh65513VK9ePQUEBKhKlSqqWrWq/vjjjxK/7/nvX716dYWGhjrtt6+kYK+f3aU+F8X1wAMPaMGCBdq9e7d+/fVXPfDAA0WW/f7773XixAm1bdtWu3fv1u7du7Vv3z517txZc+fOLXQW/rZt2yo+Pt5p69y580XrZL/WCz8v/v7+qlOnjtP3olevXjp79qy+/PJLSVJ6erq++eYb3X///Y7gumvXLknGTYeqVas6bd9//72OHz/u9D6+vr665pprLlrHy73OCz9fklS/fn3HXA1FXbtkfBZOnjypjIwMnThxQqmpqWratGmx6nep30EdO3bUvffeqzFjxqhKlSq66667NGPGDGVnZxfr/ADgCRgjDwBe6vyWabvk5GR17NhRYWFhGjt2rOLi4hQYGKgNGzbo+eefL9YSYkXNjm67YBIzVx9bHBaLRbfddptOnz6t559/Xg0bNlSFChV05MgRDRw4sMD1XamZ3qtVq6bbbrtNn3/+uSZPnqyvvvpKaWlpThOPffLJJxo4cKB69uyp5557TtWqVZOPj4/Gjx+vPXv2lFndXn31Vb300ksaPHiwXn75ZVWqVElms1lPP/30FVtSzlWfiz59+mjEiBEaMmSIKleurC5duhRZ1t7q/re//a3Q13/88cdLhnRXu/766xUbG6tPP/1UDzzwgL766iudPXtWvXr1cpSx/0w+/vhjRUVFFTjHhatFnN/jwltc6vNiMpn02Wefac2aNfrqq6/03XffafDgwfr3v/+tNWvWFLgpBwCeiCAPAFeRlStX6tSpU1q4cKFuvvlmx/59+/a5sVbnVKtWTYGBgdq9e3eB1wrbd6EtW7bor7/+0qxZs9S/f3/H/qVLl152nWrVqqXly5crPT3dKQDs3LmzROfp27evlixZom+//VZz5sxRWFiYevTo4Xj9s88+U506dbRw4UKnbsOjRo26rDpLRuttnTp1HPtPnDhRoJX7s88+U+fOnTVt2jSn/cnJyapSpYrjeXFWDDj//ZctW6a0tDSnVnn70A17/VytZs2auvHGG7Vy5Uo9+uijRS6BaF9fvlevXrrvvvsKvP7UU09p9uzZLgny9mvduXOn088iJydH+/btU3x8vFP5v/3tb3r33XeVmpqq+fPnKzY2Vtdff73jdfsQhGrVqhU49kqz9w44319//eWYwO78a7/Qjh07VKVKFVWoUEFBQUEKCwsrdMb70rj++ut1/fXX65VXXtGcOXPUt29fzZs3Tw8//LBL3wcA3MG7btECAC7K3pJ1fktnTk6O3n//fXdVyYmPj4/i4+O1aNEiHT161LF/9+7dlxyLbD9ecr4+m82md99997Lr1L17d+Xl5emDDz5w7LNYLJo4cWKJztOzZ08FBwfr/fff17fffqt77rlHgYGBF6372rVrtXr16hLXOT4+Xn5+fpo4caLT+SZMmFCgrI+PT4GW7wULFujIkSNO++xrjxdn2b3u3bvLYrFo0qRJTvvfeecdmUymYs93cDnGjRunUaNGXXQOgy+++EIZGRl6/PHHdd999xXY7rjjDn3++ecu6YodHx8vf39/vffee07f52nTpiklJUW33367U/levXopOztbs2bN0pIlSwr0GEhISFBYWJheffXVQsd/X7gMW1latGiR0+dk3bp1Wrt2rePnGx0drZYtW2rWrFlOn5utW7fq+++/V/fu3SVJZrNZPXv21FdffaXff/+9wPuUtGfGmTNnChxjX/WB7vUAvAUt8gBwFbnhhhsUERGhAQMG6KmnnpLJZNLHH3/ssq7trjB69Gh9//33uvHGG/Xoo486AmHTpk21adOmix7bsGFDxcXFadiwYTpy5IjCwsL0+eefl3is9fl69OihG2+8US+88IL279+vxo0ba+HChSUePx4SEqKePXs6xslfuJ73HXfcoYULF+ruu+/W7bffrn379mnKlClq3Lix0+RnxVG1alUNGzZM48eP1x133KHu3btr48aN+vbbb51a2e3vO3bsWA0aNEg33HCDtmzZotmzZzu1HktGS3DFihU1ZcoUhYaGqkKFCmrXrp1q165d4P179Oihzp0768UXX9T+/fvVokULff/99/rf//6np59+2mliO1fr2LGjY06EosyePVuVK1cucvm8O++8U1OnTtXixYt1zz33OPZ/++23hU4IecMNNxT4ftlVrVpVI0aM0JgxY9S1a1fdeeed2rlzp95//321adPGMT+F3XXXXae6devqxRdfVHZ2tlO3ekkKCwvTBx98oAcffFDXXXedevfurapVq+rgwYNavHixbrzxxgI3UEqquNdZt25d3XTTTXr00UeVnZ2tCRMmqHLlyho+fLijzJtvvqlu3bqpffv2euihhxzLz4WHh2v06NGOcq+++qq+//57dezYUY888ogaNWqkY8eOacGCBVq1apVjArvimDVrlt5//33dfffdiouLU1pamqZOnaqwsDDHzQMA8HQEeQC4ilSuXFlff/21nn32Wf3rX/9SRESE+vXrp1tvvVUJCQnurp4kqVWrVvr22281bNgwvfTSS4qJidHYsWO1ffv2S86q7+fnp6+++kpPPfWUxo8fr8DAQN1999164okn1KJFi8uqj9ls1pdffqmnn35an3zyiUwmk+688079+9//1rXXXluic/Xt21dz5sxRdHS0brnlFqfXBg4cqMTERH344Yf67rvv1LhxY33yySdasGCBVq5cWeJ6jxs3ToGBgZoyZYpWrFihdu3a6fvvvy/QAvx///d/ysjI0Jw5czR//nxdd911Wrx4sV544QWncn5+fpo1a5ZGjBihf/zjH8rLy9OMGTMKDfL279nIkSM1f/58zZgxQ7GxsXrzzTf17LPPlvhaXOn48eNatmyZ+vTpU+RY61tvvVXBwcH65JNPnIL8yJEjCy0/Y8aMIoO8ZNycqlq1qiZNmqRnnnlGlSpV0iOPPKJXX31Vfn5+Bcr36tVLr7zyiurWravrrruuwOsPPPCAqlevrtdee01vvvmmsrOzVaNGDXXo0KHQlSpKqrjX2b9/f5nNZk2YMEHHjx9X27ZtNWnSJEVHRzvKxMfHa8mSJRo1apRGjhwpPz8/dezYUa+//rrTZ6dGjRpau3atXnrpJc2ePVupqamqUaOGunXrVuTKA0Xp2LGj1q1bp3nz5ikpKUnh4eFq27atZs+eXejnFQA8kclWnpphAAAoQs+ePfXnn38WOi4XwJWzf/9+1a5dW2+++aaGDRvm7uoAwFWJMfIAgHLn7NmzTs937dqlb775Rp06dXJPhQAAAMoRutYDAMqdOnXqaODAgY51tj/44AP5+/s7jb0FAAC4WhHkAQDlTteuXTV37lwlJiYqICBA7du316uvvqp69eq5u2oAAABuxxh5AAAAAAA8CGPkAQAAAADwIAR5AAAAAAA8CGPkC2G1WnX06FGFhobKZDK5uzoAAAAAAC9ns9mUlpam6tWry2y+eJs7Qb4QR48eVUxMjLurAQAAAAC4yhw6dEjXXHPNRcsQ5AsRGhoqyfgGhoWFubk2AAAAAABvl5qaqpiYGEcevRiCfCHs3enDwsII8gAAAACAK6Y4w7uZ7A4AAAAAAA9CkAcAAAAAwIOUiyA/efJkxcbGKjAwUO3atdO6deuKLDtz5kyZTCanLTAw0KmMzWbTyJEjFR0draCgIMXHx2vXrl1lfRkAAAAAAJQ5t4+Rnz9/voYOHaopU6aoXbt2mjBhghISErRz505Vq1at0GPCwsK0c+dOx/MLxxC88cYbeu+99zRr1izVrl1bL730khISErRt27YCoR8AAAAAzmexWJSbm+vuasDL+Pj4yNfX1yVLnJtsNpvNBXW6bO3atVObNm00adIkScYa7jExMXryySf1wgsvFCg/c+ZMPf3000pOTi70fDabTdWrV9ezzz6rYcOGSZJSUlIUGRmpmTNnqnfv3pesU2pqqsLDw5WSksJkdwAAAMBVJD09XYcPH5abYxK8VHBwsKKjo+Xv71/gtZLkULe2yOfk5Gj9+vUaMWKEY5/ZbFZ8fLxWr15d5HHp6emqVauWrFarrrvuOr366qtq0qSJJGnfvn1KTExUfHy8o3x4eLjatWun1atXFxrks7OzlZ2d7XiemprqissDAAAA4EEsFosOHz6s4OBgVa1a1SUtp4BkNDjn5OToxIkT2rdvn+rVqyez+fJHurs1yJ88eVIWi0WRkZFO+yMjI7Vjx45Cj2nQoIGmT5+u5s2bKyUlRW+99ZZuuOEG/fnnn7rmmmuUmJjoOMeF57S/dqHx48drzJgxLrgiAAAAAJ4qNzdXNptNVatWVVBQkLurAy8TFBQkPz8/HThwQDk5OaUa9l0uJrsrifbt26t///5q2bKlOnbsqIULF6pq1ar68MMPL/ucI0aMUEpKimM7dOiQC2sMAAAAwJPQEo+yUppWeKfzuOQsl6lKlSry8fFRUlKS0/6kpCRFRUUV6xx+fn669tprtXv3bklyHFeScwYEBCgsLMxpAwAAAACgPHJrkPf391erVq20fPlyxz6r1arly5erffv2xTqHxWLRli1bFB0dLUmqXbu2oqKinM6ZmpqqtWvXFvucAAAAAACUV27vWj906FBNnTpVs2bN0vbt2/Xoo48qIyNDgwYNkiT179/faTK8sWPH6vvvv9fevXu1YcMG9evXTwcOHNDDDz8syegG8/TTT2vcuHH68ssvtWXLFvXv31/Vq1dXz5493XGJAAAAAOBRYmNjNWHChGKXX7lypUwmU5Gri8G13B7ke/XqpbfeeksjR45Uy5YttWnTJi1ZssQxWd3Bgwd17NgxR/kzZ85oyJAhatSokbp3767U1FT9+uuvaty4saPM8OHD9eSTT+qRRx5RmzZtlJ6eriVLlrCGPAAAAACvYjKZLrqNHj36ss7722+/6ZFHHil2+RtuuEHHjh1TeHj4Zb1fcdlvGERERCgrK8vptd9++81x3YVp2LChAgICCp0EvVOnToV+//7xj3+UyXWUltvXkS+PWEceAAAAuPpkZWVp3759ql27tsc0Ap4fSufPn6+RI0dq586djn0hISEKCQmRZCyBZrFY5Ovr1sXLSmXlypXq3LmzYmJi9Prrr6tPnz6O1/7xj3/o22+/1cGDB3VhzF21apX69u2rm266Sc2bN9fzzz/v9HqnTp1Uv359jR071ml/cHCwSzPhxT5jJcmhbm+RBwAAAIDyyGazKTMnzy1bcdtbo6KiHFt4eLhMJpPj+Y4dOxQaGqpvv/1WrVq1UkBAgFatWqU9e/borrvuUmRkpEJCQtSmTRstW7bM6bwXdq03mUz673//q7vvvlvBwcGqV6+evvzyS8frF3atnzlzpipWrKjvvvtOjRo1UkhIiLp27erU2zovL09PPfWUKlasqMqVK+v555/XgAEDijUkesCAAZo+fbrj+dmzZzVv3jwNGDCg0PLTpk3TAw88oAcffNDpuPMFBwc7fT+joqLKbcOu596KAQAAAIAydDbXosYjv3PLe28bm6Bgf9fEtRdeeEFvvfWW6tSpo4iICB06dEjdu3fXK6+8ooCAAH300Ufq0aOHdu7cqZo1axZ5njFjxuiNN97Qm2++qYkTJ6pv3746cOCAKlWqVGj5zMxMvfXWW/r4449lNpvVr18/DRs2TLNnz5Ykvf7665o9e7ZmzJihRo0a6d1339WiRYvUuXPnS17Tgw8+qDfffFMHDx5UzZo19fnnnys2NlbXXXddgbJpaWlasGCB1q5dq4YNGyolJUU///yzOnToUMzvYPlDizwAAAAAeLGxY8fqtttuU1xcnCpVqqQWLVro73//u5o2bap69erp5ZdfVlxcnFMLe2EGDhyoPn36qG7dunr11VeVnp6udevWFVk+NzdXU6ZMUevWrXXdddfpiSeecFpdbOLEiRoxYoTuvvtuNWzYUJMmTVLFihWLdU3VqlVTt27dNHPmTEnS9OnTNXjw4ELLzps3T/Xq1VOTJk3k4+Oj3r17a9q0aQXKvf/++46hCPbNftOhvKFF3oOtP3BGiSlZuq5WRUWHB7m7OgAAAIBXCfLz0baxCW57b1dp3bq10/P09HSNHj1aixcv1rFjx5SXl6ezZ8/q4MGDFz1P8+bNHY8rVKigsLAwHT9+vMjywcHBiouLczyPjo52lE9JSVFSUpLatm3reN3Hx0etWrWS1Wot1nUNHjxY//znP9WvXz+tXr1aCxYs0M8//1yg3PTp09WvXz/H8379+qljx46aOHGiQkNDHfv79u2rF1980elY+yTs5Q1B3oO9/u0Ordt/Wu/3vU7RzQjyAAAAgCuZTCaXdW93pwoVKjg9HzZsmJYuXaq33npLdevWVVBQkO677z7l5ORc9Dx+fn5Oz00m00VDd2HlXTnXerdu3fTII4/ooYceUo8ePVS5cuUCZbZt26Y1a9Zo3bp1ThPcWSwWzZs3T0OGDHHsCw8PV926dV1Wv7JE13oPFhpo/FJJy8p1c00AAAAAeIpffvlFAwcO1N13361mzZopKipK+/fvv6J1CA8PV2RkpH777TfHPovFog0bNhT7HL6+vurfv79WrlxZZLf6adOm6eabb9bmzZu1adMmxzZ06NBCu9d7Cs+/vXQVC3EE+Tw31wQAAACAp6hXr54WLlyoHj16yGQy6aWXXip2d3ZXevLJJzV+/HjVrVtXDRs21MSJE3XmzJki14EvzMsvv6znnnuu0Nb43Nxcffzxxxo7dqyaNm3q9NrDDz+st99+W3/++aeaNGkiyZic78I15gMCAhQREXEZV1e2aJH3YKEEeQAAAAAl9PbbbysiIkI33HCDevTooYSEhEJney9rzz//vPr06aP+/furffv2CgkJUUJCQoH11S/G399fVapUKTT8f/nllzp16pTuvvvuAq81atRIjRo1cmqVnzp1qqKjo52289epL09MNlcOUvASqampCg8PV0pKSrldN1CSXvt2h6b8uEcP3VRbL93R2N3VAQAAADxaVlaW9u3bp9q1a5coTMI1rFarGjVqpL/97W96+eWX3V2dMnGxz1hJcihd6z0YY+QBAAAAeKoDBw7o+++/V8eOHZWdna1JkyZp3759euCBB9xdtXKPrvUezB7k07PpWg8AAADAs5jNZs2cOVNt2rTRjTfeqC1btmjZsmVq1KiRu6tW7tEi78EYIw8AAADAU8XExOiXX35xdzU8Ei3yHiwkwFiXkSAPAAAAAFcPgrwHCwlgjDwAAAAAXG0I8h6MMfIAAAAAcPUhyHswxsgDAAAAwNWHIO/BQgONMfKZORZZrDY31wYAAAAAcCUQ5D2YfYy8JKXTKg8AAAAAVwWCvAfz9zUrwNf4EaZlM+EdAAAAgMvTqVMnPf30047nsbGxmjBhwkWPMZlMWrRoUanf21XnuZoQ5D0cE94BAAAAV68ePXqoa9euhb72888/y2Qy6Y8//ijxeX/77Tc98sgjpa2ek9GjR6tly5YF9h87dkzdunVz6XtdaObMmTKZTGrUqFGB1xYsWCCTyaTY2NgCr509e1aVKlVSlSpVlJ2dXeD12NhYmUymAttrr71WFpfhQJD3cPZx8kx4BwAAAFx9HnroIS1dulSHDx8u8NqMGTPUunVrNW/evMTnrVq1qoKDg11RxUuKiopSQEBAmb9PhQoVdPz4ca1evdpp/7Rp01SzZs1Cj/n888/VpEkTNWzYsMheA2PHjtWxY8ectieffNLV1XdCkPdw9nHyjJEHAAAAXMxmk3Iy3LPZijeZ9R133KGqVatq5syZTvvT09O1YMECPfTQQzp16pT69OmjGjVqKDg4WM2aNdPcuXMvet4Lu9bv2rVLN998swIDA9W4cWMtXbq0wDHPP/+86tevr+DgYNWpU0cvvfSScnONIcAzZ87UmDFjtHnzZkertb3OF3at37Jli2655RYFBQWpcuXKeuSRR5Senu54feDAgerZs6feeustRUdHq3Llynr88ccd71UUX19fPfDAA5o+fbpj3+HDh7Vy5Uo98MADhR4zbdo09evXT/369dO0adMKLRMaGqqoqCinrUKFChetS2n5XroIyjN71/rULMbIAwAAAC6Vmym9Wt097/1/RyX/S4dBX19f9e/fXzNnztSLL74ok8kkyegubrFY1KdPH6Wnp6tVq1Z6/vnnFRYWpsWLF+vBBx9UXFyc2rZte8n3sFqtuueeexQZGam1a9cqJSXFaTy9XWhoqGbOnKnq1atry5YtGjJkiEJDQzV8+HD16tVLW7du1ZIlS7Rs2TJJUnh4eIFzZGRkKCEhQe3bt9dvv/2m48eP6+GHH9YTTzzhdLNixYoVio6O1ooVK7R792716tVLLVu21JAhQy56LYMHD1anTp307rvvKjg4WDNnzlTXrl0VGRlZoOyePXu0evVqLVy4UDabTc8884wOHDigWrVqXfJ7VtZokfdwjhZ5xsgDAAAAV6XBgwdrz549+vHHHx37ZsyYoXvvvVfh4eGqUaOGhg0bppYtW6pOnTp68skn1bVrV3366afFOv+yZcu0Y8cOffTRR2rRooVuvvlmvfrqqwXK/etf/9INN9yg2NhY9ejRQ8OGDXO8R1BQkEJCQuTr6+totQ4KCipwjjlz5igrK0sfffSRmjZtqltuuUWTJk3Sxx9/rKSkJEe5iIgITZo0SQ0bNtQdd9yh22+/XcuXL7/ktVx77bWqU6eOPvvsM9lsNs2cOVODBw8utOz06dPVrVs3RUREqFKlSkpISNCMGTMKlHv++ecVEhLitP3888+XrEtp0CLv4RgjDwAAAJQRv2CjZdxd711MDRs21A033KDp06erU6dO2r17t37++WeNHTtWkmSxWPTqq6/q008/1ZEjR5STk6Ps7Oxij4Hfvn27YmJiVL36ud4J7du3L1Bu/vz5eu+997Rnzx6lp6crLy9PYWFhxb4O+3u1aNHCqWv6jTfeKKvVqp07dzpazps0aSIfHx9HmejoaG3ZsqVY7zF48GDNmDFDNWvWVEZGhrp3765JkyY5lbFYLJo1a5beffddx75+/fpp2LBhGjlypMzmc23izz33nAYOHOh0fI0aNYp9zZeDIO/hHLPWE+QBAAAA1zKZitW9vTx46KGH9OSTT2ry5MmaMWOG4uLi1LFjR0nSm2++qXfffVcTJkxQs2bNVKFCBT399NPKyclx2fuvXr1affv21ZgxY5SQkKDw8HDNmzdP//73v132Hufz8/Nzem4ymWS1Wot1bN++fTV8+HCNHj1aDz74oHx9C8bi7777TkeOHFGvXr2c9lssFi1fvly33XabY1+VKlVUt27dy7iKy0fXeg9nD/JpjJEHAAAArlp/+9vfZDabNWfOHH300UcaPHiwY7z8L7/8orvuukv9+vVTixYtVKdOHf3111/FPnejRo106NAhHTt2zLFvzZo1TmV+/fVX1apVSy+++KJat26tevXq6cCBA05l/P39ZbFYLvlemzdvVkZGhmPfL7/8IrPZrAYNGhS7zhdTqVIl3Xnnnfrxxx+L7FY/bdo09e7dW5s2bXLaevfuXeSkd1cSQd7D2cfIpzFGHgAAALhqhYSEqFevXhoxYoSOHTvm1NW7Xr16Wrp0qX799Vdt375df//7353Gm19KfHy86tevrwEDBmjz5s36+eef9eKLLzqVqVevng4ePKh58+Zpz549eu+99/TFF184lYmNjdW+ffu0adMmnTx5stB12fv27avAwEANGDBAW7du1YoVK/Tkk0/qwQcfLHRCuss1c+ZMnTx5Ug0bNizw2okTJ/TVV19pwIABatq0qdPWv39/LVq0SKdPn3aUT0tLU2JiotOWmprqsroWhiDv4RgjDwAAAEAyutefOXNGCQkJTuPZ//Wvf+m6665TQkKCOnXqpKioKPXs2bPY5zWbzfriiy909uxZtW3bVg8//LBeeeUVpzJ33nmnnnnmGT3xxBNq2bKlfv31V7300ktOZe6991517dpVnTt3VtWqVQtdAi84OFjfffedTp8+rTZt2ui+++7TrbfeWmAMe2nZl7YrzEcffaQKFSro1ltvLfDarbfeqqCgIH3yySeOfSNHjlR0dLTTNnz4cJfW90Imm62YCxReRVJTUxUeHq6UlJQST85wpX25+aiemrtR7etU1txHrnd3dQAAAACPlZWVpX379ql27doKDAx0d3XghS72GStJDqVF3sOFOrrWM0YeAAAAAK4GBHkPx6z1AAAAAHB1Ich7uBDHrPUEeQAAAAC4GhDkPZxjsjtmrQcAAACAqwJB3sPZl5/LybMqO+/iazICAAAAuDTmA0dZcdVniyDv4exBXmKcPAAAAFAaPj4+kqScnBw31wTeKjMzU5Lk5+dXqvP4XroIyjMfs0kV/H2UkWNRWlaeKocEuLtKAAAAgEfy9fVVcHCwTpw4IT8/P5nNtHvCNWw2mzIzM3X8+HFVrFjRcdPochHkvUBooJ8ycixKZ5w8AAAAcNlMJpOio6O1b98+HThwwN3VgReqWLGioqKiSn0egrwXCAn0lVKZuR4AAAAoLX9/f9WrV4/u9XA5Pz+/UrfE2xHkvUCoYwm6XDfXBAAAAPB8ZrNZgYGB7q4GUCQGfXgB+4R3dK0HAAAAAO9HkPcCYfa15OlaDwAAAABejyDvBWiRBwAAAICrB0HeC9jHyKcyRh4AAAAAvB5B3guE5Af5dLrWAwAAAIDXKxdBfvLkyYqNjVVgYKDatWundevWFeu4efPmyWQyqWfPnk77Bw4cKJPJ5LR17dq1DGpePoQyRh4AAAAArhpuD/Lz58/X0KFDNWrUKG3YsEEtWrRQQkKCjh8/ftHj9u/fr2HDhqlDhw6Fvt61a1cdO3bMsc2dO7csql8uhDJGHgAAAACuGm4P8m+//baGDBmiQYMGqXHjxpoyZYqCg4M1ffr0Io+xWCzq27evxowZozp16hRaJiAgQFFRUY4tIiKirC7B7UJYRx4AAAAArhpuDfI5OTlav3694uPjHfvMZrPi4+O1evXqIo8bO3asqlWrpoceeqjIMitXrlS1atXUoEEDPfroozp16lSRZbOzs5Wamuq0eZJQR5CnRR4AAAAAvJ1bg/zJkydlsVgUGRnptD8yMlKJiYmFHrNq1SpNmzZNU6dOLfK8Xbt21UcffaTly5fr9ddf148//qhu3brJYrEUWn78+PEKDw93bDExMZd/UW5gX36OIA8AAAAA3s/X3RUoibS0ND344IOaOnWqqlSpUmS53r17Ox43a9ZMzZs3V1xcnFauXKlbb721QPkRI0Zo6NChjuepqakeFebtk90xRh4AAAAAvJ9bg3yVKlXk4+OjpKQkp/1JSUmKiooqUH7Pnj3av3+/evTo4dhntVolSb6+vtq5c6fi4uIKHFenTh1VqVJFu3fvLjTIBwQEKCAgoLSX4zb2rvXp2Xmy2WwymUxurhEAAAAAoKy4tWu9v7+/WrVqpeXLlzv2Wa1WLV++XO3bty9QvmHDhtqyZYs2bdrk2O6880517txZmzZtKrIV/fDhwzp16pSio6PL7FrcyR7kLVabzuYWPnwAAAAAAOAd3N61fujQoRowYIBat26ttm3basKECcrIyNCgQYMkSf3791eNGjU0fvx4BQYGqmnTpk7HV6xYUZIc+9PT0zVmzBjde++9ioqK0p49ezR8+HDVrVtXCQkJV/TarpQgPx/5mE2yWG1Ky8pTsL/bf6wAAAAAgDLi9sTXq1cvnThxQiNHjlRiYqJatmypJUuWOCbAO3jwoMzm4ncc8PHx0R9//KFZs2YpOTlZ1atXV5cuXfTyyy97dPf5izGZTAoJ8FXK2VylZeUpMszdNQIAAAAAlBWTzWazubsS5U1qaqrCw8OVkpKisDDPSMU3vvaDjiSf1aLHb1TLmIrurg4AAAAAoARKkkPdOkYernNuLflcN9cEAAAAAFCWCPJewjFzPWvJAwAAAIBXI8h7Cfta8mkEeQAAAADwagR5LxESkN+1PpsgDwAAAADejCDvJRgjDwAAAABXB4K8lwhhjDwAAAAAXBUI8l4ijDHyAAAAAHBVIMh7CfsY+XTGyAMAAACAVyPIewl7kE9ljDwAAAAAeDWCvJdwrCNPizwAAAAAeDWCvJcIccxaT5AHAAAAAG9GkPcS9snumLUeAAAAALwbQd5L2MfIs448AAAAAHg3gryXsI+Rz8ixyGK1ubk2AAAAAICyQpD3EvYx8hIT3gEAAACANyPIe4kAXx/5+xo/ToI8AAAAAHgvgrwXCWWcPAAAAAB4PYK8F3GsJc/M9QAAAADgtQjyXsSxljxd6wEAAADAaxHkvUhogLGWfBot8gAAAADgtQjyXiSErvUAAAAA4PUI8l7EPkaeye4AAAAAwHsR5L2IfdZ6lp8DAAAAAO9FkPcijsnu6FoPAAAAAF6LIO9FQgOZ7A4AAAAAvB1B3ouEBDBGHgAAAAC8HUHei9gnu2OMPAAAAAB4L4K8FwlljDwAAAAAeD2CvBexj5GnRR4AAAAAvBdB3oswRh4AAAAAvB9B3ovQtR4AAAAAvB9B3ouEBhhd67PzrMrJs7q5NgAAAACAskCQ9yIh+S3yEuPkAQAAAMBbEeS9iI/ZpGB/H0mMkwcAAAAAb0WQ9zKMkwcAAAAA70aQ9zL2mevpWg8AAAAA3okg72Xsa8nTIg8AAAAA3okg72XsXevTsxkjDwAAAADeiCDvZRgjDwAAAADejSDvZexj5AnyAAAAAOCdCPJeJiSAMfIAAAAA4M0I8l6GMfIAAAAA4N0I8l6GMfIAAAAA4N0I8l7G0SJPkAcAAAAAr0SQ9zKMkQcAAAAA70aQ9zKOrvXZBHkAAAAA8EblIshPnjxZsbGxCgwMVLt27bRu3bpiHTdv3jyZTCb17NnTab/NZtPIkSMVHR2toKAgxcfHa9euXWVQ8/InxDFGnsnuAAAAAMAbuT3Iz58/X0OHDtWoUaO0YcMGtWjRQgkJCTp+/PhFj9u/f7+GDRumDh06FHjtjTfe0HvvvacpU6Zo7dq1qlChghISEpSVlVVWl1FuhDlmradFHgAAAAC8kduD/Ntvv60hQ4Zo0KBBaty4saZMmaLg4GBNnz69yGMsFov69u2rMWPGqE6dOk6v2Ww2TZgwQf/617901113qXnz5vroo4909OhRLVq0qNDzZWdnKzU11WnzVOePkbfZbG6uDQAAAADA1dwa5HNycrR+/XrFx8c79pnNZsXHx2v16tVFHjd27FhVq1ZNDz30UIHX9u3bp8TERKdzhoeHq127dkWec/z48QoPD3dsMTExpbgq97KPkbdYbcrKtbq5NgAAAAAAV3NrkD958qQsFosiIyOd9kdGRioxMbHQY1atWqVp06Zp6tSphb5uP64k5xwxYoRSUlIc26FDh0p6KeVGsL+PzCbjMePkAQAAAMD7+Lq7AiWRlpamBx98UFOnTlWVKlVcdt6AgAAFBAS47HzuZDKZFBLgq9SsPKVl56mauysEAAAAAHAptwb5KlWqyMfHR0lJSU77k5KSFBUVVaD8nj17tH//fvXo0cOxz2o1uo/7+vpq586djuOSkpIUHR3tdM6WLVuWwVWUP6GBfkaQZy15AAAAAPA6bu1a7+/vr1atWmn58uWOfVarVcuXL1f79u0LlG/YsKG2bNmiTZs2ObY777xTnTt31qZNmxQTE6PatWsrKirK6Zypqalau3Ztoef0RvZx8ukEeQAAAADwOm7vWj906FANGDBArVu3Vtu2bTVhwgRlZGRo0KBBkqT+/furRo0aGj9+vAIDA9W0aVOn4ytWrChJTvuffvppjRs3TvXq1VPt2rX10ksvqXr16gXWm/dWIQH2JegYIw8AAAAA3sbtQb5Xr146ceKERo4cqcTERLVs2VJLlixxTFZ38OBBmc0l6zgwfPhwZWRk6JFHHlFycrJuuukmLVmyRIGBgWVxCeWOvUU+lRZ5AAAAAPA6JhuLjReQmpqq8PBwpaSkKCwszN3VKbEn527UV5uPauQdjTX4ptrurg4AAAAA4BJKkkPdOkYeZcPetZ7J7gAAAADA+xDkvVBYIGPkAQAAAMBbEeS9EC3yAAAAAOC9CPJeyD7ZXVo2QR4AAAAAvA1B3guFBPpJokUeAAAAALwRQd4L2Vvk07MYIw8AAAAA3oYg74VCGSMPAAAAAF6LIO+FQvO71qczRh4AAAAAvA5B3guFBNIiDwAAAADeiiDvhRxj5LPzZLXa3FwbAAAAAIArEeS9kH0deUlKz6FVHgAAAAC8ie+lizjbt2+ffv75Zx04cECZmZmqWrWqrr32WrVv316BgYFlUUeUUKCfj/x9zMqxWJWelaew/DHzAAAAAADPV+wgP3v2bL377rv6/fffFRkZqerVqysoKEinT5/Wnj17FBgYqL59++r5559XrVq1yrLOKIaQQF+dzshhnDwAAAAAeJliBflrr71W/v7+GjhwoD7//HPFxMQ4vZ6dna3Vq1dr3rx5at26td5//33df//9ZVJhFE9ofpBPz2YteQAAAADwJsUK8q+99poSEhKKfD0gIECdOnVSp06d9Morr2j//v2uqh8uk32cfCot8gAAAADgVYoV5C8W4i9UuXJlVa5c+bIrBNdwzFxPkAcAAAAAr1LsWes//fRT5eTkOJ4fPnxYVqvV8TwzM1NvvPGGa2uHyxYSYExwl55NkAcAAAAAb1LsIN+nTx8lJyc7njdu3NipC31aWppGjBjhyrqhFOwt8mlZjJEHAAAAAG9S7CBvs9ku+hzlC13rAQAAAMA7FTvIw7Mw2R0AAAAAeCeCvJcKDWSMPAAAAAB4o2LNWm/33XffKTw8XJJktVq1fPlybd26VZKcxs/D/UIYIw8AAAAAXqlEQX7AgAFOz//+97+7tDJwnTD7GHla5AEAAADAqxQ7yJ+/1BzKP/sY+TTGyAMAAACAV3HZGHmr1aqvv/7aVadDKTnGyBPkAQAAAMCrlKhrfWF2796t6dOna+bMmTpx4oRycxmTXR4waz0AAAAAeKfLapE/e/asPvroI918881q0KCBfv31V40cOVKHDx92df1wmRzryGdzYwUAAAAAvEmJWuR/++03/fe//9W8efMUFxenvn376tdff9X777+vxo0bl1UdcRnsQT4r16pci1V+Pqw0CAAAAADeoNjprnnz5rr//vtVuXJl/frrr9qwYYOeffZZmUymsqwfLpO9a73EOHkAAAAA8CbFDvI7d+7UzTffrM6dO9P67gF8fcwK8vORxMz1AAAAAOBNih3k9+7dqwYNGujRRx/VNddco2HDhmnjxo20yJdj9u71aYyTBwAAAACvUewgX6NGDb344ovavXu3Pv74YyUmJurGG29UXl6eZs6cqb/++qss64nLEBLIWvIAAAAA4G0uawa0W265RZ988omOHTumSZMm6YcfflDDhg3VvHlzV9cPpcBa8gAAAADgfUo1lXl4eLgee+wx/f7779qwYYM6derkomrBFUID7EvQEeQBAAAAwFu4bE2yli1b6r333nPV6eAC9pnr07IYIw8AAAAA3qLY68jfcsstlyxjMpm0fPnyUlUIrnNusjta5AEAAADAWxQ7yK9cuVK1atXS7bffLj8/v7KsE1yEye4AAAAAwPsUO8i//vrrmjFjhhYsWKC+fftq8ODBatq0aVnWDaXEZHcAAAAA4H2KPUb+ueee07Zt27Ro0SKlpaXpxhtvVNu2bTVlyhSlpqaWZR1xmUIZIw8AAAAAXqfEk921b99eU6dO1bFjx/T4449r+vTpql69OmG+HLKPkWfWegAAAADwHpc9a/2GDRv0448/avv27WratCnj5ssh+xj5VLrWAwAAAIDXKFGQP3r0qF599VXVr19f9913nypVqqS1a9dqzZo1CgoKKqs64jIxRh4AAAAAvE+xJ7vr3r27VqxYoS5duujNN9/U7bffLl/fYh8ON3CsI5/NGHkAAAAA8BYmm81mK05Bs9ms6OhoVatWTSaTqchyGzZscFnl3CU1NVXh4eFKSUlRWFiYu6tz2XYlpem2d35SRLCfNo7s4u7qAAAAAACKUJIcWuwm9VGjRpW6Yriyzl9H3mazXfQGDAAAAADAM5SLID958mS9+eabSkxMVIsWLTRx4kS1bdu20LILFy7Uq6++qt27dys3N1f16tXTs88+qwcffNBRZuDAgZo1a5bTcQkJCVqyZEmZXUN5ZB8jn2e1KTvPqkA/HzfXCAAAAABQWm4f5D5//nwNHTpUU6ZMUbt27TRhwgQlJCRo586dqlatWoHylSpV0osvvqiGDRvK399fX3/9tQYNGqRq1aopISHBUa5r166aMWOG43lAQMAVuZ7yJNjPRyaTZLNJqVm5BHkAAAAA8ALFmrW+a9euWrNmzSXLpaWl6fXXX9fkyZOLXYG3335bQ4YM0aBBg9S4cWNNmTJFwcHBmj59eqHlO3XqpLvvvluNGjVSXFyc/vnPf6p58+ZatWqVU7mAgABFRUU5toiIiGLXyVuYzSbHhHfMXA8AAAAA3qFYLfL333+/7r33XoWHh6tHjx5q3bq1qlevrsDAQJ05c0bbtm3TqlWr9M033+j222/Xm2++Waw3z8nJ0fr16zVixAjHPrPZrPj4eK1evfqSx9tsNv3www/auXOnXn/9dafXVq5cqWrVqikiIkK33HKLxo0bp8qVKxd6nuzsbGVnZzuep6amFqv+niA0wFdpWXlKI8gDAAAAgFcoVpB/6KGH1K9fPy1YsEDz58/Xf/7zH6WkpEiSTCaTGjdurISEBP32229q1KhRsd/85MmTslgsioyMdNofGRmpHTt2FHlcSkqKatSooezsbPn4+Oj999/Xbbfd5ni9a9euuueee1S7dm3t2bNH//d//6du3bpp9erV8vEp2L18/PjxGjNmTLHr7UlCA/2klCylZxPkAQAAAMAbFHuMfEBAgPr166d+/fpJMsL02bNnVblyZfn5+ZVZBQsTGhqqTZs2KT09XcuXL9fQoUNVp04dderUSZLUu3dvR9lmzZqpefPmiouL08qVK3XrrbcWON+IESM0dOhQx/PU1FTFxMSU+XVcCedmrmcteQAAAADwBpc92V14eLjCw8NL9eZVqlSRj4+PkpKSnPYnJSUpKiqqyOPMZrPq1q0rSWrZsqW2b9+u8ePHO4L8herUqaMqVapo9+7dhQb5gIAAr50Mzz5Gnq71AAAAAOAdijXZXVnx9/dXq1attHz5csc+q9Wq5cuXq3379sU+j9VqdRrjfqHDhw/r1KlTio6OLlV9PVFofos8XesBAAAAwDu4ffm5oUOHasCAAWrdurXatm2rCRMmKCMjQ4MGDZIk9e/fXzVq1ND48eMlGePZW7durbi4OGVnZ+ubb77Rxx9/rA8++ECSlJ6erjFjxujee+9VVFSU9uzZo+HDh6tu3bpOy9NdLUIDaZEHAAAAAG/i9iDfq1cvnThxQiNHjlRiYqJatmypJUuWOCbAO3jwoMzmcx0HMjIy9Nhjj+nw4cMKCgpSw4YN9cknn6hXr16SJB8fH/3xxx+aNWuWkpOTVb16dXXp0kUvv/yy13afv5jQQGP+AlrkAQAAAMA7mGw2m624hS0Wi3755Rc1b95cFStWLMNquVdqaqrCw8OVkpKisLAwd1enVN5bvktvL/1LfdrGaPw9zd1dHQAAAABAIUqSQ0s0Rt7Hx0ddunTRmTNnSlVBXDl0rQcAAAAA71Liye6aNm2qvXv3lkVdUAaYtR4AAAAAvEuJg/y4ceM0bNgwff311zp27JhSU1OdNpQvjJEHAAAAAO9S4snuunfvLkm68847ZTKZHPttNptMJpMsFovraodSO9e1PtfNNQEAAAAAuEKJg/yKFSvKoh4oI4515OlaDwAAAABeocRBvmPHjmVRD5QRxsgDAAAAgHe5rHXkk5OTNW3aNG3fvl2S1KRJEw0ePFjh4eEurRxKzzFGPidPVqtNZrPpEkcAAAAAAMqzEk929/vvvysuLk7vvPOOTp8+rdOnT+vtt99WXFycNmzYUBZ1RCnYu9bbbFJGDq3yAAAAAODpStwi/8wzz+jOO+/U1KlT5etrHJ6Xl6eHH35YTz/9tH766SeXVxKXL8DXLD8fk3ItNqVn5zla6AEAAAAAnumyWuSff/55R4iXJF9fXw0fPly///67SyuH0jOZTIyTBwAAAAAvUuIgHxYWpoMHDxbYf+jQIYWGhrqkUnAteys8QR4AAAAAPF+Jg3yvXr300EMPaf78+Tp06JAOHTqkefPm6eGHH1afPn3Koo4opXMt8qwlDwAAAACersRj5N966y2ZTCb1799feXlGC6+fn58effRRvfbaay6vIEovxL6WfDYt8gAAAADg6UoU5C0Wi9asWaPRo0dr/Pjx2rNnjyQpLi5OwcHBZVJBlF6YPcjTtR4AAAAAPF6JgryPj4+6dOmi7du3q3bt2mrWrFlZ1QsuxGR3AAAAAOA9SjxGvmnTptq7d29Z1AVlxDHZHV3rAQAAAMDjlTjIjxs3TsOGDdPXX3+tY8eOKTU11WlD+WMfI89kdwAAAADg+Uo82V337t0lSXfeeadMJpNjv81mk8lkksVicV3t4BKhjJEHAAAAAK9R4iC/YsWKsqgHylAoY+QBAAAAwGuUKMjn5uZq7NixmjJliurVq1dWdYKL2cfIs/wcAAAAAHi+Eo2R9/Pz0x9//FFWdUEZOTdrPWPkAQAAAMDTlXiyu379+mnatGllUReUEfsYeWatBwAAAADPV+Ix8nl5eZo+fbqWLVumVq1aqUKFCk6vv/322y6rHFzj3Kz1BHkAAAAA8HQlDvJbt27VddddJ0n666+/nF47fxZ7lB9h9jHyBHkAAAAA8HjMWn8VsI+RP5trUa7FKj+fEo+oAAAAAACUEy5NdMePH3fl6eAi9q71kpTBOHkAAAAA8GjFDvLBwcE6ceKE4/ntt9+uY8eOOZ4nJSUpOjratbWDS/j5mBXoZ/yoGScPAAAAAJ6t2EE+KytLNpvN8fynn37S2bNnncqc/zrKF/ta8gR5AAAAAPBsLu1az2R35Vcoa8kDAAAAgFdg1rOrhH2cfDpj5AEAAADAoxU7yJtMJqcW9wufo3wLZS15AAAAAPAKxV5+zmazqX79+o7wnp6ermuvvVZms9nxOsov+xJ0abTIAwAAAIBHK3aQnzFjRlnWA2XMPtldOi3yAAAAAODRih3kBwwYUJb1QBkLYbI7AAAAAPAKTHZ3lQhjsjsAAAAA8AoE+atECJPdAQAAAIBXIMhfJexj5AnyAAAAAODZCPJXCcbIAwAAAIB3uOwgn5OTo507dyovjxZeTxDKGHkAAAAA8AolDvKZmZl66KGHFBwcrCZNmujgwYOSpCeffFKvvfaayysI1whljDwAAAAAeIUSB/kRI0Zo8+bNWrlypQIDAx374+PjNX/+fJdWDq7jWEeeFnkAAAAA8GjFXkfebtGiRZo/f76uv/56mUwmx/4mTZpoz549Lq0cXOf8MfI2m83pZwcAAAAA8BwlbpE/ceKEqlWrVmB/RkYG4bAcs3etz7XYlJ1ndXNtAAAAAACXq8RBvnXr1lq8eLHjuT28//e//1X79u1dVzO4VAX/c50vGCcPAAAAAJ6rxF3rX331VXXr1k3btm1TXl6e3n33XW3btk2//vqrfvzxx7KoI1zAbDYpJMBX6dl5Ss/OU9XQAHdXCQAAAABwGUrcIn/TTTdp06ZNysvLU7NmzfT999+rWrVqWr16tVq1anVZlZg8ebJiY2MVGBiodu3aad26dUWWXbhwoVq3bq2KFSuqQoUKatmypT7++GOnMjabTSNHjlR0dLSCgoIUHx+vXbt2XVbdvMm5metZSx4AAAAAPFWJW+QlKS4uTlOnTnVJBebPn6+hQ4dqypQpateunSZMmKCEhATt3Lmz0LH4lSpV0osvvqiGDRvK399fX3/9tQYNGqRq1aopISFBkvTGG2/ovffe06xZs1S7dm299NJLSkhI0LZt25xm2r/a2Ce8S6drPQAAAAB4rBK3yPv4+Oj48eMF9p86dUo+Pj4lrsDbb7+tIUOGaNCgQWrcuLGmTJmi4OBgTZ8+vdDynTp10t13361GjRopLi5O//znP9W8eXOtWrVKktEaP2HCBP3rX//SXXfdpebNm+ujjz7S0aNHtWjRohLXz5vYW+RTCfIAAAAA4LFKHORtNluh+7Ozs+Xv71+ic+Xk5Gj9+vWKj48/VyGzWfHx8Vq9enWx6rJ8+XLt3LlTN998syRp3759SkxMdDpneHi42rVrV+Q5s7OzlZqa6rR5oxDWkgcAAAAAj1fsrvXvvfeeJGOW+v/+978KCQlxvGaxWPTTTz+pYcOGJXrzkydPymKxKDIy0ml/ZGSkduzYUeRxKSkpqlGjhrKzs+Xj46P3339ft912myQpMTHRcY4Lz2l/7ULjx4/XmDFjSlR3T2RvkU9njDwAAAAAeKxiB/l33nlHktEKPmXKFKdu9P7+/oqNjdWUKVNcX8NChIaGatOmTUpPT9fy5cs1dOhQ1alTR506dbqs840YMUJDhw51PE9NTVVMTIyLalt+hAbYJ7ujRR4AAAAAPFWxg/y+ffskSZ07d9bChQsVERFR6jevUqWKfHx8lJSU5LQ/KSlJUVFRRR5nNptVt25dSVLLli21fft2jR8/Xp06dXIcl5SUpOjoaKdztmzZstDzBQQEKCDA+5djc7TI07UeAAAAADxWicfIr1ixwiUhXjJa8lu1aqXly5c79lmtVi1fvlzt27cv9nmsVquys7MlSbVr11ZUVJTTOVNTU7V27doSndMbhQQYY+SZ7A4AAAAAPFeJl58bPHjwRV8varb5ogwdOlQDBgxQ69at1bZtW02YMEEZGRkaNGiQJKl///6qUaOGxo8fL8kYz966dWvFxcUpOztb33zzjT7++GN98MEHkowx/E8//bTGjRunevXqOZafq169unr27FnSy/UqtMgDAAAAgOcrcZA/c+aM0/Pc3Fxt3bpVycnJuuWWW0pcgV69eunEiRMaOXKkEhMT1bJlSy1ZssQxWd3BgwdlNp/rOJCRkaHHHntMhw8fVlBQkBo2bKhPPvlEvXr1cpQZPny4MjIy9Mgjjyg5OVk33XSTlixZclWvIS9JIYH2MfJMdgcAAAAAnspkK2o9uRKwWq169NFHFRcXp+HDh7uiXm6Vmpqq8PBwpaSkKCwszN3VcZklW4/pH59sUOtaEfrs0RvcXR0AAAAAQL6S5NASj5Ev9CRms4YOHeqY2R7lk32MPLPWAwAAAIDnckmQl6Q9e/YoL4+AWJ4xRh4AAAAAPF+Jx8ifv966ZKwrf+zYMS1evFgDBgxwWcXgevYx8qmMkQcAAAAAj1XiIL9x40an52azWVWrVtW///3vS85oD/c6v0XeZrPJZDK5uUYAAAAAgJIqcZBfsWJFWdQDV0Bo/hh5m03KyLEoJKDEP34AAAAAgJu5bIw8yr9AP7N8zEYrfDoT3gEAAACARypWk+y1115b7G7YGzZsKFWFUHZMJpNCA32VnJmrtKxcRYUHurtKAAAAAIASKlaQ79mzZxlXA1dKSEB+kGfmegAAAADwSMUK8qNGjSrreuAKCQ30k3SWteQBAAAAwENd9mxn69ev1/bt2yVJTZo00bXXXuuySqHshOZPcMcYeQAAAADwTCUO8sePH1fv3r21cuVKVaxYUZKUnJyszp07a968eapataqr6wgXsi9Bl8Za8gAAAADgkUo8a/2TTz6ptLQ0/fnnnzp9+rROnz6trVu3KjU1VU899VRZ1BEuFHLeWvIAAAAAAM9T4hb5JUuWaNmyZWrUqJFjX+PGjTV58mR16dLFpZWD651rkSfIAwAAAIAnKnGLvNVqlZ+fX4H9fn5+slqtLqkUyk5IgPGzI8gDAAAAgGcqcZC/5ZZb9M9//lNHjx517Dty5IieeeYZ3XrrrS6tHFwv1NG1njHyAAAAAOCJShzkJ02apNTUVMXGxiouLk5xcXGqXbu2UlNTNXHixLKoI1yIrvUAAAAA4NlKPEY+JiZGGzZs0LJly7Rjxw5JUqNGjRQfH+/yysH1QpnsDgAAAAA82mWtI28ymXTbbbfptttuk2QsPwfPYB8jn0qLPAAAAAB4pBJ3rX/99dc1f/58x/O//e1vqly5smrUqKHNmze7tHJwPUeLPOvIAwAAAIBHKnGQnzJlimJiYiRJS5cu1dKlS/Xtt9+qW7dueu6551xeQbhWSABj5AEAAADAk5W4a31iYqIjyH/99df629/+pi5duig2Nlbt2rVzeQXhWmGBRtd6xsgDAAAAgGcqcYt8RESEDh06JElasmSJY5I7m80mi8Xi2trB5ULyu9Zn5liUZ7G6uTYAAAAAgJIqcYv8PffcowceeED16tXTqVOn1K1bN0nSxo0bVbduXZdXEK5l71ovSRnZFoUHl/heDgAAAADAjUoc5N955x3Fxsbq0KFDeuONNxQSEiJJOnbsmB577DGXVxCu5e9rVoCvWdl5VqVm5So82M/dVQIAAAAAlECJg7yfn5+GDRtWYP8zzzzjkgqh7IUG+io7PYdx8gAAAADggS5rHfmdO3dq4sSJ2r59uySpUaNGevLJJ9WgQQOXVg5lIzTQTyfTc5i5HgAAAAA8UIkHSH/++edq2rSp1q9frxYtWqhFixbasGGDmjZtqs8//7ws6ggXs4+TT89mLXkAAAAA8DQlbpEfPny4RowYobFjxzrtHzVqlIYPH657773XZZVD2QgNZC15AAAAAPBUJW6RP3bsmPr3719gf79+/XTs2DGXVAply94iT5AHAAAAAM9T4iDfqVMn/fzzzwX2r1q1Sh06dHBJpVC2QgONmeqZ7A4AAAAAPE+xutZ/+eWXjsd33nmnnn/+ea1fv17XX3+9JGnNmjVasGCBxowZUza1hEud61rPGHkAAAAA8DQmm81mu1Qhs7l4Dfcmk0kWi6XUlXK31NRUhYeHKyUlRWFhYe6ujsv9+/udmvjDbg1oX0tj7mrq7uoAAAAAwFWvJDm0WC3yVqvVJRVD+cAYeQAAAADwXCUeI1+U5ORkTZo0yVWnQxmyj5FPY4w8AAAAAHicUgf55cuX64EHHlB0dLRGjRrlijqhjIUwRh4AAAAAPNZlBflDhw5p7Nixql27trp06SKTyaQvvvhCiYmJrq4fyoB9sjtmrQcAAAAAz1PsIJ+bm6sFCxYoISFBDRo00KZNm/Tmm2/KbDbrxRdfVNeuXeXn51eWdYWLhDJGHgAAAAA8VrEmu5OkGjVqqGHDhurXr5/mzZuniIgISVKfPn3KrHIoG4515AnyAAAAAOBxit0in5eXJ5PJJJPJJB8fn7KsE8rYuTHyBHkAAAAA8DTFDvJHjx7VI488orlz5yoqKkr33nuvvvjiC5lMprKsH8qAffm5HItV2XkWN9cGAAAAAFASxQ7ygYGB6tu3r3744Qdt2bJFjRo10lNPPaW8vDy98sorWrp0qSwWQqEnsAd5iVZ5AAAAAPA0lzVrfVxcnMaNG6cDBw5o8eLFys7O1h133KHIyEhX1w9lwMdsUgV/Y3gE4+QBAAAAwLMUe7K7wpjNZnXr1k3dunXTiRMn9PHHH7uqXihjoYF+ysix0CIPAAAAAB7mslrkC1O1alUNHTrUVadDGXNMeJed6+aaAAAAAABKwmVBHp4llJnrAQAAAMAjlYsgP3nyZMXGxiowMFDt2rXTunXriiw7depUdejQQREREYqIiFB8fHyB8gMHDnQslWffunbtWtaX4VHsE94xRh4AAAAAPIvbg/z8+fM1dOhQjRo1Shs2bFCLFi2UkJCg48ePF1p+5cqV6tOnj1asWKHVq1crJiZGXbp00ZEjR5zKde3aVceOHXNsc+fOvRKXc2Vlp0kbP5EsJQ/jYYF+kqS0LLrWAwAAAIAncXuQf/vttzVkyBANGjRIjRs31pQpUxQcHKzp06cXWn727Nl67LHH1LJlSzVs2FD//e9/ZbVatXz5cqdyAQEBioqKcmwRERFX4nKuHKtV+uAG6X+PS7uXlvhwR4t8Ni3yAAAAAOBJSjxrvcVi0cyZM7V8+XIdP35cVqvV6fUffvih2OfKycnR+vXrNWLECMc+s9ms+Ph4rV69uljnyMzMVG5uripVquS0f+XKlapWrZoiIiJ0yy23aNy4capcuXKh58jOzlZ2drbjeWpqarGvwW3MZqnRndLqSdLvM6QG3Up0uGOMPEEeAAAAADxKiYP8P//5T82cOVO33367mjZtKpPJdNlvfvLkSVkslgLrz0dGRmrHjh3FOsfzzz+v6tWrKz4+3rGva9euuueee1S7dm3t2bNH//d//6du3bpp9erV8vHxKXCO8ePHa8yYMZd9HW7TapAR5HcvlZIPSRVjin1oCJPdAQAAAIBHKnGQnzdvnj799FN17969LOpTIq+99prmzZunlStXKjAw0LG/d+/ejsfNmjVT8+bNFRcXp5UrV+rWW28tcJ4RI0Y4LZ2XmpqqmJjih2K3qVJXiu0g7f9Z2vCRdMuLxT40NH+MPJPdAQAAAIBnKfEYeX9/f9WtW9clb16lShX5+PgoKSnJaX9SUpKioqIueuxbb72l1157Td9//72aN29+0bJ16tRRlSpVtHv37kJfDwgIUFhYmNPmMVoPNr5u+EiyFH/iutAAe4s8k90BAAAAgCcpcZB/9tln9e6778pms5X6zf39/dWqVSuniersE9e1b9++yOPeeOMNvfzyy1qyZIlat259yfc5fPiwTp06pejo6FLXudxpeIdUoaqUnij9taTYh9nHyDPZHQAAAAB4lhJ3rV+1apVWrFihb7/9Vk2aNJGfn5/T6wsXLizR+YYOHaoBAwaodevWatu2rSZMmKCMjAwNGjRIktS/f3/VqFFD48ePlyS9/vrrGjlypObMmaPY2FglJiZKkkJCQhQSEqL09HSNGTNG9957r6KiorRnzx4NHz5cdevWVUJCQkkvt/zz9Zda9pV+mWBMeteoR7EOY4w8AAAAAHimEgf5ihUr6u6773ZZBXr16qUTJ05o5MiRSkxMVMuWLbVkyRLHBHgHDx6U2Xyu48AHH3ygnJwc3XfffU7nGTVqlEaPHi0fHx/98ccfmjVrlpKTk1W9enV16dJFL7/8sgICAlxW73Kl1QAjyO/5QTqzX4qIveQhoY515AnyAAAAAOBJTDZX9JH3MqmpqQoPD1dKSornjJf/qKe0d4V001ApftQli+8+nq74t39UWKCv/hjthT0VAAAAAMCDlCSHlniMPMqp1sZQBG38pFiT3p0/Rp57OQAAAADgOUrctV6SPvvsM3366ac6ePCgcnJynF7bsGGDSyqGEmrQXQqJlNKTpB2LpSY9L1rcHuStNikzx6IKAZf1UQAAAAAAXGElbpF/7733NGjQIEVGRmrjxo1q27atKleurL1796pbt25lUUcUh4+fdG0/4/H6GZcsHuTnIx+zSRIz1wMAAACAJylxkH///ff1n//8RxMnTpS/v7+GDx+upUuX6qmnnlJKSkpZ1BHFdd0ASSZp70rp1J6LFjWZTAphLXkAAAAA8DglDvIHDx7UDTfcIEkKCgpSWlqaJOnBBx/U3LlzXVs7lExELanurcbjDbMuWfxckKdFHgAAAAA8RYmDfFRUlE6fPi1JqlmzptasWSNJ2rdvH5OmlQet7JPezZbyci5aNJS15AEAAADA45Q4yN9yyy368ssvJUmDBg3SM888o9tuu029evVy6fryuEz1u0qh0VLmSWnHVxctev7M9QAAAAAAz1Diqcr/85//yGq1SpIef/xxVa5cWb/++qvuvPNO/f3vf3d5BVFCPr7Sdf2lH1+Xfp8hNb23yKKhgX6SGCMPAAAAAJ6kxEHebDbLbD7XkN+7d2/17t3bpZVCKV3XX/rpTWn/z9LJ3VKVuoUWY4w8AAAAAHieEnetl6Sff/5Z/fr1U/v27XXkyBFJ0scff6xVq1a5tHK4TOHXSPW6GI8vshQdXesBAAAAwPOUOMh//vnnSkhIUFBQkDZu3Kjs7GxJUkpKil599VWXVxCXyT7p3aY5Um5WoUVCmOwOAAAAADxOiYP8uHHjNGXKFE2dOlV+fn6O/TfeeKM2bNjg0sqhFOrdJoVdI509LW0vfNK7sPwx8ukEeQAAAADwGCUO8jt37tTNN99cYH94eLiSk5NdUSe4gtnHGCsvSb9PL7SIY4x8NpPdAQAAAICnuKx15Hfv3l1g/6pVq1SnTh2XVAouct2DkslHOvirdHxHgZdZRx4AAAAAPE+Jg/yQIUP0z3/+U2vXrpXJZNLRo0c1e/ZsDRs2TI8++mhZ1BGXK6y6sa68JK2fWeBlZq0HAAAAAM9T4uXnXnjhBVmtVt16663KzMzUzTffrICAAA0bNkxPPvlkWdQRpdF6kLRzsbR5jhQ/SvILcrxkX0eeWesBAAAAwHOUuEXeZDLpxRdf1OnTp7V161atWbNGJ06c0Msvv1wW9UNpxd0ihdeUslKkPxc5vXSuaz1j5AEAAADAU1zWOvKS5O/vr8aNG6tt27YKCQlxZZ3gSmYfqVX+pHcXrClv71rPrPUAAAAA4DmK3bV+8ODBxSo3fXrhM6TDja59UFr5mnRorZS0TYpsLOlci3xGjkUWq00+ZpM7awkAAAAAKIZiB/mZM2eqVq1auvbaa2Wz2cqyTnC10CipQTdjPfn1M6Tub0qSQgLP/fjTs/MUHuTnrhoCAAAAAIqp2EH+0Ucf1dy5c7Vv3z4NGjRI/fr1U6VKlcqybnCl1oONIL95vhQ/RvIPVoCvj/x9zcrJsyotK5cgDwAAAAAeoNhj5CdPnqxjx45p+PDh+uqrrxQTE6O//e1v+u6772ih9wS1O0kRsVJ2ivTnQsfuUPs4eWauBwAAAACPUKLJ7gICAtSnTx8tXbpU27ZtU5MmTfTYY48pNjZW6enpZVVHuILZLLUaaDz+/dykd+dmrifIAwAAAIAnuOxZ681ms0wmk2w2mywWiyvrhLLSsp9k9pOO/C4lbpF0bpw8M9cDAAAAgGcoUZDPzs7W3Llzddttt6l+/frasmWLJk2apIMHD7IEnScIqSo1usN4nN8qHxpgjItPZS15AAAAAPAIxQ7yjz32mKKjo/Xaa6/pjjvu0KFDh7RgwQJ1795dZvNlN+zjSms1yPj6x6dSdvq5FnnGyAMAAACARyj2rPVTpkxRzZo1VadOHf3444/68ccfCy23cOHCQvejnKh9s1QpTjq9R9r6uUIDW0hijDwAAAAAeIpiB/n+/fvLZDKVZV1wJZhMxqR3S1+S1s9QaOQkSYyRBwAAAABPUewgP3PmzDKsBq6oln2lH16Wjm5U3cq7JfnpZHq2u2sFAAAAACgGBrdfjSpUlhrdKUnqnL5YkvTFxiM6fCbTnbUCAAAAABQDQf5q1dqY9K7G4cXqVCtA2XlWvbJ4u5srBQAAAAC4FIL81arWjVKV+jLlZui1+jvlYzbp262J+nnXCXfXDAAAAABwEQT5q5XJ5FiKLmrXXD3YrqYkafSXfyonz+rOmgEAAAAALoIgfzVr0VvyCZASt2hY0wxVruCvPScyNOvX/e6uGQAAAACgCAT5q1lwJanJ3ZKkkG+f0NiOIZKkCcv+0vHULHfWDAAAAABQBIL81a7T81JYDenkX+q+9kHdH5WkjByLxn+7w901AwAAAAAUgiB/tatUR3p4uRTVXKaME3o9bYQSfH7TFxuP6Lf9p91dOwAAAADABQjykMKipUHfSvUSZLZk6QO/CXrI5xuNXLRVFqvN3bUDAAAAAJyHIA9DQIjUe47U5mGZZdNLfp+o98n3NHf1HnfXDAAAAABwHoI8zvHxlbq/JXV5RTaZNMB3qWKWPqLTZ+hiDwAAAADlBUEezkwm6YYnZL1vlrLlr45ar7MfJkipx9xdMwAAAACACPIogk/Tu7Tn9nk6aQtTjay/lPPhLVLSn+6uFgAAAABc9QjyKFLjNrfqg7gp2m2tLv+Mo7JNS5B2L3d3tQAAAADgqkaQx0U90vNWPaiXtdrSWKacNGn2/dL6me6uFgAAAABctQjyuKjIsEANir9W/XNf0GLTzZLNIn31T2nZaMlqdXf1AAAAAOCqQ5DHJQ28obZqVg3X42f/rpXRg42dq96RPn9Iys1yb+UAAAAAlD+n9khbP5dyMtxdE69ULoL85MmTFRsbq8DAQLVr107r1q0rsuzUqVPVoUMHRUREKCIiQvHx8QXK22w2jRw5UtHR0QoKClJ8fLx27dpV1pfhtfx9zRp9ZxNJJj104DYd6/yOZPaT/lwofXSXlHHK3VUEAAAAUB7YbNLvM6QPbpQ+Gyy93Uj67kXpzH5318yruD3Iz58/X0OHDtWoUaO0YcMGtWjRQgkJCTp+/Hih5VeuXKk+ffpoxYoVWr16tWJiYtSlSxcdOXLEUeaNN97Qe++9pylTpmjt2rWqUKGCEhISlJVF6/Hl6lCvqro2iZLFatMzOxvJ1u9zKSBcOrRGmhZv3HEDAAAAcPU6mywtGCh9/bSUd9bIC1kp0upJ0rstpbkPSHt/NMI+SsVks7n3u9iuXTu1adNGkyZNkiRZrVbFxMToySef1AsvvHDJ4y0WiyIiIjRp0iT1799fNptN1atX17PPPqthw4ZJklJSUhQZGamZM2eqd+/elzxnamqqwsPDlZKSorCwsNJdoBc5fCZTt/77R2XnWTWxz7XqUT1Nmn2flHxQCqok9Z4t1brB3dUEAAAAcKUdWid99pCUclAy+0q3jpSuf1zas1xa+6Hx1a5qI6ndI1LzXpJ/BffVuZwpSQ51a4t8Tk6O1q9fr/j4eMc+s9ms+Ph4rV69uljnyMzMVG5uripVqiRJ2rdvnxITE53OGR4ernbt2hV5zuzsbKWmpjptKOiaiGA91qmuJOmVxduVERYnPbxcqn6ddPa0NPMOadUEJsEDrmbcYQcA4OpitUg/vSVN72qE+IhYafD30o3/lHx8pfoJ0oMLpcd/k9oMkfwqSCe2S18/Y3S7//5f0pkD7r4Kj+PWIH/y5ElZLBZFRkY67Y+MjFRiYmKxzvH888+revXqjuBuP64k5xw/frzCw8MdW0xMTEkv5arx9451FFMpSImpWZq0YrcUUk0auFhqep8xo/2yUdKcvzFuHrjaWK3S6snS67HSp/0ZbgMAwNUgLVH6+G7ph5eNLND0PunvP0vXtCpYtmp96fa3pGe3SwnjjcCflSL9OlF6r6U0r6+07yfXNwrYbFL6ca8bo+/r7gqUxmuvvaZ58+Zp5cqVCgwMvOzzjBgxQkOHDnU8T01NJcwXIdDPRyPvaKIhH/2u//68V/e3ukZ1qoZI9/5Xqt1B+vZ5afdSacpN0n3TpVrt3V1lAGUt/YS06FHj374kbfuftOMbqc3DUsfhUnAl99YPAAC43q6l0hf/kDJPSn7BUve3pJYPSCbTxY8LDJfaPya1+7txjnUfSnt+kHZ8bWzVGktt7d3ugy9dD0uelHZUSj4kpRzK/3rw3POUw1JellTrJmnQYtdcezng1iBfpUoV+fj4KCkpyWl/UlKSoqKiLnrsW2+9pddee03Lli1T8+bNHfvtxyUlJSk6OtrpnC1btiz0XAEBAQoICLjMq7j6xDeqpo71q+rHv05ozFfbNHNQG5lMJqnVQKlGa2OCi1O7pJm3S7e8KN34jGR2+7yKAMrC7uXGf+IZxyXfQKnj89KBX41Qv/YDadMc6eZhxn/Ifpd/wxUAgEKdTZZsVikgVPLxc3dtLl9ulhE4M45LYTWk8Gsks4+7a1W4vBxp+RhjAjtJimxmNOBVrV+y85h9pAZdje3ETmndf6RNc6Xj24zJ8paNlq7rb2QMm805nCcfMubpSjkkpR41egNclEmy5JT8WsuxcjHZXdu2bTVx4kRJxmR3NWvW1BNPPFHkZHdvvPGGXnnlFX333Xe6/vrrnV6zT3Y3bNgwPfvss5KMFvZq1aox2Z0L7T2RroQJPynXYtPU/q11W+PzhjJkp0uLh0p/zDeex90q3f2hFFLVPZUF4Hp5OUY3ul/fM55Xa2z8J16tkfF8zw/S9yOlpC3G84o1pVtHSU3vvfSdegAALuZssrT9S+mPT6X9qyTlxxnfICkwTAoIy/8aet7j8EL2hTk/Dgwvu5vOeTn5AfRg/nbg3OMzB6T0C4YA+/hLlepIleKkyvatrvE8NMp9/5ee2mMsKXdsk/G83T+k+DGu+76dTTYaAdZ9WLKu8GY/4+ZHxRgpvGb+15hzX8NqSL7+rqljGSpJDnV7kJ8/f74GDBigDz/8UG3bttWECRP06aefaseOHYqMjFT//v1Vo0YNjR8/XpL0+uuva+TIkZozZ45uvPFGx3lCQkIUEhLiKPPaa69p1qxZql27tl566SX98ccf2rZtW7G64BPki+f1JTv0wco9iqkUpKXPdFSg33l3DW02aeMn0jfPGUtPhERJ902TYm9yX4WLKydD2vW9VLsjXYKBwpzaI33+kHR0o/G8zRCpy8uSX5BzOavFuKG3/GWjy5sk1WgldRnHChcAgJLJyzF6e/0xX9q5RLJkl837+PifC/XnB3zHzYDC9uc/ls4L6heE9dSjctxwKIpfBalCFSnt2MVbj/1DjJB/frivXNd4XpZ/u26ebzTW5aQbK1b1fF9q0K1s3stqMbrdr50i7V1hfG/OD+cVa+Y/zv8aEukVPYA9KshL0qRJk/Tmm28qMTFRLVu21Hvvvad27dpJkjp16qTY2FjNnDlTkhQbG6sDBwrOajhq1CiNHj1aktEqP2rUKP3nP/9RcnKybrrpJr3//vuqX7943T0I8sWTkZ2nW//9oxJTszT0tvp66tZ6BQslbTO62p/cKZnMUqf/kzoMLb9dhY5skD5/WDq9x/gF+eAXxkQcAIwbdJvnSd8My/9PPEK6a7LU8PaLH5eTKa2ZbKxqkZNu7Gt4h3EHv0rdMq+2x8vLltbPlDJPSVXqS1XqGX+wsVwPyhNLrrH01J7lRo+c4zuk6BZSnY7GjfFr2nhEaxjKGatVOrTWCO9/fiFlJZ97rWpDqfnfpGb3S6HRUnaaMXFadmr+41Tjsf3r+Y+z8ss4vZ6mSwbt0vINMoJnRC3jq2OrZWzBlYyWdqvFaL0/tSd/2238bXpqt3FTwHaRFaKCIoxgX7WB8T2q1sjYwmpcfit+dprROLd5rvG81k3SvVOlsOqXd76Syss2brBcBT36PC7IlzcE+eL7cvNRPTV3owJ8zVr+bEddE1HIhBQ5GdLiYdLmOcbzOp2ke6YaM96XF1aL9Mu70opXJGveuf0hkVK/z6WoZu6rG1AeZKUad+G3LDCex3YwhsyE1yj+OdKPSyvHG6HUZjXWmG39kDGuvkLlMqm2xzu1R/pskHRsc8HXwmOMUF+lvvMWUu2q+GMH5cDpfUZw3/2DMdN0TlrRZf2CpZrtzwX7qOZe0XqGMnJipxHetywwgqtdSJTU7D5jErSoZq79XWe1Gp/hrNRzNwQcwT+liH3n3RjISjHGadtbiZ3CeqzxtUKV0tc5L8focm4P9o6gv1dKPVL0cQFhRriv1shYw71aQ+PrpbrpH91kdKU/vSe/UW6E1OHZ8tso5+EI8qVEkC8+m82m3v9Zo7X7TuuGuMqa2r+1KgQUMYfipjnS4mel3EwjIN8z1fgP3d1SDksL/y4dWGU8b3yX8Uvqs4ek438av/j6zPWMYQFAWTj8u9GV/sx+yeQjdR4h3VSKnjXHdxhLVf61xHgeEGb01Gn3KBPinW/zPON3pr33Q4PbjT+kTv5ltM4XJSD8XMCvel7Aj4j17Img4H7ZadK+n/PD+3LpzD7n14MrS3U6S3VvNULWkQ3Svh+NkJ9xwrlsUIRxQ7BOR6l2J6NLMDegrm5pidLWz40Af/7NS/9QqfGdRut7bAcC5MXkZBg32E7tMm6GHN8undhhBP3zG6rOF1gxP9yf13pftZFx02HNB9LSkZI1Vwq7xlilihWpyhRBvpQI8iWzMzFNd05apew8qxpHh2nawNaKDg8qvPDxHUZX+xPbJZmMlriOw933S/nPL6Sv/mncRfWrIHV/89yyGWeTpbl9pIO/Sj4Bxhj/Rj3cU0/AHaxW6ZcJ53qqhNc0/h3EtHXN+ff+KH3/LynxD+N5eIx060hjDdqruaUuO83oxfTHPON5YV0YM04Zf6id/MvYTuR/TT5QdJdLs68xKWHjO6Um9xjBCbgYq9X492lvdT+01viD3s7sK8W0k+JuMbboloX/27XZjFmo9/5oBPv9vxRsvQ+rYbTU21vsw6ILngfuZbMZwXDfT8aWfMAY4uMfkj+BXIhxY9Y/JP9xqBHCHa+Fnlc21FjpJCdd2v61Ed73/Xju95fZV6obb4T3+t2KtwQZipaXY4T5E9uNv8VPbDd+lqf3Fv1/hn/ouX+nDe+Q7pzI3FFXAEG+lAjyJbf+wGk98tF6ncrIUWRYgKYNaKOmNcILL5yTKX37nDEZnmTcXb13mhQaWXj5spCdZqx5v2m28bxGK6OHwIV/2OaeNVrmdy42uhPdMUFqNeDK1RNwl9Rj0hd/N/6wkozgd8c7UlBF176P1Spt+VRaPvZcl8Dolka3vbjOxh97V5PSdmHMzTL+MDv5l3TyvKB/cpeUm+Fctvq1xs+1yd3GxEG4ulnyjJ4eGcelxK35Y91XGOtDny+ittHiHneL8f934GX8nWTJNSbLtAf7Q2sLTuxVpb4R6BveLtW+mVZYd7DZjN8n9uC+/+eCPStKw+STPx78vJbia9oa4b3JPQy5uhJys4ybwueH++Pb82eLtxkNWV1fNYbB0WPmiiDIlxJB/vIcOp2pwTN/067j6Qry89G7vVuqS5Ooog/YPF/6+hnjj8sKVY0gHde57Ct6+HdjQrsz+4w/lDs8a/QMKKrLqSXPWMty48fG81v+JXUYxi80eK+dS6T/PWb8Ue8XLHV7Q7q2X9l+5nPPGl34fn77XAuA2U+qeb3RKlM3Xops4r3/7my2su3CaLUaN0r2rpT+XGgEqPPX3I1pZywN2PguY7wkvENethG8Mk5I6SeMkJ5+PP/58fNeO54/XKOQPwn9Q4wgHXeLEeAr1XF9PXMypUNrzgX7o5uc6xIanT8uurcU1dT17+8JLLnnZkH3DzV66IRGuf4GR8qRc8F9309S6mHn132DjN9LtW821g7PO2ssO5ydZvzuzk4773l6/iRy5z9POzfpqV3lusaY92b3lc3nCyWXk2kE/NDqLB99hRHkS4kgf/lSs3L1+OwN+nnXSZlM0v91a6SHO9SWqag/vk/8ZXS1P/6nJJN0/aNSy75l8we71WKEhJXjz01Gcs9/ircMls0m/TBO+vkt43nbR6Sur1/d3X/hfXKzjLHra6cYz6OaSffNMMZbXynpJ6Rf35V2LDZags4XGm0EibrxxqSZQRFXrl5lKeOktOhRY9lL6cp0YUw/IW3/n7T1C+nALzoXmkzGfCBN75Ea3VU+W8SsVqPHwrHNRvfbqGZGK/HV+vs446SUuMXYkv40ZrpOP26E9qyUEp7MZIxzj6hl/BuLu9UYSnOl51Y4e8ZYG3z3MunPRc4zlUc2zQ9995d99/uzyUY99v1k3AgLjcoP0NWNr/bNVStI5OUYYf30HuP33+m9xkRmp/fmz1RucS5v8jlXp7AaxhZew/l5SKTkU8TcRZLx+dn/s3GNe3803vt8Zj/jM1D7ZmOr0UryDSjddVqtRpjPSTduUFSs6b03aYESIsiXEkG+dHItVo3+8k/NXmvMMtqnbYzG3tVUfj5F/JGVe1Za8oIxk7VdRG2jO12jHkY3q9L+gZZ8UFr4iHRwtfG86b3S7W+XvJvw2g+lb4cbj5vcI909pfT/oQHulpdj/BG3bLSUtMXYd/1jUvxo936+T+0xJtTavcyoX97Zc6+ZfIzlrOrGG+G+qLG55d2+n6TPh0jpiUYXxoRXpDYPX9k/alOPSdsWGZNMHf7t3H6TjxHmmt5r/D529bCK4rDZjBbIIxuMrthHNxoBPjvVuZx/iHEDOKqZsUU2MyZsKotxtVar8fM6P2SlHzcClWNt45rGY78i5ou5HJY8Y4xr0tb80L7V6AKfnnjx48y+Rq+3ClWkCtWMVQ0qVM3/Ws1obbPvD65c/rqw52UbN7k2z5P++u68MfomYzx9897G3woBIaV/r5wM6eCa/NboH43P2sWW+bILDD8v3EcbATo0/6s97AdFGP+u87LzZxzfWzCspxy6+PvZly7LzTTWJL8w2BemsLAfVt24MbHvJ+Nz5FTebAy7sQf3mOsZnw5cQQT5UiLIl57NZtP0X/Zr3OJtstmkG+tW1vsPtFJ48EXu6u/4RtrwkbH+rCX73P4K1aSG3Y1Wqto3lzxYbPnM6MKfnWp0R7v938b4q8v9Q3nLZ9IX/zD+mKjTSer1ydU3jheeLztN2rXUaPne9f25YBRcRer5gVS/i3vrd6HcLGPiyd3LjXqf3On8enCVc631cbcYoaU8s+QZvYN+/rckm1SlgXTfdPd3Gz5zwJgE9M+FzrNG+/gb39um90r1u7omNF3IZpPSjjmH9qMbpbOnC5b1DTICuzVXStrm/H+GncksVa5nfE/t4T6qWfHmY7FapbSj5wKW07bP+abSxVSodi7cV6yZvyyVfUmqmKJbcs8mG63r54f249ulvKxCCpukSrWNluqoZkbXZEdIr2bMSO2JN7kKk3nauOm0eb7RFd/OL9j4G6FFL2MG/Iu1QJ8vL0c6sv7czPqH1jlP5icZn6HaNxvLdqUnGTe+Uo8Yn9XUowW7iRfFN9D4WaQn6aJrlftVMH6GlWrnf61jzN9TqY6x9Jr9Z2m1GDeQUo8a3d9Tjxqr8KQezd+OFD/sV2tiXGOdjkYvxcAi5jgCUOYI8qVEkHedZduS9NS8jcrMsSiuagVNH9hGtSpfogtadroxyc72r42779nndQ0MCJPq3Wb8h13vtosH6KwU6ZvnjJlQJaNl/96pxhJMpbXnB2leP2N8f/VrpQcWMIYI5V/6cWnnt9KOr42x0udPLhUSJTW6Q7r5Oc8YI5188Fxr/d6VF/wxbTL+XVZvabRuWfOM4GzNM/5IP/+x47XCHucarZnRLYwx5DFtjaBU2m7GyQeNeToOrTWeX9df6vqa67rnusrJ3Uag37owf6WRfCYfo3UxMPzcFlTR+XlguBFaAisWLGe/GZt+4rzAnh/e05MK1sPsZ4Tx6tfmb9cZyyTZw5olzxjLmbjVmGHd3s38wkna7CpUOxfuo5ob13JhC+npfYXfHDj/e1Cx5nkBq5qUlmS0qCYfNLbiBLzgyucCflh1KfmQUfeUg4WX96uQ3/Og6bngXq1x2dxYKe9O75P++NRY3eH8YTghkcbKFy16GT/f82/aWy3GZ8TejfzgaqN1+3xh1+TPnH+zMZlfeI2L1yMr1QjMafYAfX7Qzw/TFy4X6R9yLqQXCOuRruuRc7GwHxh+7hr5+wUoNwjypUSQd60/j6bo4Vm/61hKliKC/fSf/q3VJraYYz/zcoyxWzsWG9v5XQh9/I0W8YZ3SA26O/9HdHCNtHCI8ceUyWxMZtdhWPHv0hfHkfXS7PuN/6ArxUkPLnTNTQLAlU7vM4L7jsXGv4vzW4IqxRnhvWEPY9yjp7ba5eVIh9cZLfW7l58bHlAWfIOkGtcZoT6mnXGDsCTjyLf9T/rySeNGY0CY1GOC0cpd3iVtyw/1nxecu6CkfAONLudnzxR8zeRjdImv3tII7NWvNYJrSXti2WzGTYHzw33SVmP2/ou1hp7P7Gv8TneErbhzLaUVa178ho7NZlxf8kHncJ+c/zjl4KXHr4fH5If180L71TwXQFFsNuP/483zjM/n+T04qjYyeuAFhBo3/Pavch5vLxk3U+zdyGt3NH7Grh7akptlBPuzZ6Twa4yhDYwJB1AIgnwpEeRdLyk1Sw/P+l1bjqTI38es1+9rpruvvaZkJ7Fajf+sd3xltNafPyGLyWyM42p0h/Ef5c//NlriKtYyZsOv2c61F2R3crf08d3GH2UhUVK/z93fNRZXN5vNCC07vjb+nRz/0/n16tcaN78a3mF0FfXGPyZTjxm9es4cMMKYj6/Rqmv2NcKX2cd47pO/z7Hf94Lnfkar6pHfjS63h9YVDAGSMeOyvcX+mrZGa/GFYSv3rLRkhLR+hvG8Rmvpvmmed/PP3v397BkjiJ6/nU0+73nyBV9TjJZLpxBtMiZStLeyV7/WCKtlOR43J9Poon5+y312qhGQL+zOHB7j2pu/FzqbnB/y88N96hGjVT6qmXHzwlsmc7yS8nKMXjp/zDNW3yisV4V/qDGhoz28V2vMzREA5QZBvpQI8mUjMydPz8zfpO/+NLpOPnVLXT1zW/2iZ7S/GJtNOrHzXKg/tqlgmea9pe5vXt4atyWRekz65B7p+DYpIFzqM1eKvbF057RajD/sTu02bkhEt/CM7s648mw2Y4KmY5vye658bXx27Ew+xuexYQ9jronwEt5AwzlWq9GF+9A6o1v8oXUFx+pLxu+Ba1qfC/cBYdL/Hs/vnm6Sbnpa6vzilZ8J3N2sViM0Z6UYczRUrFn2v59x9TqbbPSA+fMLSTajC3mdTsbEmGV5gwYASoEgX0oE+bJjtdr0+nc79OGPRtfMHi2q6837mivQr5Sz5CYfknZ+I23/yujq3uFZYz3SK+XsGWluH2O8nU+AMWlVozuKd9zJ3UY4OLkr/+tuo+vqhS0JIVHnxv1GtzQeF2fSJpRvZ/YbYxaz088tx2N/nJ1mhPTz9zm9nv/1wq7CvkHGxG8N75DqJ5TtMmZXu8zT0uHfja79h9ZKh9cbc2cUpkI16Z4Pjcn4AAAALkCQLyWCfNmb/9tBvfjFVuVZbbquZkX9p39rVQnx8GXccs9Knw02biiYzNIdE6RWA4yJmM7sLxjWT+2SMk4UfT6fAGPyG5vNaPUrbEma0Ohzod4e8An3l2azGbM/u3JpqJI4uVva9oX05/9cN547KEKq381YJizuFpYLchdLnjGcwd4V/9BaY/m0el2kuyYbk6IBAAAUgiBfSgT5K+PXPSf1j4/XKzUrT9dEBGn6wDaqH+nhy7hZ8qSv/ylt/MR4XinO6OZ84XI25wutLlWpayxxU6Ve/te6xvhM+3q+ORnGWM6jm4wu1Ec3Sif/KiLcV8+fKOra/JDfkvAgGeH96Abpz0VGd8vkA8aSO3U6SXGdjSV3ynLW8KLCu9nXGJ8bEGLMZOwfcu5xoftCjXo6Hue/5hfsnePdvUFedsknawMAAFcdgnwpEeSvnD0n0jV45m86cCpToQG+mtT3OnWs7+HLoNhs0vKx0qq3z+3zCzZa1y8M65XrXv4a9I5wv9EI+PZwX9iMzKHVjcmTqjU697VKA8kv8PLe21PYbEa3522LpG1fFr2kk2SsghDT7lywj2557kbK5Tq1J39N7kUFw3vtjlKTnkb3d7q+AwAAXPUI8qVEkL+yTmfk6B8fr9e6/adlMkkPXl9LzyU0UGigh08EdXSjMQa+cj0prMaVmRU3O/1cuHe03Bex3JLJbPQYiGxstEzbQ35EbOkDrDtZrdLh34xW923/M9bOtfMLNsaMN+5pLLd2eJ20Z4WxLFHKIefzBFY0ZjSO6yzV6WzMZl0c9vC+bZHxs7AjvAMAAOAiCPKlRJC/8rLzLBr95TbNXWe0mEaFBWpcz6aKb8x471LLTpOS/jRm1U/alv/1z8KX0ZKMidKqNjCW5IlsbAT8ak2MWfNNpvzx5dnnJmHLzTz3OOf8xxn5r+U/zsl/HBhu3CyIiM1f8qm2Mb67NN3CrVZjLLI9vKcdPfeaXwWpQVcjvNeNL3zsuM1mBPC9+aF+30/G7Nrni4g1An1cZ2P24/ODeFHh3eRjtPAT3gEAAHAJBPlSIsi7zy+7T2rEwi06eDpTknR782iN7tFEVUMZX+pSNpuUlmiE+vMD/okdxiRwhQnI/7eQkyHZLK6tT0CYFFHrvIAfey7oh8dIvv4Fj7FapINrjOC+/UtjbWs7/9DzwvutJZ/UzpJnjKffs8II94d/k6x55143mY2u99e0NlYqILwDAACglAjypUSQd6+zORZNWPaXpv68V1abFB7kpxdvb6T7W11zeWvOo/isFmOGfXsLvj3kn95T+MR6voFGd3X/kPwJ2Arb8idi869gfD172ngP+3Z+AC+MyWwMTTg/4KcdM5YaTE86Vy4gTGrQXWp8lzFruyvH/2enSft/MUL9nhUF1w43+Uh1OkpN7ia8AwAA4LIQ5EuJIF8+bD2Souc//0N/HjW6ON8QV1nj72mmWpXLcGZxFC43SzqzTzL7GV3T/SsYXdZ9fF1w7rPGzP7nh/vzt9zMoo8NCDeWW2t8l9Hl/UrNDJ5yRNr3ozEHQVQzwjsAAABKjSBfSgT58iPPYtW0Vfv09tK/lJ1nVaCfWc/E19dDN9WWr88VmDwO7mWzSenHLwj3+4zA3uB2owt7Yd3uAQAAAA9DkC8lgnz5s/9khv7viy36dc8pSVKT6mF6/d7maloj3M01AwAAAIDSK0kOpUkTHiG2SgXNfrid3rivucKD/PTn0VTdNfkXjf9mu87muHjiNQAAAAAoxwjy8Bgmk0l/ax2jpUNv1u3No2Wx2vThT3uVMOEn/bL7pLurBwAAAABXBEEeHqdaaKAmP3CdpvZvraiwQB08nam+/12r5xZsVnJmjrurBwAAAABliiAPj3Vb40gtHXqzHry+liRpwfrDin/7R32x8bBSzua6uXYAAAAAUDaY7K4QTHbneX7ff1ovLNyi3cfTHftqVAxSo+hQNYoOc2y1KgXLbGYtegAAAADlC7PWlxJB3jNl51n0wco9WvD7YR1JPltomSA/HzWIMsJ94/yQ3zA6TCEBLlgPHQAAAAAuE0G+lAjyni/lbK52HEvV9mOp2n4sTdsTU7UzMU3ZedZCy9esFOxovW8YFaYm1cN0TUSQTCZa7wEAAACUPYJ8KRHkvVOexar9pzLzw/25kJ+YmlVo+YrBfmpxTUW1jDG2FjEVVamC/xWuNQAAAICrAUG+lAjyV5czGTlGqE9McwT8XUnpyrEUbL2vWSlYLWLs4T5cTaqHK9DPxw21BgAAAOBNCPKlRJBHTp5VOxJTtelQsmPbeyKjQDlfs0kNo0ONFvv81vu4qiFMqAcAAACgRAjypUSQR2FSzubqj8PJ2nxeuD+ZXnDd+pAAXzW/JlwtYiqqUXSY6lSpoNgqFZhQDwAAAECRCPKlRJBHcdhsNh1JPqvNh1K06dAZbT6Uoi1HUnQ211Jo+WqhAapdpYLqVK2g2lUqqHaVENWuEqyYSsEK8KV7PgAAAHA1I8iXEkEelyvPYtVfSenadMhoud9zIl37TmboVEbBlns7s0m6JiI4P9yfH/QrqHp4EN30AQAAgKsAQb6UCPJwtZTMXO07laF9J9O170SG9p7M0P5TGdp3IkMZOYW34EtSgK9Z9SJDdH3tyrq+TmW1rVNJYYF+V7DmAAAAAK4EgnwpEeRxpdhsNp1Iy9bekxnal7/tPWEE/oOnM5Vrcf7naTZJTWuEq32dyro+rrLaxFZi7D0AAADgBQjypUSQR3mQZ7HqSPJZbTqUrDV7T2n1nlPafyrTqYyP2aRmNcLVPq6y2teprNaxEQr2J9gDAAAAnoYgX0oEeZRXx1LOOkL96r2ndOj0WafXfc0mtYipqPZ1Kqt9XGW1qhXBOvcAAACAByDIlxJBHp7i8JlMrd5zSmv2ntaavad0JNk52Pv7mNWyZkXdEFdZd7WsodpVKrippgAAAAAuhiBfSgR5eCKbzaZDp/Nb7PNb7RNTs5zKtImN0P2tYtS9eTRj6wEAAIByhCBfSgR5eAObzab9pzK1Zu8pffdnon7664Ss+f/ag/191K1ptO5vfY3a1a4kk4kl7gAAAAB3IsiXEkEe3igxJUsLNx7WZ78f1t6TGY79NSsF675W1+jeVteoRsUgN9YQAAAAuHoR5EuJIA9vZrPZtOHgGX3622F9/cdRxzr2JpN0U90quq/VNUpoEsUkeQAAAMAVRJAvJYI8rhaZOXn6dkuiFqw/pDV7Tzv2hwb66s4W1XV/6xi1uCacrvcAAABAGStJDjVfoToVafLkyYqNjVVgYKDatWundevWFVn2zz//1L333qvY2FiZTCZNmDChQJnRo0fLZDI5bQ0bNizDKwA8V7C/r+5tdY3mPdJePz3XWU/dWk81KgYpLStPs9ceVM/Jvyhhwk+a+tNenUjLdhxns9mUZ7EqK9eizJw8pWXlKjkzR6fSs3U8LUvHUs7q8JlMHTyVqb0n0rX7eJp2Jqbpz6MpOnQ6U1m5FjdeNQAAAODZ3Dpt9fz58zV06FBNmTJF7dq104QJE5SQkKCdO3eqWrVqBcpnZmaqTp06uv/++/XMM88Ued4mTZpo2bJljue+vszODVxKzcrBGnpbfT19az2t3ntKn/5+SEu2JuqvpHS98s12vfrtdvmaTcqz2uSKfjwVg/0UFRaoamGBigwNUFS48+PIsEBVCQmQj5neAAAAAMD53Jpw3377bQ0ZMkSDBg2SJE2ZMkWLFy/W9OnT9cILLxQo36ZNG7Vp00aSCn3dztfXV1FRUWVTacDLmc0m3Vi3im6sW0UpZ3P19R9HteD3w9p0KFm5lksneLNJ8jGbZDaZ5Gs2yWw2ycdsPDaZTEo9m6vsPKuSM3OVnJmrHYlpFz1X1dAARYYFqlpooKLCAxQZGqgaEUGqHxmquKohCvJnLD8AAACuLm4L8jk5OVq/fr1GjBjh2Gc2mxUfH6/Vq1eX6ty7du1S9erVFRgYqPbt22v8+PGqWbNmkeWzs7OVnX2u23Bqamqp3h/wFuFBfurbrpb6tqulk+nZyrVY5WM2ycdkhHP7Zg/tPvlh/WJsNptSzuYqKTVbSalZSkzN0vHULCWlZjs9PpGeLYvVll8uW1JKgXOZTMas+/Wqhap+ZIjqR4aqXmSI4qqGMFkfAAAAvJbbgvzJkydlsVgUGRnptD8yMlI7duy47PO2a9dOM2fOVIMGDXTs2DGNGTNGHTp00NatWxUaGlroMePHj9eYMWMu+z2Bq0GVkACXnMdkMqlisL8qBvurQVTh/yYlyWK16VR6tiPgJ+WH/MTULB04lam/ktJ0JjNXB05l6sCpTC3bnuQ41mySalWucF64N4J+7SoVFOBLwAcAAIBn87rB4926dXM8bt68udq1a6datWrp008/1UMPPVToMSNGjNDQoUMdz1NTUxUTE1PmdQVQNB+zSdXyx9A3U3iB1202m06m52hXUpr+SkrTX8fT8x+nK+VsrvadzNC+kxn67s8kp3PGVg52dMuvVMFfFYP9VDHYT+FB+Y+D/BQe5CdfH7fPBQoAAAAUym1BvkqVKvLx8VFSUpLT/qSkJJeOb69YsaLq16+v3bt3F1kmICBAAQGuaW0EcGWYTCZVDQ1Q1dAA3VC3imO/zWbTibRs/ZWUrr+S0rQrf8b8XUnp+v/27j1GqurwA/j3zvv92vcuyy64gIBlkeUhFX6orCJtaGlpagnR1TQxtguREtNWU0FTE0xLKjVV+lT/sIrFBGuNYnBb8RERhS5FWJCX+37vvN8z9/7+uDMXhl1g1wVmhv1+ktv7nJkz48mW7z3nnuOPJnC6P4jT/cHLvr9Vr4E9FfIdRh3sRq28bzzvmEkLp0kHp0kLp1kHB28AEBEREdE1kLUgr9PpUFdXh6amJqxevRoAIIoimpqasH79+iv2OYFAAKdPn8a99957xd6TiHKXIJxryV8yLTPg9/gi+LJXbrlvHQzBE5anzfOG46nB92LwRRIAAH80AX80gQ53eEyfbzVoUi39csB3mc5tO826jODvNMm9APg8PxERERGNRVa71m/atAkNDQ2YP38+Fi5ciO3btyMYDCqj2N93332oqKjA1q1bAcgD5B07dkzZ7uzsRHNzMywWC2pqagAAjzzyCFatWoWqqip0dXVhy5YtUKvVWLt2bXa+JBHlBEEQUGY3osxuxLLpRRe9LpEU4Y8klJDvCcfhDZ3b9oTiqeAfgzt0bu0NxwEA/kgC/kgCrYOhUZfNatCgLDXlXqnNIG/bDcqxMrsRTpP2sgMJEhEREdHEkNUgf88996C/vx+bN29GT08P5s6diz179igD4LW1tUGlOtdNtaurCzfffLOyv23bNmzbtg3Lli3D+++/DwDo6OjA2rVrMTg4iKKiIixZsgT79+9HUdHF/+FORJSmUavk1nKzDoB51K9LJEV4w3El3A8FY/CE4nCHYhgKxeAJytueUFzeT90ASIpSKvwH8GVv4KLvr9OoUGLTo8xmzAj5pTYDSu0GFFv1cJl1MOnUDPxERERE1zlBkqTLTww9wfh8Ptjtdni9XthstmwXh4iuU5IkwRdJoN8fQY83im5vGL2+CLq9EWVqvh5vBAOB2KjfU6dWwWlOP7uvUwb0S3f3d41wzqLXMPwTERERZdlYcuh1N2o9EVG+EARBHkTPqEVN8cWn4oslRPSmpuBTQr43gm5fBL1e+Vh/IIpYQkQsKaLXJ0/bN1patQCnSQebUQtAvsEgAUDqNq903jFJAiRISN8CPreWzwsAiqx6VDiNqHAYMclpQoXDiAqnEZOcRlgN2jH+SkRERER0IbbIj4At8kSUbyRJQjiehDsUhzsYk7v0B2Opbblbf/qc3O1f7vIfiYvXtJw2gwYVThMmKUHfmNo2ocLJsQCIiIho4mKLPBHRBCMIAkw6DUw6DSocxlG/LhxLKqHfnxqxXxDklnVBEJDO1ELqOCBknlc+HxAgQJQk9Poi6HCH0ekJo9MdRocnhE53GO5QHL5IAr5uH1q6fSOWx6RTo8JhhNOsg0GrhlGrglGrhlGnhl4jr41aeTHo1DBoVBnH9Km1UaeG06SFw6T7mr8oERERUe5ikCcimsCMOjWMOiPKxxD+v65gNHFeuA+jwy0H/E5PGB3uMPr9UYRiSZzsu/igf2PlMutQU2TBDcUW3FBkRk2xBTXFFpTbjVCp2PJPRERE+Yld60fArvVERNdeJJ5EtzeCDncIvnACkXgS4XhSXseSiCSSCMdE5Vj6vHxORCSW2k+dS/cwGIlRq8bUdLBPBf2aYguqC8zQaVQXfR0RERHR1cKu9URElHcMWjWmFJoxpXD00/5dSiiWwJn+IE71BXC6P4BTffLy1WAQ4XgSR7t8ONqV2cVfrRIw2WXCDUVysL+hyIypRfJ6onbT94bj6HCH0D4k96LwRxJYNMWFBVNc0Kp504OIiCgb2CI/ArbIExFdvxJJEW1DITnY9wdwui+YWgcQiF68Fd9l1mFqoRlTU+Fe3rZgssuU1634vkgcHamQ3uEOoz21lpfQRXs2WA0aLJtehPqZJbhtRtGEvdFBRER0pYwlhzLIj4BBnoho4pEkCX3+qNJyn27FP9MfRI8vctHXpVvxp6Z6E0wtsqTCvhlFFn1WR+GXJAlDwRi6vRF0esLo8pwL6OkWdt8lHkFIKzDrUjMMmKBVC/jw5AAGgzHlvFoloK7KifqZxVg+swQ3FFmu5tciIiK6LjHIjxODPBERnS8YTeDsQBBnBoI40y+H+zMD8joUS170dVa9Rg70VgNcZi2cZh1cJh1cZnlJ7zvNOtgMmjGHfn8kjm5vBF2esLLu8kTQ7Q0rx6KJy08x6FKCuhzWJzmNqExPE+g0wqTLfBIvKUpobvegqaUXTS19ONHrzzg/pdCM5TfKoX5BtRMadsEnIiK6LAb5cWKQJyKi0ZAkCb2+KM70B3D6gpDf4Q5jLP8Pq1YJcJp0cuA3ZQZ9h0mLSDyJrnRo90TQ5Q1fckC/8xVa9KhwGFBmN6LSdS6sp9dm/fiGzGkfCsmh/ngf9p8ZRDx57ovbDBrcNqMYy2cW47bpxbCbtOP6LCIiousVg/w4McgTEdF4ReJJtA2FcHYgiMFADO5QDEPBGNzBGIZS2+n94CVa9S/HZtCg3CFPIVhmN2Ssy+1GlNj10GvUV/CbXZo/EseHJwfwXksv/nO8D+5QXDmnVglYUO1E/cwSzK10oKbYwmfriYiIUhjkx4lBnoiIrqVIPAlPKC4H+3Tgzwj+ceg1qlQ4N6DMYVRa2Mfbmn41JUUJ/21z472WPjS19OJkX2DYNYUW3XmzBMjrmmILyuyGrI4vQEREdK0xyI8TgzwREdGV1zoYRFNLHz442Y8ve/zo8l58EEGzTo0bzgv36XVVgYnT3hER0XWJQX6cGOSJiIiuvmA0ocwOkF6f6gugdTCEhDjyP080KgHVhWbcUGSGw6hDUpKQFM8tCVFEUgSSooikJK8TSQmiJCEhZl6bFCXoNCqU2eUeDhVOo/KYwiSHEYUWPVQq9gogIqJrg0F+nBjkiYiIsieeFNE6GMSpvmBGwD/dH7jkLAFXmlYtpEK+HO4rHPLYA0rgtxth1F278QeIiOj6NpYcmrsP1hEREdGEpFWrUFNsRU2xNeO4KEro8UWUYB+KJaBWqaBRCVCphIy1WiVALQjQqAWohPOOXbBE4kl0etJT94XR6ZbXPb4I4kkJbUMhtA2FLlrWArMOpXYDXGYdHCYdnCYtHEYtHKnZBpwmHeyptcOohc2ohXoMrfyhWAKDgRgGgzEMBqKpdQxDwahyfOi8cw6TFnVVTsyb7MT8ahdmldmg0/BRBCKi6w1b5EfAFnkiIqKJLZEU0euPKsG+03PB2h3+WrMNCAJgM2jlwH9e2LcZNAhEk3JAT4X1wWAUkbg4ru+h16hQW+lAXZUT81MB32m+8jMFSJIEdyiOrwaDaB2UZ2qoKbagdpLjqnxePhFFCaf75UdGaisdKLLqs10kIspR7Fo/TgzyREREdCmSJMEXTqDTE0aPLwx3MA5POA5PKAZPKA53KAZvWF57QnF4QnEEoomv9Vl6jQqFFj1cZh0KLDoUmPWptQ4us0455zLr0OUJ42CbGwe/cuNgmxue86b/S7uhyJwK9i7Mq3LihiLzqGYIkCQJ/f4ovhoMKYH9q8EQWgeDaB0IwX+R7zfZZUJtpQO1k+yorXRgdrkNJt312yk0GE3gcLsHB1vl/waHWt3wReTfRhCAmysduHNWKe6cVYwbiiycnYGIFAzy48QgT0RERFdaPCnCE4rDG47BnQr37lAM3lAc3nAcJr0ahebhgd2kU3+tsCdJEs4MBOVQ3+rG561DON0fHHadw6RF3WQn5qVa7csdRrS7Q2hNB/aBdHAPIRy/dC+EcrsBVQVmOM1aHO/248zA8M9TCcD0EitqJzlQW+nAnEl2zCi15uVsBJIkocMdxqE2+Tc+2OpGS7cPF47VaNDK00eeueD3n1JoRv3MYtTPLEFdlROaPPwNiOjKYZAfJwZ5IiIiuh65g7GM0Hm4wzOm7vsqAZjkNKGqQF6qC8yoKjCjusCESpcJBm3m4H/ecBxHOrw43OHB4XYPDnd40OuLDntfvUaF2eW2VMu9HPCrC0w511odTSRxtMuHQ63nfsM+//DvU+EwYl6VE3WTHaircuHGMvlGRbc3jPda+vDesV58cnoQseS5395p0uL2G4tx58wS/N/0Ipj112+vBSIaGYP8ODHIExER0UQQS4ho6fbh81a5C/jnrUMYDMQw2ZUO63JIryo0o7rAjAqHcdyD5/V4Izjc4cH/Ojw43C6HfH9keLd8q0EDu1ELQO6SLkBQtgFAAJSgLyj/M/y4WiVAq1ZBq06vz9vWqKBVXWRbndrXqDAUjOFQqxv/6/Qilsi88aFVC5hVbkfdZKc80GCVA2V242V/h0A0gQ++7Md7x3rx7xN9GY9B6NQqfLOmAPUzS3DnrBKU2Ayj/n2JKH8xyI8TgzwRERFNVJIkXdOWcFGU8NVgMNVqLwf7o12+YYE5VxSYdXJre2r5RoV9WE+EsUokRXze6sZ7x3qxt6UXrYOZMyXMmWTHnTNLUD+rBDeWWrPaU0GSJPT6ouhwy49ahGNJRBIiIrEkIonUflxUtqPnHQvHk4goiwhRkjC30oGl04uwpKYQrgk+MCIRg/w4McgTERERZU8sIeLMQACRuAhJkpD+x6r8r1bpvG15T9m+4FoJEkRRHp9AXiTEkyJiSRGJ1PaF+7GkiHhCQkJMnUtIMOpUuLlSDu5VV7nLvyRJONUXwN6WXrx3rBf/bffg/H+tWw0azCqzYVa5DbPL7ZhVZkNNseWqTDMoSRK6vBEc6fDiaJcXRzq9+KLTh4HA8McJxksQgJvK7Vg6rRBLpxVhXpUDes34bpAQ5RsG+XFikCciIiKiXNDnj+A/x/uw91gfPjrVP+KYBjq1CtNKLErAn1Vmw8xyG2wG7ag/Jz1wnxzW5dB+tMuHoWBs2LXpsRJMOjWMOjUMGjUMWtW57fOPadUwaNPHVDBo1cqxaCKJ/WcG8eHJARzv8Wd8hlGrxi1TXVg6rQj/N72QI/zThMAgP04M8kRERESUa2IJEaf7Azja5cOxLh+OdXtxrMunTG93ockuE2aV2TC7PBXwy20otRkgSUDbUEgO7V1ycP+i0wdvePh0hRqVgGklVnyjwoabKuy4qcKOmaU2GHVXtrW8zxfBR6cG8OHJAXx4sh8DgcwbCGV2A5bUFF7RbviReBL+SAL+SBxatQpFVv24H5MgGg8G+XFikCciIiKifJBuST/WLYf7o10+tHT70OkJj3i9y6xDPCmOOMCgVi1gRqkV36iwY3a5Hd+okKcGvNbhVhQlHO/x46NT/fjw5AA+PTuUMWZCuhv+kmmFWFpTCItBowRyXyQBfyQBXziuHPNHEvBH0/vnrhtpHAarQYMiix6FVj2KrHoUWVLr8/aLrfI0kZwukK40BvlxYpAnIiIionzmCcWUcC+33vtwsi+AZGqSe51GhZllNtxUbsM3Ui3t00usV+VZ+/GKxJM4cHYIH50awAdf9g/rhj9eFr0GsaQ4pgEWBUEe+LBwhKB/4Q0Au1F71R8LiMSTGArGMBSMwRuOQyUIMOrkxxiMWjUMOpWyzRsQuYtBfpwY5ImIiIjoehOJJ3GqLwC1SkBNsQXaPA106W74H6Va60VJgtWggdWgvWCtgc2ghe0i56wGLSx6DdQqAZIkwRdJYCAQRb//vGWE/cFAFOIYEpRWLWQE+4zwf8GNAJNOg0g8CU8ojqFgDO5QTFm7g/GM/aFgTLkuHE+OqTzpsQrSYX+kfZdZi8kuEypdJkx2mVDhNF6TAQglScJQMIYOdxidnjB6fRFIkjyVpLIIAlQqAWoVoBIEaFQqZVutSp0TBGjS2yoBFr0GM8tyO9sxyI8TgzwREREREY0kKcpBMx3sB1LrPl/03I2A1HqkcQcuRadWIZb8elMvatUCnCYdHCYtJAnKdH/hWBKheBLjTX2CAJTaDEqwTy/p/UKLblQ9D0RRQn8gig53GB3uEDo9YXS6w0pw73SHx3RjYrRuqrDhrQ1Lr/j7XkljyaGaa1QmIiIiIiKivKdWCUoL+uVEE0kMBOTQP3CRFv70djieVEK8RiXAYdLBZdbCadLBZdbBadbBabpwXweXSQenWe5dcLEgLUkSoglRDvapcH8u6IvysXgSkdTxUCyJfn8UbUMhdLhDaBsKIRRLotsbQbc3ggNnh4Z9hlGrRqXLmBHurQYtuj3nQnqHO4QuT2RUNyuKrXpMchpRZjdCEABRkpAUJSRFeTshShDF1DEptX3eOpGUlNeIElDhMF72M/MJgzwREREREdFVoNeoUeEwjipEBqMJuEMx2IxaWC8Ryr8OQZC70xu0aji+xuslScJgMIa2oRDah0JoGwyhPRXw24fC6PLKrehf9gbwZW/gsu+nEoAyu/y7THIaUeFMrR1yF/4yu4EzCFwGgzwREREREVGWmfUamPW5Gc8EQUChRX6+f95k57DzsYSITk9YCfrtQ3LI90XiKLeng7pJCe6ldkPejtGQK3KzphAREREREVFe0GlUmFJoxpRCc7aLMmHwNggRERERERFRHmGQJyIiIiIiIsojDPJEREREREREeYRBnoiIiIiIiCiPMMgTERERERER5REGeSIiIiIiIqI8wiBPRERERERElEcY5ImIiIiIiIjyCIM8ERERERERUR5hkCciIiIiIiLKIwzyRERERERERHmEQZ6IiIiIiIgoj2Q9yD/33HOorq6GwWDAokWLcODAgYtee/ToUaxZswbV1dUQBAHbt28f93sSERERERER5ZOsBvnXXnsNmzZtwpYtW3Do0CHU1tZixYoV6OvrG/H6UCiEqVOn4umnn0ZpaekVeU8iIiIiIiKifCJIkiRl68MXLVqEBQsW4A9/+AMAQBRFVFZWYsOGDfjlL395yddWV1dj48aN2Lhx4xV7zzSfzwe73Q6v1wubzTb2L0ZEREREREQ0BmPJoVlrkY/FYjh48CDq6+vPFUalQn19PT755JNr+p7RaBQ+ny9jISIiIiIiIspFWQvyAwMDSCaTKCkpyTheUlKCnp6ea/qeW7duhd1uV5bKysqv9flEREREREREV1vWB7vLBY8++ii8Xq+ytLe3Z7tIRERERERERCPSZOuDCwsLoVar0dvbm3G8t7f3ogPZXa331Ov10Ov1yn562AB2sSciIiIiIqJrIZ0/RzOMXdaCvE6nQ11dHZqamrB69WoA8sB0TU1NWL9+fVbf0+/3AwC72BMREREREdE15ff7YbfbL3lN1oI8AGzatAkNDQ2YP38+Fi5ciO3btyMYDOKBBx4AANx3332oqKjA1q1bAciD2R07dkzZ7uzsRHNzMywWC2pqakb1nqNRXl6O9vZ2WK1WCIJwhb/1lePz+VBZWYn29naOrk95gXWW8gnrK+Ub1lnKJ6yvlG+uRZ2VJAl+vx/l5eWXvTarQf6ee+5Bf38/Nm/ejJ6eHsydOxd79uxRBqtra2uDSnXuMf6uri7cfPPNyv62bduwbds2LFu2DO+///6o3nM0VCoVJk2adGW+5DVgs9n4B5DyCuss5RPWV8o3rLOUT1hfKd9c7Tp7uZb4tKzOI0/jw/nuKd+wzlI+YX2lfMM6S/mE9ZXyTa7VWY5aT0RERERERJRHGOTzmF6vx5YtWzJG3CfKZayzlE9YXynfsM5SPmF9pXyTa3WWXeuJiIiIiIiI8ghb5ImIiIiIiIjyCIM8ERERERERUR5hkCciIiIiIiLKIwzyRERERERERHmEQT6PPffcc6iurobBYMCiRYtw4MCBbBeJCADwwQcfYNWqVSgvL4cgCHjjjTcyzkuShM2bN6OsrAxGoxH19fU4efJkdgpLE97WrVuxYMECWK1WFBcXY/Xq1Thx4kTGNZFIBI2NjSgoKIDFYsGaNWvQ29ubpRLTRLZjxw7MmTMHNpsNNpsNixcvxjvvvKOcZ12lXPb0009DEARs3LhROcY6S7nkiSeegCAIGcuNN96onM+l+sogn6dee+01bNq0CVu2bMGhQ4dQW1uLFStWoK+vL9tFI0IwGERtbS2ee+65Ec//5je/wbPPPos//vGP+PTTT2E2m7FixQpEIpFrXFIiYN++fWhsbMT+/fuxd+9exONx3HXXXQgGg8o1P/vZz/Cvf/0Lu3btwr59+9DV1YXvf//7WSw1TVSTJk3C008/jYMHD+Lzzz/HHXfcge9+97s4evQoANZVyl2fffYZ/vSnP2HOnDkZx1lnKdfMnj0b3d3dyvLRRx8p53KqvkqUlxYuXCg1NjYq+8lkUiovL5e2bt2axVIRDQdA2r17t7IviqJUWloq/fa3v1WOeTweSa/XS6+++moWSkiUqa+vTwIg7du3T5IkuX5qtVpp165dyjUtLS0SAOmTTz7JVjGJFE6nU/rrX//Kuko5y+/3S9OmTZP27t0rLVu2THr44YclSeLfV8o9W7ZskWpra0c8l2v1lS3yeSgWi+HgwYOor69XjqlUKtTX1+OTTz7JYsmILu/s2bPo6enJqL92ux2LFi1i/aWc4PV6AQAulwsAcPDgQcTj8Yw6e+ONN2Ly5Mmss5RVyWQSO3fuRDAYxOLFi1lXKWc1Njbi29/+dkbdBPj3lXLTyZMnUV5ejqlTp2LdunVoa2sDkHv1VXPNP5HGbWBgAMlkEiUlJRnHS0pKcPz48SyVimh0enp6AGDE+ps+R5Qtoihi48aNuPXWW3HTTTcBkOusTqeDw+HIuJZ1lrLlyJEjWLx4MSKRCCwWC3bv3o1Zs2ahubmZdZVyzs6dO3Ho0CF89tlnw87x7yvlmkWLFuGll17CjBkz0N3djSeffBJLly7FF198kXP1lUGeiIgopbGxEV988UXG83BEuWbGjBlobm6G1+vF66+/joaGBuzbty/bxSIapr29HQ8//DD27t0Lg8GQ7eIQXdbKlSuV7Tlz5mDRokWoqqrCP/7xDxiNxiyWbDh2rc9DhYWFUKvVw0ZI7O3tRWlpaZZKRTQ66TrK+ku5Zv369Xjrrbfwn//8B5MmTVKOl5aWIhaLwePxZFzPOkvZotPpUFNTg7q6OmzduhW1tbX4/e9/z7pKOefgwYPo6+vDvHnzoNFooNFosG/fPjz77LPQaDQoKSlhnaWc5nA4MH36dJw6dSrn/sYyyOchnU6Huro6NDU1KcdEUURTUxMWL16cxZIRXd6UKVNQWlqaUX99Ph8+/fRT1l/KCkmSsH79euzevRv//ve/MWXKlIzzdXV10Gq1GXX2xIkTaGtrY52lnCCKIqLRKOsq5Zzly5fjyJEjaG5uVpb58+dj3bp1yjbrLOWyQCCA06dPo6ysLOf+xrJrfZ7atGkTGhoaMH/+fCxcuBDbt29HMBjEAw88kO2iESEQCODUqVPK/tmzZ9Hc3AyXy4XJkydj48aNeOqppzBt2jRMmTIFjz/+OMrLy7F69ersFZomrMbGRrzyyiv45z//CavVqjznZrfbYTQaYbfb8eMf/xibNm2Cy+WCzWbDhg0bsHjxYtxyyy1ZLj1NNI8++ihWrlyJyZMnw+/345VXXsH777+Pd999l3WVco7ValXGG0kzm80oKChQjrPOUi555JFHsGrVKlRVVaGrqwtbtmyBWq3G2rVrc+5vLIN8nrrnnnvQ39+PzZs3o6enB3PnzsWePXuGDSBGlA2ff/45br/9dmV/06ZNAICGhga89NJL+PnPf45gMIgHH3wQHo8HS5YswZ49e/j8HGXFjh07AAC33XZbxvEXX3wR999/PwDgmWeegUqlwpo1axCNRrFixQo8//zz17ikREBfXx/uu+8+dHd3w263Y86cOXj33Xdx5513AmBdpfzDOku5pKOjA2vXrsXg4CCKioqwZMkS7N+/H0VFRQByq74KkiRJWflkIiIiIiIiIhozPiNPRERERERElEcY5ImIiIiIiIjyCIM8ERERERERUR5hkCciIiIiIiLKIwzyRERERERERHmEQZ6IiIiIiIgojzDIExEREREREeURBnkiIiIiIiKiPMIgT0RERFkhCALeeOONbBeDiIgo7zDIExERTUD3338/BEEYttx9993ZLhoRERFdhibbBSAiIqLsuPvuu/Hiiy9mHNPr9VkqDREREY0WW+SJiIgmKL1ej9LS0ozF6XQCkLu979ixAytXroTRaMTUqVPx+uuvZ7z+yJEjuOOOO2A0GlFQUIAHH3wQgUAg45oXXngBs2fPhl6vR1lZGdavX59xfmBgAN/73vdgMpkwbdo0vPnmm8o5t9uNdevWoaioCEajEdOmTRt244GIiGgiYpAnIiKiET3++ONYs2YNDh8+jHXr1uFHP/oRWlpaAADBYBArVqyA0+nEZ599hl27duG9997LCOo7duxAY2MjHnzwQRw5cgRvvvkmampqMj7jySefxA9/+EP873//w7e+9S2sW7cOQ0NDyucfO3YM77zzDlpaWrBjxw4UFhZeux+AiIgoRwmSJEnZLgQRERFdW/fffz9efvllGAyGjOOPPfYYHnvsMQiCgIceegg7duxQzt1yyy2YN28enn/+efzlL3/BL37xC7S3t8NsNgMA3n77baxatQpdXV0oKSlBRUUFHnjgATz11FMjlkEQBPzqV7/Cr3/9awDyzQGLxYJ33nkHd999N77zne+gsLAQL7zwwlX6FYiIiPITn5EnIiKaoG6//faMoA4ALpdL2V68eHHGucWLF6O5uRkA0NLSgtraWiXEA8Ctt94KURRx4sQJCIKArq4uLF++/JJlmDNnjrJtNpths9nQ19cHAPjJT36CNWvW4NChQ7jrrruwevVqfPOb3/xa35WIiOh6wiBPREQ0QZnN5mFd3a8Uo9E4quu0Wm3GviAIEEURALBy5Uq0trbi7bffxt69e7F8+XI0NjZi27ZtV7y8RERE+YTPyBMREdGI9u/fP2x/5syZAICZM2fi8OHDCAaDyvmPP/4YKpUKM2bMgNVqRXV1NZqamsZVhqKiIjQ0NODll1/G9u3b8ec//3lc70dERHQ9YIs8ERHRBBWNRtHT05NxTKPRKAPK7dq1C/Pnz8eSJUvw97//HQcOHMDf/vY3AMC6deuwZcsWNDQ04IknnkB/fz82bNiAe++9FyUlJQCAJ554Ag899BCKi4uxcuVK+P1+fPzxx9iwYcOoyrd582bU1dVh9uzZiEajeOutt5QbCURERBMZgzwREdEEtWfPHpSVlWUcmzFjBo4fPw5AHlF+586d+OlPf4qysjK8+uqrmDVrFgDAZDLh3XffxcMPP4wFCxbAZDJhzZo1+N3vfqe8V0NDAyKRCJ555hk88sgjKCwsxA9+8INRl0+n0+HRRx/FV199BaPRiKVLl2Lnzp1X4JsTERHlN45aT0RERMMIgoDdu3dj9erV2S4KERERXYDPyBMRERERERHlEQZ5IiIiIiIiojzCZ+SJiIhoGD55R0RElLvYIk9ERERERESURxjkiYiIiIiIiPIIgzwRERERERFRHmGQJyIiIiIiIsojDPJEREREREREeYRBnoiIiIiIiCiPMMgTERERERER5REGeSIiIiIiIqI88v/HRYwcA6KO4wAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# 1. Gráfico de la Pérdida (Loss) de Entrenamiento y Validación\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(history.history['loss'], label='Training Loss')  # Pérdida en entrenamiento\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')  # Pérdida en validación\n",
    "plt.title('Training and Validation Loss over Epochs')  # Título del gráfico\n",
    "plt.xlabel('Epochs')  # Etiqueta del eje X\n",
    "plt.ylabel('Loss')  # Etiqueta del eje Y\n",
    "plt.legend()  # Leyenda\n",
    "plt.show()\n",
    "\n",
    "# 2. Gráfico del MAE (Mean Absolute Error) de Entrenamiento y Validación\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(history.history['mae'], label='Training MAE')  # Error absoluto medio en entrenamiento\n",
    "plt.plot(history.history['val_mae'], label='Validation MAE')  # Error absoluto medio en validación\n",
    "plt.title('Training and Validation MAE over Epochs')  # Título del gráfico\n",
    "plt.xlabel('Epochs')  # Etiqueta del eje X\n",
    "plt.ylabel('Mean Absolute Error (MAE)')  # Etiqueta del eje Y\n",
    "plt.legend()  # Leyenda\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Evaluate your model:\n",
    "- See the result of your loss function.\n",
    "- What can you deduct from there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 680us/step - loss: 0.0597 - mae: 0.1940\n",
      "Test Loss: 0.05897882208228111\n",
      "Test MAE: 0.19408905506134033\n"
     ]
    }
   ],
   "source": [
    "# Evaluar el modelo en el conjunto de prueba\n",
    "test_loss, test_mae = model.evaluate(X_test, y_test)\n",
    "\n",
    "# Imprimir los resultados de la evaluación\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test MAE: {test_mae}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Loss (Pérdida): La función de pérdida me indica qué tan bien se ajusta mi modelo a los datos de prueba. Un valor de 0.0597 sugiere que mi modelo tiene una baja pérdida, lo cual es una buena señal de que está bien entrenado.\n",
    "\n",
    "Test MAE (Error Absoluto Medio): Con un valor de 0.1940, sé que en promedio, las predicciones de mi modelo están a 0.194 del valor real del GPA. Como el GPA está generalmente entre 0 y 4, este error promedio es bastante bajo, lo que indica que mi modelo está haciendo predicciones precisas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. Use your model to make some predictions:\n",
    "- Make predictions of your X_test dataset\n",
    "- Print the each of the predictions and the actual value (which is in y_test)\n",
    "- How good was your model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 654us/step\n",
      "Prediction: 1.6527546644210815, Actual: 1.4277243762746905\n",
      "Prediction: 2.989314556121826, Actual: 3.117354434785501\n",
      "Prediction: 1.7553740739822388, Actual: 2.037768574636005\n",
      "Prediction: 3.453036308288574, Actual: 3.5485205508668662\n",
      "Prediction: 0.2825004458427429, Actual: 0.2489771312307257\n",
      "Prediction: 2.859912872314453, Actual: 2.627693905554347\n",
      "Prediction: 1.7579351663589478, Actual: 2.057378500596372\n",
      "Prediction: 2.629941701889038, Actual: 2.248337588471201\n",
      "Prediction: 2.0545098781585693, Actual: 2.1947065208246226\n",
      "Prediction: 1.0930639505386353, Actual: 0.7581829737450007\n",
      "Prediction: 2.6739280223846436, Actual: 2.370893096932428\n",
      "Prediction: 0.7594481706619263, Actual: 0.7664048694920337\n",
      "Prediction: 3.2146668434143066, Actual: 2.952721567213245\n",
      "Prediction: 2.499385118484497, Actual: 2.3433313526833226\n",
      "Prediction: 2.789438486099243, Actual: 2.7718106588704914\n",
      "Prediction: 0.4852260947227478, Actual: 0.2878673233291232\n",
      "Prediction: 1.0356040000915527, Actual: 1.0182646498699195\n",
      "Prediction: 1.4579066038131714, Actual: 1.629355895809393\n",
      "Prediction: 1.9386385679244995, Actual: 2.0744387503601613\n",
      "Prediction: 2.9568257331848145, Actual: 2.423800751639832\n",
      "Prediction: 1.9205330610275269, Actual: 1.7562115530004156\n",
      "Prediction: 1.6273301839828491, Actual: 1.5662885180613493\n",
      "Prediction: 1.724303960800171, Actual: 1.7062124885863237\n",
      "Prediction: 3.3416826725006104, Actual: 3.161436270258364\n",
      "Prediction: 1.7793443202972412, Actual: 1.733364046560005\n",
      "Prediction: 0.6037267446517944, Actual: 0.8419632253726905\n",
      "Prediction: 1.8395148515701294, Actual: 1.3791671997209602\n",
      "Prediction: 2.5642166137695312, Actual: 3.026983310961493\n",
      "Prediction: 2.0417611598968506, Actual: 2.191998419606377\n",
      "Prediction: 1.8318079710006714, Actual: 2.315769874969324\n",
      "Prediction: 1.947608470916748, Actual: 2.068111784968204\n",
      "Prediction: 1.0636050701141357, Actual: 0.869123386308555\n",
      "Prediction: 2.9035520553588867, Actual: 2.900096239205548\n",
      "Prediction: 3.195265293121338, Actual: 3.468581349135728\n",
      "Prediction: 1.3052985668182373, Actual: 1.5674124377048069\n",
      "Prediction: 1.9542382955551147, Actual: 1.7946671055341392\n",
      "Prediction: 3.015209674835205, Actual: 3.1813076022771107\n",
      "Prediction: 3.1838512420654297, Actual: 2.8973550040674096\n",
      "Prediction: 3.1671066284179688, Actual: 3.2448822032661777\n",
      "Prediction: 0.8930972814559937, Actual: 0.3578088919508027\n",
      "Prediction: 2.58906888961792, Actual: 2.6523548127186087\n",
      "Prediction: 3.4920737743377686, Actual: 3.680961344427839\n",
      "Prediction: 1.482556700706482, Actual: 1.0363787383257312\n",
      "Prediction: 2.365177631378174, Actual: 2.017218038843316\n",
      "Prediction: 1.1002230644226074, Actual: 0.9633750092514732\n",
      "Prediction: 2.7212510108947754, Actual: 2.23946398594873\n",
      "Prediction: 2.962344169616699, Actual: 2.735960967147571\n",
      "Prediction: 1.1650645732879639, Actual: 1.3619328272119078\n",
      "Prediction: 2.827343463897705, Actual: 2.70295861751592\n",
      "Prediction: 1.4535845518112183, Actual: 1.441918756451196\n",
      "Prediction: 3.2059366703033447, Actual: 3.219531247903172\n",
      "Prediction: 3.2598156929016113, Actual: 3.339094362200312\n",
      "Prediction: 1.821527123451233, Actual: 1.556218796080208\n",
      "Prediction: 1.1862465143203735, Actual: 1.3423871779577343\n",
      "Prediction: 1.7899249792099, Actual: 1.756186167808898\n",
      "Prediction: 3.411710500717163, Actual: 3.421837670026282\n",
      "Prediction: 2.5588269233703613, Actual: 2.3169599744650875\n",
      "Prediction: 3.4039957523345947, Actual: 3.286585133610396\n",
      "Prediction: 1.0183066129684448, Actual: 0.684651926072042\n",
      "Prediction: 2.161843776702881, Actual: 2.1370681063433614\n",
      "Prediction: 1.7665830850601196, Actual: 1.6884896091579062\n",
      "Prediction: 2.0313665866851807, Actual: 2.1962173498725552\n",
      "Prediction: 2.4069485664367676, Actual: 2.4777903742896354\n",
      "Prediction: 1.3773614168167114, Actual: 1.1979333311054492\n",
      "Prediction: 0.9907341003417969, Actual: 0.9881530769380218\n",
      "Prediction: 2.2939231395721436, Actual: 1.8589248556209292\n",
      "Prediction: 3.6222951412200928, Actual: 3.040729612939948\n",
      "Prediction: 2.8019113540649414, Actual: 2.3741309720150148\n",
      "Prediction: 1.1079131364822388, Actual: 1.2212994205081906\n",
      "Prediction: 3.410606622695923, Actual: 3.2742334588098787\n",
      "Prediction: 3.5600152015686035, Actual: 3.5451594318003106\n",
      "Prediction: 1.0045723915100098, Actual: 1.101939932271634\n",
      "Prediction: 3.011443614959717, Actual: 2.968807133269986\n",
      "Prediction: 2.5382585525512695, Actual: 2.5761746968185832\n",
      "Prediction: 1.0295997858047485, Actual: 0.4541144380742554\n",
      "Prediction: 2.755570411682129, Actual: 2.6741625507699083\n",
      "Prediction: 1.9259027242660522, Actual: 2.05996665628182\n",
      "Prediction: 1.9259849786758423, Actual: 1.983133992222757\n",
      "Prediction: 0.18433837592601776, Actual: 0.2123670952038988\n",
      "Prediction: 1.3935548067092896, Actual: 1.279370611476852\n",
      "Prediction: 2.131706476211548, Actual: 2.029736582447598\n",
      "Prediction: 3.0113255977630615, Actual: 3.189217169770364\n",
      "Prediction: 2.083712339401245, Actual: 2.2564883117007817\n",
      "Prediction: 1.7335814237594604, Actual: 1.636403110402885\n",
      "Prediction: 1.3713464736938477, Actual: 1.4015509339508203\n",
      "Prediction: 0.7852345705032349, Actual: 0.4436406552124723\n",
      "Prediction: 4.304920673370361, Actual: 4.0\n",
      "Prediction: 1.1138522624969482, Actual: 1.2712295298373406\n",
      "Prediction: 1.3434350490570068, Actual: 1.3026414038177534\n",
      "Prediction: 1.7489303350448608, Actual: 1.5970165723817666\n",
      "Prediction: 2.5568206310272217, Actual: 2.5353912836886785\n",
      "Prediction: 1.1653777360916138, Actual: 1.382935704905427\n",
      "Prediction: 1.0970548391342163, Actual: 1.0384883524708666\n",
      "Prediction: 0.8534876108169556, Actual: 0.1306542378736745\n",
      "Prediction: 1.5062074661254883, Actual: 1.2738181762310288\n",
      "Prediction: 1.0839184522628784, Actual: 1.2714946229661936\n",
      "Prediction: 3.469758987426758, Actual: 3.3250668431789085\n",
      "Prediction: 1.3532092571258545, Actual: 1.0707079518820537\n",
      "Prediction: 1.725507140159607, Actual: 1.574306088258861\n",
      "Prediction: 1.770886778831482, Actual: 1.6336793710032238\n",
      "Prediction: 0.19406738877296448, Actual: 0.0\n",
      "Prediction: 2.314589500427246, Actual: 2.122102757166825\n",
      "Prediction: 1.3203420639038086, Actual: 1.2912304259430896\n",
      "Prediction: 1.5501121282577515, Actual: 1.4547228982036302\n",
      "Prediction: 0.8684120178222656, Actual: 0.7742848136453381\n",
      "Prediction: 2.19895076751709, Actual: 2.293087191388992\n",
      "Prediction: 2.851532220840454, Actual: 2.6827762879633723\n",
      "Prediction: 1.1329931020736694, Actual: 1.3154643711031746\n",
      "Prediction: 1.4095247983932495, Actual: 1.4693892718306072\n",
      "Prediction: 0.8119051456451416, Actual: 0.61316598823277\n",
      "Prediction: 1.6923567056655884, Actual: 1.8819787410279116\n",
      "Prediction: 1.8832370042800903, Actual: 2.268905391743987\n",
      "Prediction: 3.2369558811187744, Actual: 3.545153035874012\n",
      "Prediction: 0.49026307463645935, Actual: 0.4258137609932144\n",
      "Prediction: 0.6247044205665588, Actual: 0.5403751565523403\n",
      "Prediction: 1.2656283378601074, Actual: 1.1110684623439582\n",
      "Prediction: 1.9306222200393677, Actual: 2.035367286041147\n",
      "Prediction: 2.915968894958496, Actual: 2.995458295719109\n",
      "Prediction: 0.7262551784515381, Actual: 1.2178731513333656\n",
      "Prediction: 1.9100620746612549, Actual: 2.1269889706667486\n",
      "Prediction: 0.9333800077438354, Actual: 0.5297986094952745\n",
      "Prediction: 2.837808132171631, Actual: 3.0168978681026624\n",
      "Prediction: 3.495307683944702, Actual: 3.5921289778598062\n",
      "Prediction: 0.9004395008087158, Actual: 1.0583113523259429\n",
      "Prediction: 2.059736967086792, Actual: 1.8425841347566336\n",
      "Prediction: 1.2371865510940552, Actual: 1.254572618142762\n",
      "Prediction: 2.6939215660095215, Actual: 2.794885282534225\n",
      "Prediction: 1.2006443738937378, Actual: 1.3478638291935137\n",
      "Prediction: 2.109715223312378, Actual: 2.226983393791037\n",
      "Prediction: 2.929685115814209, Actual: 2.81347034515229\n",
      "Prediction: 0.9697978496551514, Actual: 1.1055870981431069\n",
      "Prediction: 4.03989315032959, Actual: 4.0\n",
      "Prediction: 2.506736993789673, Actual: 2.898151345753362\n",
      "Prediction: 0.5181727409362793, Actual: 0.4239919484053893\n",
      "Prediction: 0.35514432191848755, Actual: 0.691477418739295\n",
      "Prediction: 0.9786254167556763, Actual: 0.930028645913522\n",
      "Prediction: 1.969773292541504, Actual: 2.330783482945125\n",
      "Prediction: 0.24569864571094513, Actual: 0.3375541414467983\n",
      "Prediction: 0.1821831464767456, Actual: 0.5022261210258885\n",
      "Prediction: 1.2110638618469238, Actual: 0.9893299205987556\n",
      "Prediction: 2.6654703617095947, Actual: 2.745858798383193\n",
      "Prediction: 1.8605910539627075, Actual: 1.8041546917762192\n",
      "Prediction: 3.154909610748291, Actual: 3.3432781941994127\n",
      "Prediction: 1.6601823568344116, Actual: 1.5730510214028783\n",
      "Prediction: 3.1992273330688477, Actual: 2.964009263152522\n",
      "Prediction: 1.6302181482315063, Actual: 1.1936177713396423\n",
      "Prediction: 1.4733282327651978, Actual: 1.3492561219436314\n",
      "Prediction: 2.2510695457458496, Actual: 2.520175258554297\n",
      "Prediction: 3.1069908142089844, Actual: 3.2537859623175915\n",
      "Prediction: 1.4058620929718018, Actual: 1.4633796485356\n",
      "Prediction: 3.2400450706481934, Actual: 3.161961511352394\n",
      "Prediction: 0.8989830017089844, Actual: 0.7696361214560695\n",
      "Prediction: 3.3093948364257812, Actual: 3.5037432645192648\n",
      "Prediction: 1.758841872215271, Actual: 1.2687721230682183\n",
      "Prediction: 0.6560949087142944, Actual: 1.1708122846030742\n",
      "Prediction: 0.47189006209373474, Actual: 0.4712831088434319\n",
      "Prediction: 1.4795509576797485, Actual: 1.3978971899557189\n",
      "Prediction: 0.6385847330093384, Actual: 0.9689861311254953\n",
      "Prediction: 1.572685718536377, Actual: 1.511276997165948\n",
      "Prediction: 0.7559473514556885, Actual: 0.5242135665585334\n",
      "Prediction: 1.573211908340454, Actual: 1.4913821292254057\n",
      "Prediction: 1.1111713647842407, Actual: 1.519441725815139\n",
      "Prediction: 1.0899983644485474, Actual: 0.7132676650608875\n",
      "Prediction: 0.854799747467041, Actual: 0.4005694786322673\n",
      "Prediction: 0.3568061590194702, Actual: 0.5813557994949716\n",
      "Prediction: 0.6361502408981323, Actual: 0.4050526130408124\n",
      "Prediction: 0.8039100170135498, Actual: 1.1544100089135072\n",
      "Prediction: 1.4925044775009155, Actual: 1.150153548429549\n",
      "Prediction: 2.313638925552368, Actual: 2.45790140704778\n",
      "Prediction: 3.5057168006896973, Actual: 3.4555094110343934\n",
      "Prediction: 1.7255513668060303, Actual: 1.4414095429135232\n",
      "Prediction: 3.4369003772735596, Actual: 3.2879731984208025\n",
      "Prediction: 2.6992764472961426, Actual: 3.043931624402609\n",
      "Prediction: 1.2606327533721924, Actual: 0.189818059909026\n",
      "Prediction: 1.4564220905303955, Actual: 1.1657871621526066\n",
      "Prediction: 2.492663860321045, Actual: 2.565368052695248\n",
      "Prediction: 2.2257676124572754, Actual: 2.2346855491679\n",
      "Prediction: 1.1569541692733765, Actual: 1.25865485443205\n",
      "Prediction: 2.263195037841797, Actual: 2.116723382234456\n",
      "Prediction: 1.8209645748138428, Actual: 1.674676218445066\n",
      "Prediction: 2.92250394821167, Actual: 2.8211081074612654\n",
      "Prediction: 1.7374521493911743, Actual: 1.9961073864422316\n",
      "Prediction: 0.560976505279541, Actual: 0.8090678531539729\n",
      "Prediction: 3.2262372970581055, Actual: 2.546634577748015\n",
      "Prediction: 2.894195556640625, Actual: 2.735041610764964\n",
      "Prediction: 2.825127363204956, Actual: 2.7535902317989964\n",
      "Prediction: 3.081120252609253, Actual: 3.283916521897384\n",
      "Prediction: 1.5048960447311401, Actual: 1.2878189977208636\n",
      "Prediction: 0.5490466356277466, Actual: 0.3106695325979863\n",
      "Prediction: 2.1196491718292236, Actual: 1.83151128144078\n",
      "Prediction: 1.2443739175796509, Actual: 0.911568270646688\n",
      "Prediction: 2.029047727584839, Actual: 2.109686328016939\n",
      "Prediction: 1.4095059633255005, Actual: 1.0444999950877136\n",
      "Prediction: 0.9292511940002441, Actual: 0.9654824453045304\n",
      "Prediction: 1.8544315099716187, Actual: 1.5504493308923313\n",
      "Prediction: 1.2661868333816528, Actual: 1.223828264622006\n",
      "Prediction: 1.8400706052780151, Actual: 1.8934409155419147\n",
      "Prediction: 1.8769127130508423, Actual: 2.295362280360723\n",
      "Prediction: 2.4864490032196045, Actual: 2.8393132491560324\n",
      "Prediction: 2.4223289489746094, Actual: 2.251847104187132\n",
      "Prediction: 1.7446022033691406, Actual: 1.4053156279015715\n",
      "Prediction: 3.1438231468200684, Actual: 3.03210533252155\n",
      "Prediction: 0.5081872940063477, Actual: 0.5694198849254213\n",
      "Prediction: 1.9628673791885376, Actual: 2.220050546998637\n",
      "Prediction: 2.9740428924560547, Actual: 2.7373779261627598\n",
      "Prediction: 2.206040143966675, Actual: 2.340811012860678\n",
      "Prediction: 0.35599127411842346, Actual: 0.5601746057023475\n",
      "Prediction: 3.0832042694091797, Actual: 2.913887649138132\n",
      "Prediction: 2.3823442459106445, Actual: 2.259451153743707\n",
      "Prediction: 1.6091231107711792, Actual: 1.7419681672894356\n",
      "Prediction: 1.4617152214050293, Actual: 1.2658914451513914\n",
      "Prediction: 0.9903535842895508, Actual: 1.298729106820987\n",
      "Prediction: 2.29874324798584, Actual: 1.9137997969013387\n",
      "Prediction: 2.677999258041382, Actual: 2.7808169956104924\n",
      "Prediction: 2.1268694400787354, Actual: 2.553484846074773\n",
      "Prediction: 0.8512700796127319, Actual: 0.8922661351679123\n",
      "Prediction: 2.878281593322754, Actual: 2.669749932596335\n",
      "Prediction: 3.219817638397217, Actual: 3.088512305616677\n",
      "Prediction: 1.7465801239013672, Actual: 1.5635740338353443\n",
      "Prediction: 2.982128620147705, Actual: 2.875735286006944\n",
      "Prediction: 0.8945413827896118, Actual: 1.184519764401664\n",
      "Prediction: 2.249614715576172, Actual: 2.584174278596964\n",
      "Prediction: 3.5297155380249023, Actual: 3.812757187598897\n",
      "Prediction: 0.6242307424545288, Actual: 0.6729361977994386\n",
      "Prediction: 1.5069084167480469, Actual: 1.9558725265628367\n",
      "Prediction: 1.8051245212554932, Actual: 1.773293697386631\n",
      "Prediction: 3.478855609893799, Actual: 3.055386295398076\n",
      "Prediction: 2.8757271766662598, Actual: 2.718465435794503\n",
      "Prediction: 1.5455385446548462, Actual: 1.2705295622953123\n",
      "Prediction: 2.1358542442321777, Actual: 1.9879647265294176\n",
      "Prediction: 1.883794903755188, Actual: 1.7209071500753406\n",
      "Prediction: 1.8534983396530151, Actual: 2.1105837595046006\n",
      "Prediction: 2.801054000854492, Actual: 2.8816123214605245\n",
      "Prediction: 1.0417343378067017, Actual: 0.9707643470928292\n",
      "Prediction: 3.015897512435913, Actual: 2.9728834414945147\n",
      "Prediction: 2.8124356269836426, Actual: 2.5210277348652257\n",
      "Prediction: 0.6371415853500366, Actual: 0.5152393995715008\n",
      "Prediction: 1.220784306526184, Actual: 1.0085719028530793\n",
      "Prediction: 2.7959389686584473, Actual: 2.791339403107066\n",
      "Prediction: 0.9901752471923828, Actual: 0.586837405483887\n",
      "Prediction: 3.8387787342071533, Actual: 3.666290826527483\n",
      "Prediction: 1.110797643661499, Actual: 0.9030855768578068\n",
      "Prediction: 0.5675061941146851, Actual: 0.7045952434646587\n",
      "Prediction: 2.2182230949401855, Actual: 2.3983144793001743\n",
      "Prediction: 1.3655002117156982, Actual: 1.817789572439356\n",
      "Prediction: 0.5577660799026489, Actual: 0.7995911976901089\n",
      "Prediction: 2.4650254249572754, Actual: 2.127408865912826\n",
      "Prediction: 1.4471555948257446, Actual: 1.1767815056705988\n",
      "Prediction: 0.5295141935348511, Actual: 0.4291372796949342\n",
      "Prediction: 1.7626384496688843, Actual: 2.0469388171096283\n",
      "Prediction: 1.0625375509262085, Actual: 1.0861513973549914\n",
      "Prediction: 3.310624599456787, Actual: 2.9869427371126283\n",
      "Prediction: 2.561953067779541, Actual: 2.474039536809681\n",
      "Prediction: 2.0639090538024902, Actual: 1.581931480635446\n",
      "Prediction: 2.367912769317627, Actual: 2.3278327626806856\n",
      "Prediction: 1.8559962511062622, Actual: 1.5252820489261911\n",
      "Prediction: 1.7147119045257568, Actual: 1.6831172628416484\n",
      "Prediction: 2.387822389602661, Actual: 2.4610469629080955\n",
      "Prediction: 0.5874494910240173, Actual: 0.0278186247324679\n",
      "Prediction: 1.6513999700546265, Actual: 1.5364194793970165\n",
      "Prediction: 1.9700790643692017, Actual: 2.0998851567205854\n",
      "Prediction: 0.29581448435783386, Actual: 0.3751478505639292\n",
      "Prediction: 1.8682608604431152, Actual: 1.2945928801079334\n",
      "Prediction: 0.7746027708053589, Actual: 0.7697406121390962\n",
      "Prediction: 1.8359299898147583, Actual: 1.821442173929074\n",
      "Prediction: 3.4703221321105957, Actual: 3.4982573417733205\n",
      "Prediction: 2.3684959411621094, Actual: 2.378050042081803\n",
      "Prediction: 0.7168116569519043, Actual: 0.5185224297099189\n",
      "Prediction: 2.4687986373901367, Actual: 2.754877493270432\n",
      "Prediction: 2.1126561164855957, Actual: 2.207001981395421\n",
      "Prediction: 0.9587234258651733, Actual: 1.1416385674703\n",
      "Prediction: 3.4684598445892334, Actual: 3.137624350847544\n",
      "Prediction: 1.3999184370040894, Actual: 1.3638410472397342\n",
      "Prediction: 1.3954099416732788, Actual: 1.6884763841942343\n",
      "Prediction: 1.3953617811203003, Actual: 1.3503298063610123\n",
      "Prediction: 2.565380096435547, Actual: 2.0624682672770884\n",
      "Prediction: 1.0212643146514893, Actual: 1.022641733675116\n",
      "Prediction: 1.7703617811203003, Actual: 1.7922893205354298\n",
      "Prediction: 0.40156635642051697, Actual: 0.0\n",
      "Prediction: 2.687547206878662, Actual: 2.8728793655039597\n",
      "Prediction: 3.4260854721069336, Actual: 3.08869986818596\n",
      "Prediction: 2.8018250465393066, Actual: 2.937454182316864\n",
      "Prediction: 2.016209602355957, Actual: 1.9900604524480008\n",
      "Prediction: 1.5787793397903442, Actual: 1.5165082679194366\n",
      "Prediction: 3.205077886581421, Actual: 3.300928568970799\n",
      "Prediction: 2.2165465354919434, Actual: 2.172740551700977\n",
      "Prediction: 1.6333459615707397, Actual: 1.11944101772116\n",
      "Prediction: 1.2697280645370483, Actual: 1.5717864335294334\n",
      "Prediction: 0.6889609098434448, Actual: 0.4958590410264636\n",
      "Prediction: 0.3967271149158478, Actual: 0.155004788411154\n",
      "Prediction: 3.772139072418213, Actual: 3.8649768612963977\n",
      "Prediction: 2.066662073135376, Actual: 1.8044174585321688\n",
      "Prediction: 2.4078567028045654, Actual: 2.784237837142815\n",
      "Prediction: 1.1153311729431152, Actual: 1.2058569757056352\n",
      "Prediction: 2.4811604022979736, Actual: 2.823600084682192\n",
      "Prediction: 1.3297526836395264, Actual: 0.8952499802854423\n",
      "Prediction: 2.923987865447998, Actual: 3.1122811365205387\n",
      "Prediction: 1.4837595224380493, Actual: 1.8154017176022967\n",
      "Prediction: 0.341966837644577, Actual: 0.1005921480894177\n",
      "Prediction: 2.891303777694702, Actual: 3.065473133634235\n",
      "Prediction: 2.8710274696350098, Actual: 2.5538644982316425\n",
      "Prediction: 2.3449132442474365, Actual: 1.9863780592187463\n",
      "Prediction: 0.839929461479187, Actual: 0.9941294103867458\n",
      "Prediction: 3.1848602294921875, Actual: 3.3501309740346112\n",
      "Prediction: 2.4409079551696777, Actual: 2.3116704996467785\n",
      "Prediction: 2.6575236320495605, Actual: 2.504167767054588\n",
      "Prediction: 0.7164465188980103, Actual: 0.763471998256058\n",
      "Prediction: 2.6314287185668945, Actual: 2.71222974268319\n",
      "Prediction: 0.6756435632705688, Actual: 0.9252693613945324\n",
      "Prediction: 1.8908830881118774, Actual: 1.849760707133483\n",
      "Prediction: 1.5023397207260132, Actual: 1.3970629516250068\n",
      "Prediction: 1.750332236289978, Actual: 1.8889919304287464\n",
      "Prediction: 0.6915667057037354, Actual: 0.9000416924553322\n",
      "Prediction: 0.9815324544906616, Actual: 1.027727966185627\n",
      "Prediction: 0.7751582860946655, Actual: 0.7016799102374711\n",
      "Prediction: 1.3798598051071167, Actual: 1.4119815069059265\n",
      "Prediction: 3.1429665088653564, Actual: 2.977408432892682\n",
      "Prediction: 2.323031425476074, Actual: 2.2103713279948844\n",
      "Prediction: 2.6620984077453613, Actual: 2.438731252650425\n",
      "Prediction: 1.8879402875900269, Actual: 1.9212942080249984\n",
      "Prediction: 1.9930076599121094, Actual: 1.7339724542334658\n",
      "Prediction: 1.2974013090133667, Actual: 1.5892697074168551\n",
      "Prediction: 1.9403727054595947, Actual: 1.503416679305313\n",
      "Prediction: 2.316193103790283, Actual: 2.222002853095735\n",
      "Prediction: 2.7684850692749023, Actual: 3.1062304249844512\n",
      "Prediction: 1.592927098274231, Actual: 1.5420637396404375\n",
      "Prediction: 0.9836831092834473, Actual: 1.2523485891697117\n",
      "Prediction: 1.2622004747390747, Actual: 1.710466837709535\n",
      "Prediction: 2.6993513107299805, Actual: 2.693598515909963\n",
      "Prediction: 0.9808799028396606, Actual: 0.9657009889491656\n",
      "Prediction: 1.971621036529541, Actual: 1.86827692299816\n",
      "Prediction: 2.7923359870910645, Actual: 2.806877505411242\n",
      "Prediction: 2.3687405586242676, Actual: 2.342836773191855\n",
      "Prediction: 2.6108529567718506, Actual: 2.583738162772638\n",
      "Prediction: 3.230713129043579, Actual: 3.2485727923536656\n",
      "Prediction: 2.6343624591827393, Actual: 2.5844682625115074\n",
      "Prediction: 2.7053418159484863, Actual: 2.587565796370635\n",
      "Prediction: 1.2164416313171387, Actual: 1.5660204997024247\n",
      "Prediction: 0.6022762060165405, Actual: 0.8670343739276987\n",
      "Prediction: 2.439940929412842, Actual: 1.8476004181084256\n",
      "Prediction: 1.1683526039123535, Actual: 1.1221109734183077\n",
      "Prediction: 1.632675051689148, Actual: 1.7181817231817458\n",
      "Prediction: 1.0602561235427856, Actual: 1.1645391660958937\n",
      "Prediction: 1.8566557168960571, Actual: 1.6833300315712254\n",
      "Prediction: 1.8948875665664673, Actual: 2.018579782190191\n",
      "Prediction: 2.6226096153259277, Actual: 2.512488758731327\n",
      "Prediction: 3.029046058654785, Actual: 3.168988610106379\n",
      "Prediction: 3.2959420680999756, Actual: 3.0526409582889382\n",
      "Prediction: 1.0305688381195068, Actual: 1.1528666911541523\n",
      "Prediction: 3.215132474899292, Actual: 3.25829468502287\n",
      "Prediction: 3.690737724304199, Actual: 3.363670491095614\n",
      "Prediction: 2.2601747512817383, Actual: 2.404089819888117\n",
      "Prediction: 1.8503868579864502, Actual: 2.137692088152197\n",
      "Prediction: 2.571367025375366, Actual: 2.427614635957672\n",
      "Prediction: 1.979469895362854, Actual: 1.810037822647263\n",
      "Prediction: 1.9888159036636353, Actual: 1.756035494723187\n",
      "Prediction: 2.387507677078247, Actual: 2.053147894166025\n",
      "Prediction: 1.4245723485946655, Actual: 1.6014725497408242\n",
      "Prediction: 0.2387956976890564, Actual: 0.4695533233798704\n",
      "Prediction: 2.131289482116699, Actual: 2.0046273170074884\n",
      "Prediction: 2.5426101684570312, Actual: 2.2887682028383933\n",
      "Prediction: 3.1383492946624756, Actual: 3.091715028356484\n",
      "Prediction: 2.398571014404297, Actual: 2.117233031215417\n",
      "Prediction: 1.051619529724121, Actual: 1.3476334931151803\n",
      "Prediction: 1.7112923860549927, Actual: 1.5304278892477712\n",
      "Prediction: 2.868957042694092, Actual: 2.734401494419992\n",
      "Prediction: 3.74943470954895, Actual: 3.8302053754229743\n",
      "Prediction: 2.605044364929199, Actual: 2.6394472915746228\n",
      "Prediction: 2.374345302581787, Actual: 2.471395779180272\n",
      "Prediction: 2.140968084335327, Actual: 2.2286086189122747\n",
      "Prediction: 0.6688385009765625, Actual: 0.6566169233161951\n",
      "Prediction: 2.2031219005584717, Actual: 2.2598041504961186\n",
      "Prediction: 2.6691646575927734, Actual: 2.3327839636333105\n",
      "Prediction: 2.843747854232788, Actual: 3.0234824828446896\n",
      "Prediction: 2.31377911567688, Actual: 2.964668230929299\n",
      "Prediction: 1.00516939163208, Actual: 0.983576997394541\n",
      "Prediction: 1.3421357870101929, Actual: 1.465549386433812\n",
      "Prediction: 2.2969493865966797, Actual: 2.268850734169383\n",
      "Prediction: 3.967979669570923, Actual: 3.5729453198762804\n",
      "Prediction: 0.7437589168548584, Actual: 0.6822651648416035\n",
      "Prediction: 2.0565550327301025, Actual: 1.9846599185571745\n",
      "Prediction: 2.385288953781128, Actual: 2.519724822511747\n",
      "Prediction: 0.6745721101760864, Actual: 0.5496018253589585\n",
      "Prediction: 2.953557014465332, Actual: 2.9868916209305363\n",
      "Prediction: 2.7881836891174316, Actual: 2.6404761356980795\n",
      "Prediction: 1.4311354160308838, Actual: 1.4772887703973712\n",
      "Prediction: 2.2462539672851562, Actual: 1.9395846660340497\n",
      "Prediction: 1.9563218355178833, Actual: 1.8298105464885008\n",
      "Prediction: 2.6822402477264404, Actual: 2.6696408286087285\n",
      "Prediction: 1.7311915159225464, Actual: 1.5961281034309902\n",
      "Prediction: 2.3608345985412598, Actual: 2.278951504956563\n",
      "Prediction: 0.8453675508499146, Actual: 1.1378011102056016\n",
      "Prediction: 1.066481590270996, Actual: 0.6768179731112823\n",
      "Prediction: 2.2089147567749023, Actual: 2.5040052870066454\n",
      "Prediction: 2.1240227222442627, Actual: 2.122638529628868\n",
      "Prediction: 2.643868923187256, Actual: 2.977851918315743\n",
      "Prediction: 2.752955436706543, Actual: 2.827614868021281\n",
      "Prediction: 2.9880447387695312, Actual: 2.942198841728139\n",
      "Prediction: 1.7925186157226562, Actual: 2.309975847769393\n",
      "Prediction: 3.179934501647949, Actual: 2.7778858935835875\n",
      "Prediction: 2.5359532833099365, Actual: 2.5244226584154354\n",
      "Prediction: 2.296685218811035, Actual: 2.135266354890094\n",
      "Prediction: 2.5763697624206543, Actual: 2.224197461212005\n",
      "Prediction: 3.183120012283325, Actual: 3.2389317177358112\n",
      "Prediction: 2.18814754486084, Actual: 2.230253521333785\n",
      "Prediction: 2.8401923179626465, Actual: 3.060805402033993\n",
      "Prediction: 0.9533214569091797, Actual: 1.3635615499322744\n",
      "Prediction: 3.1871814727783203, Actual: 3.603507572240497\n",
      "Prediction: 1.9168899059295654, Actual: 2.1672829561454443\n",
      "Prediction: 2.9754443168640137, Actual: 3.323902960329112\n",
      "Prediction: 1.8205008506774902, Actual: 2.0165967745176614\n",
      "Prediction: 1.6175330877304077, Actual: 1.3620437691526197\n",
      "Prediction: 1.9121123552322388, Actual: 2.1156039687255843\n",
      "Prediction: 2.6793553829193115, Actual: 2.465306489467062\n",
      "Prediction: 3.2087085247039795, Actual: 3.060490750087925\n",
      "Prediction: 2.1011085510253906, Actual: 1.9915084140251773\n",
      "Prediction: 0.37435826659202576, Actual: 0.264924162952827\n",
      "Prediction: 3.238964557647705, Actual: 3.64573804877044\n",
      "Prediction: 2.900240421295166, Actual: 2.5172289818586204\n",
      "Prediction: 1.517878532409668, Actual: 1.5487102111350304\n",
      "Prediction: 1.4534238576889038, Actual: 1.599593887728051\n",
      "Prediction: 1.4834588766098022, Actual: 1.5538733401089513\n",
      "Prediction: 2.2780444622039795, Actual: 2.595889050696416\n",
      "Prediction: 2.0198915004730225, Actual: 1.8790984603853385\n",
      "Prediction: 1.4116591215133667, Actual: 1.5066627733506968\n",
      "Prediction: 1.4116291999816895, Actual: 1.1048937876999445\n",
      "Prediction: 0.6672509908676147, Actual: 0.3413935419913523\n",
      "Prediction: 2.009490489959717, Actual: 2.4052675257641485\n",
      "Prediction: 1.7681469917297363, Actual: 1.6848422066992197\n",
      "Prediction: 3.1797118186950684, Actual: 2.993502391205279\n",
      "Prediction: 2.710165023803711, Actual: 3.4154133242434344\n",
      "Prediction: 1.4373492002487183, Actual: 1.7097013783889978\n",
      "Prediction: 1.6517289876937866, Actual: 1.5386892509239083\n",
      "Prediction: 3.050074815750122, Actual: 2.921386757069629\n",
      "Prediction: 2.419895887374878, Actual: 2.605247445547851\n",
      "Prediction: 2.270965576171875, Actual: 2.4400060965135784\n",
      "Prediction: 1.2416765689849854, Actual: 1.42899323811113\n",
      "Prediction: 3.4183177947998047, Actual: 3.3721260428259656\n",
      "Prediction: 2.470655679702759, Actual: 2.1516179803357813\n",
      "Prediction: 1.6372874975204468, Actual: 1.5950547587554351\n",
      "Prediction: 1.360107660293579, Actual: 1.4145556778225787\n",
      "Prediction: 3.2564237117767334, Actual: 3.128858646003016\n",
      "Prediction: 2.9837098121643066, Actual: 2.553439811443938\n",
      "Prediction: 3.0101633071899414, Actual: 3.1296400506375512\n",
      "Prediction: 2.872681140899658, Actual: 2.981992255406158\n",
      "Prediction: 3.107938051223755, Actual: 2.981786874282664\n",
      "Prediction: 1.1841901540756226, Actual: 1.2010533026138683\n",
      "Prediction: 2.6267571449279785, Actual: 2.79138610847234\n",
      "Prediction: 0.5342038869857788, Actual: 0.1530318116508149\n",
      "Prediction: 0.9059829711914062, Actual: 0.6193509314675341\n",
      "Prediction: 2.245431423187256, Actual: 2.281345006080266\n",
      "Prediction: 0.7588886022567749, Actual: 0.4937411351889655\n",
      "Prediction: 3.1766982078552246, Actual: 2.966548034294946\n",
      "Prediction: 2.1563477516174316, Actual: 1.989455195588546\n",
      "Prediction: 3.665128231048584, Actual: 3.5433159148930136\n",
      "Prediction: 1.7073335647583008, Actual: 1.970600159244711\n",
      "Prediction: 1.1336314678192139, Actual: 1.3440857175872982\n",
      "Prediction: 0.8696620464324951, Actual: 1.027015599936749\n",
      "Prediction: 0.48276177048683167, Actual: 0.4277633541749704\n",
      "Prediction: 2.340606451034546, Actual: 1.9746552454467765\n",
      "Prediction: 0.7937537431716919, Actual: 1.242176324159397\n",
      "Prediction: 0.7285624742507935, Actual: 0.384375395876116\n",
      "Prediction: 0.8009068965911865, Actual: 0.4474828563605549\n",
      "Prediction: 1.4695204496383667, Actual: 1.7290731666537256\n",
      "Prediction: 2.177320957183838, Actual: 2.136399546240388\n",
      "Prediction: 0.3676457107067108, Actual: 0.2109791787447653\n",
      "Prediction: 0.2504606246948242, Actual: 0.33096690773874\n",
      "Prediction: 2.7816176414489746, Actual: 2.888891669272444\n",
      "Prediction: 3.412770986557007, Actual: 3.270373860776488\n",
      "Prediction: 2.715512752532959, Actual: 2.500113299959695\n",
      "Prediction: 1.3274520635604858, Actual: 1.212880751488374\n",
      "Prediction: 1.847080111503601, Actual: 2.009298479722319\n",
      "Prediction: 1.2414251565933228, Actual: 1.543837471085622\n",
      "Prediction: 1.770187258720398, Actual: 1.4382049683676248\n",
      "Prediction: 1.8648271560668945, Actual: 1.562359564441758\n",
      "Prediction: 2.200179100036621, Actual: 2.17490279620988\n",
      "Prediction: 2.4956836700439453, Actual: 2.3325403195354064\n",
      "Prediction: 2.485853433609009, Actual: 2.777966932491008\n",
      "Prediction: 0.9679771661758423, Actual: 0.863545351686935\n"
     ]
    }
   ],
   "source": [
    "# Realizar predicciones en el conjunto de prueba\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Asegurarse de que y_test es un array o convertirlo\n",
    "y_test_array = y_test.values if hasattr(y_test, 'values') else y_test\n",
    "\n",
    "# Imprimir cada predicción junto con el valor real (de y_test)\n",
    "for i in range(len(y_test_array)):\n",
    "    print(f\"Prediction: {y_pred[i][0]}, Actual: {y_test_array[i]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Respuesta\n",
    "Viendo las predicciones y los valores reales, puedo observar que las predicciones del modelo están bastante cercanas a los valores reales del GPA, lo que indica que el modelo está funcionando de manera eficiente. Aunque el MAE es de 0.19, lo que ya es un error pequeño en comparación con el rango total del GPA (0 a 4), al observar visualmente las predicciones, puedo confirmar que en la mayoría de los casos, la diferencia entre las predicciones y los valores reales es muy baja.\n",
    "\n",
    "Esto sugiere que mi modelo está capturando bien las relaciones en los datos y está haciendo predicciones bastante precisas. El hecho de que muchas de las predicciones estén a menos de 0.2 puntos de diferencia del valor real refuerza la idea de que el modelo generaliza bien y tiene un rendimiento sólido."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13. Compete against this model:\n",
    "- Create two more different models to compete with this model\n",
    "- Here are a few ideas of things you can change:\n",
    "   - During Dataset data engineering:\n",
    "      - You can remove features that you think do not help in the training and prediction \n",
    "      - Feature Scaling: Ensure all features are on a similar scale (as you already did with StandardScaler)\n",
    "   - During Model Definition:\n",
    "      - You can change the Model Architecture (change the type or number of layers or the number of units)\n",
    "      - You can add dropout layers to prevent overfitting\n",
    "   - During Model Compile:\n",
    "      - You can try other optimizer when compiling your model, here some optimizer samples: Adam, RMSprop, or Adagrad.\n",
    "      - Try another Loss Function\n",
    "   - During Model Training:\n",
    "      - Encrease the number of Epochs\n",
    "      - Adjust the size of your batch\n",
    "- Explain in a Markdown cell which changes are you implementing\n",
    "- Show the comparison of your model versus the original model\n",
    "   \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 2:\n",
    "- Changes:\n",
    "   - Dataset Data Engineering:  Podríamos eliminar algunas columnas adicionales para simplificar el modelo, como Gender o Ethnicity si no parecen ser útiles.\n",
    "   - Model Definit; ion: Vamos a añadir una capa extra con más neuronas para hacer el modelo más complejo y tal vez mejorar el rendimiento.\n",
    "   - Model Compile: Probaremos con otro optimizador, como RMSprop, para ver si eso mejora la convergencia.\n",
    "   - Model Training: Aumentaremos el número de épocas a 100 para permitir que el modelo se entrene durante más tiempo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset Data Engineering: Podríamos eliminar algunas columnas adicionales para simplificar el modelo, como Gender o Ethnicity si no parecen ser útiles.\n",
    "\n",
    "Model Definition: Vamos a añadir una capa extra con más neuronas para hacer el modelo más complejo y tal vez mejorar el rendimiento.\n",
    "\n",
    "Model Compile: Probaremos con otro optimizador, como RMSprop, para ver si eso mejora la convergencia.\n",
    "\n",
    "Model Training: Aumentaremos el número de épocas a 100 para permitir que el modelo se entrene durante más tiempo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\adria\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.4179 - mae: 0.8457 - val_loss: 0.0560 - val_mae: 0.1910\n",
      "Epoch 2/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 844us/step - loss: 0.0469 - mae: 0.1742 - val_loss: 0.0276 - val_mae: 0.1331\n",
      "Epoch 3/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - loss: 0.0222 - mae: 0.1196 - val_loss: 0.0234 - val_mae: 0.1262\n",
      "Epoch 4/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - loss: 0.0140 - mae: 0.0948 - val_loss: 0.0121 - val_mae: 0.0874\n",
      "Epoch 5/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 801us/step - loss: 0.0089 - mae: 0.0751 - val_loss: 0.0101 - val_mae: 0.0789\n",
      "Epoch 6/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 870us/step - loss: 0.0079 - mae: 0.0700 - val_loss: 0.0112 - val_mae: 0.0865\n",
      "Epoch 7/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 892us/step - loss: 0.0059 - mae: 0.0621 - val_loss: 0.0096 - val_mae: 0.0780\n",
      "Epoch 8/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0054 - mae: 0.0570 - val_loss: 0.0084 - val_mae: 0.0727\n",
      "Epoch 9/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 857us/step - loss: 0.0048 - mae: 0.0552 - val_loss: 0.0059 - val_mae: 0.0587\n",
      "Epoch 10/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 848us/step - loss: 0.0042 - mae: 0.0504 - val_loss: 0.0054 - val_mae: 0.0573\n",
      "Epoch 11/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 842us/step - loss: 0.0042 - mae: 0.0497 - val_loss: 0.0059 - val_mae: 0.0622\n",
      "Epoch 12/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 870us/step - loss: 0.0038 - mae: 0.0485 - val_loss: 0.0043 - val_mae: 0.0504\n",
      "Epoch 13/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 902us/step - loss: 0.0035 - mae: 0.0472 - val_loss: 0.0040 - val_mae: 0.0499\n",
      "Epoch 14/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 949us/step - loss: 0.0034 - mae: 0.0452 - val_loss: 0.0064 - val_mae: 0.0649\n",
      "Epoch 15/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 903us/step - loss: 0.0036 - mae: 0.0470 - val_loss: 0.0064 - val_mae: 0.0663\n",
      "Epoch 16/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 844us/step - loss: 0.0032 - mae: 0.0441 - val_loss: 0.0052 - val_mae: 0.0567\n",
      "Epoch 17/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 850us/step - loss: 0.0031 - mae: 0.0443 - val_loss: 0.0033 - val_mae: 0.0449\n",
      "Epoch 18/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 916us/step - loss: 0.0026 - mae: 0.0395 - val_loss: 0.0026 - val_mae: 0.0388\n",
      "Epoch 19/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 844us/step - loss: 0.0025 - mae: 0.0388 - val_loss: 0.0026 - val_mae: 0.0392\n",
      "Epoch 20/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 892us/step - loss: 0.0026 - mae: 0.0410 - val_loss: 0.0031 - val_mae: 0.0432\n",
      "Epoch 21/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 902us/step - loss: 0.0025 - mae: 0.0389 - val_loss: 0.0047 - val_mae: 0.0580\n",
      "Epoch 22/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 868us/step - loss: 0.0021 - mae: 0.0366 - val_loss: 0.0024 - val_mae: 0.0386\n",
      "Epoch 23/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 849us/step - loss: 0.0023 - mae: 0.0376 - val_loss: 0.0075 - val_mae: 0.0720\n",
      "Epoch 24/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 840us/step - loss: 0.0023 - mae: 0.0381 - val_loss: 0.0024 - val_mae: 0.0370\n",
      "Epoch 25/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0019 - mae: 0.0340 - val_loss: 0.0037 - val_mae: 0.0500\n",
      "Epoch 26/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 894us/step - loss: 0.0021 - mae: 0.0368 - val_loss: 0.0061 - val_mae: 0.0652\n",
      "Epoch 27/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 881us/step - loss: 0.0019 - mae: 0.0334 - val_loss: 0.0022 - val_mae: 0.0362\n",
      "Epoch 28/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 912us/step - loss: 0.0020 - mae: 0.0347 - val_loss: 0.0045 - val_mae: 0.0560\n",
      "Epoch 29/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 826us/step - loss: 0.0020 - mae: 0.0346 - val_loss: 0.0026 - val_mae: 0.0394\n",
      "Epoch 30/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 829us/step - loss: 0.0019 - mae: 0.0336 - val_loss: 0.0023 - val_mae: 0.0380\n",
      "Epoch 31/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 843us/step - loss: 0.0018 - mae: 0.0326 - val_loss: 0.0020 - val_mae: 0.0347\n",
      "Epoch 32/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 850us/step - loss: 0.0015 - mae: 0.0296 - val_loss: 0.0032 - val_mae: 0.0455\n",
      "Epoch 33/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855us/step - loss: 0.0017 - mae: 0.0315 - val_loss: 0.0019 - val_mae: 0.0352\n",
      "Epoch 34/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 863us/step - loss: 0.0017 - mae: 0.0323 - val_loss: 0.0035 - val_mae: 0.0482\n",
      "Epoch 35/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 887us/step - loss: 0.0017 - mae: 0.0315 - val_loss: 0.0016 - val_mae: 0.0299\n",
      "Epoch 36/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 978us/step - loss: 0.0016 - mae: 0.0304 - val_loss: 0.0018 - val_mae: 0.0339\n",
      "Epoch 37/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 894us/step - loss: 0.0017 - mae: 0.0329 - val_loss: 0.0028 - val_mae: 0.0431\n",
      "Epoch 38/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0014 - mae: 0.0294 - val_loss: 0.0097 - val_mae: 0.0849\n",
      "Epoch 39/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 923us/step - loss: 0.0016 - mae: 0.0309 - val_loss: 0.0016 - val_mae: 0.0296\n",
      "Epoch 40/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - loss: 0.0016 - mae: 0.0310 - val_loss: 0.0013 - val_mae: 0.0267\n",
      "Epoch 41/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step - loss: 0.0015 - mae: 0.0307 - val_loss: 0.0012 - val_mae: 0.0257\n",
      "Epoch 42/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 857us/step - loss: 0.0017 - mae: 0.0312 - val_loss: 0.0017 - val_mae: 0.0322\n",
      "Epoch 43/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 823us/step - loss: 0.0014 - mae: 0.0296 - val_loss: 0.0031 - val_mae: 0.0471\n",
      "Epoch 44/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 893us/step - loss: 0.0015 - mae: 0.0298 - val_loss: 0.0015 - val_mae: 0.0311\n",
      "Epoch 45/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 880us/step - loss: 0.0014 - mae: 0.0298 - val_loss: 0.0012 - val_mae: 0.0269\n",
      "Epoch 46/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 843us/step - loss: 0.0013 - mae: 0.0267 - val_loss: 0.0012 - val_mae: 0.0266\n",
      "Epoch 47/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 937us/step - loss: 0.0015 - mae: 0.0290 - val_loss: 0.0016 - val_mae: 0.0304\n",
      "Epoch 48/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 851us/step - loss: 0.0014 - mae: 0.0287 - val_loss: 0.0015 - val_mae: 0.0284\n",
      "Epoch 49/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 857us/step - loss: 0.0013 - mae: 0.0280 - val_loss: 0.0028 - val_mae: 0.0442\n",
      "Epoch 50/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 851us/step - loss: 0.0016 - mae: 0.0314 - val_loss: 0.0021 - val_mae: 0.0355\n",
      "Epoch 51/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 842us/step - loss: 0.0015 - mae: 0.0307 - val_loss: 0.0016 - val_mae: 0.0287\n",
      "Epoch 52/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 862us/step - loss: 0.0013 - mae: 0.0273 - val_loss: 0.0012 - val_mae: 0.0276\n",
      "Epoch 53/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 828us/step - loss: 0.0011 - mae: 0.0261 - val_loss: 0.0013 - val_mae: 0.0281\n",
      "Epoch 54/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 901us/step - loss: 0.0012 - mae: 0.0272 - val_loss: 0.0011 - val_mae: 0.0246\n",
      "Epoch 55/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0013 - mae: 0.0264 - val_loss: 0.0011 - val_mae: 0.0257\n",
      "Epoch 56/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 852us/step - loss: 0.0014 - mae: 0.0291 - val_loss: 0.0032 - val_mae: 0.0478\n",
      "Epoch 57/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 881us/step - loss: 0.0012 - mae: 0.0277 - val_loss: 0.0018 - val_mae: 0.0353\n",
      "Epoch 58/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 846us/step - loss: 0.0012 - mae: 0.0268 - val_loss: 0.0013 - val_mae: 0.0273\n",
      "Epoch 59/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 866us/step - loss: 0.0013 - mae: 0.0272 - val_loss: 0.0011 - val_mae: 0.0246\n",
      "Epoch 60/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 845us/step - loss: 0.0011 - mae: 0.0243 - val_loss: 8.3163e-04 - val_mae: 0.0220\n",
      "Epoch 61/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 843us/step - loss: 0.0012 - mae: 0.0268 - val_loss: 0.0010 - val_mae: 0.0243\n",
      "Epoch 62/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 849us/step - loss: 0.0011 - mae: 0.0244 - val_loss: 9.3475e-04 - val_mae: 0.0228\n",
      "Epoch 63/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 851us/step - loss: 0.0011 - mae: 0.0256 - val_loss: 9.0453e-04 - val_mae: 0.0223\n",
      "Epoch 64/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 881us/step - loss: 0.0011 - mae: 0.0256 - val_loss: 0.0012 - val_mae: 0.0265\n",
      "Epoch 65/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 976us/step - loss: 0.0011 - mae: 0.0251 - val_loss: 0.0017 - val_mae: 0.0344\n",
      "Epoch 66/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 858us/step - loss: 0.0011 - mae: 0.0252 - val_loss: 0.0011 - val_mae: 0.0245\n",
      "Epoch 67/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817us/step - loss: 0.0012 - mae: 0.0264 - val_loss: 0.0011 - val_mae: 0.0259\n",
      "Epoch 68/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0010 - mae: 0.0245 - val_loss: 0.0026 - val_mae: 0.0419\n",
      "Epoch 69/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 831us/step - loss: 0.0011 - mae: 0.0250 - val_loss: 8.5788e-04 - val_mae: 0.0234\n",
      "Epoch 70/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 881us/step - loss: 0.0011 - mae: 0.0250 - val_loss: 8.2701e-04 - val_mae: 0.0214\n",
      "Epoch 71/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 850us/step - loss: 9.8042e-04 - mae: 0.0235 - val_loss: 0.0032 - val_mae: 0.0492\n",
      "Epoch 72/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step - loss: 0.0011 - mae: 0.0250 - val_loss: 7.5503e-04 - val_mae: 0.0212\n",
      "Epoch 73/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 863us/step - loss: 0.0010 - mae: 0.0242 - val_loss: 8.5284e-04 - val_mae: 0.0222\n",
      "Epoch 74/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 825us/step - loss: 0.0010 - mae: 0.0251 - val_loss: 0.0013 - val_mae: 0.0285\n",
      "Epoch 75/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step - loss: 9.7174e-04 - mae: 0.0240 - val_loss: 0.0036 - val_mae: 0.0534\n",
      "Epoch 76/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 874us/step - loss: 0.0012 - mae: 0.0270 - val_loss: 0.0013 - val_mae: 0.0292\n",
      "Epoch 77/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 882us/step - loss: 9.7440e-04 - mae: 0.0242 - val_loss: 0.0011 - val_mae: 0.0272\n",
      "Epoch 78/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 861us/step - loss: 9.5665e-04 - mae: 0.0233 - val_loss: 0.0030 - val_mae: 0.0456\n",
      "Epoch 79/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 820us/step - loss: 0.0010 - mae: 0.0250 - val_loss: 0.0012 - val_mae: 0.0273\n",
      "Epoch 80/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9.1019e-04 - mae: 0.0231 - val_loss: 0.0023 - val_mae: 0.0395\n",
      "Epoch 81/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 879us/step - loss: 9.0543e-04 - mae: 0.0236 - val_loss: 0.0017 - val_mae: 0.0336\n",
      "Epoch 82/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9.0360e-04 - mae: 0.0237 - val_loss: 0.0012 - val_mae: 0.0266\n",
      "Epoch 83/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 822us/step - loss: 8.8898e-04 - mae: 0.0230 - val_loss: 0.0015 - val_mae: 0.0317\n",
      "Epoch 84/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 835us/step - loss: 9.4586e-04 - mae: 0.0240 - val_loss: 8.2777e-04 - val_mae: 0.0225\n",
      "Epoch 85/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 850us/step - loss: 8.4466e-04 - mae: 0.0221 - val_loss: 7.8022e-04 - val_mae: 0.0218\n",
      "Epoch 86/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 837us/step - loss: 8.3963e-04 - mae: 0.0214 - val_loss: 7.5562e-04 - val_mae: 0.0221\n",
      "Epoch 87/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 838us/step - loss: 9.9830e-04 - mae: 0.0239 - val_loss: 0.0023 - val_mae: 0.0418\n",
      "Epoch 88/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 856us/step - loss: 8.9462e-04 - mae: 0.0233 - val_loss: 0.0013 - val_mae: 0.0302\n",
      "Epoch 89/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 830us/step - loss: 9.3548e-04 - mae: 0.0237 - val_loss: 0.0011 - val_mae: 0.0250\n",
      "Epoch 90/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 824us/step - loss: 8.4957e-04 - mae: 0.0225 - val_loss: 6.4776e-04 - val_mae: 0.0191\n",
      "Epoch 91/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 896us/step - loss: 8.7089e-04 - mae: 0.0228 - val_loss: 7.7231e-04 - val_mae: 0.0219\n",
      "Epoch 92/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 884us/step - loss: 8.3853e-04 - mae: 0.0217 - val_loss: 9.9071e-04 - val_mae: 0.0263\n",
      "Epoch 93/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 862us/step - loss: 8.1421e-04 - mae: 0.0218 - val_loss: 0.0013 - val_mae: 0.0304\n",
      "Epoch 94/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 872us/step - loss: 8.6528e-04 - mae: 0.0226 - val_loss: 7.9096e-04 - val_mae: 0.0213\n",
      "Epoch 95/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 911us/step - loss: 9.0932e-04 - mae: 0.0232 - val_loss: 0.0011 - val_mae: 0.0249\n",
      "Epoch 96/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 835us/step - loss: 8.7578e-04 - mae: 0.0221 - val_loss: 8.0499e-04 - val_mae: 0.0229\n",
      "Epoch 97/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 937us/step - loss: 8.3907e-04 - mae: 0.0224 - val_loss: 0.0033 - val_mae: 0.0495\n",
      "Epoch 98/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 924us/step - loss: 8.1793e-04 - mae: 0.0221 - val_loss: 6.7095e-04 - val_mae: 0.0211\n",
      "Epoch 99/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 831us/step - loss: 7.3439e-04 - mae: 0.0203 - val_loss: 8.2052e-04 - val_mae: 0.0211\n",
      "Epoch 100/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 877us/step - loss: 7.0223e-04 - mae: 0.0197 - val_loss: 6.5855e-04 - val_mae: 0.0201\n"
     ]
    }
   ],
   "source": [
    "# Dataset Data Engineering: eliminar columnas adicionales\n",
    "columns_to_remove_2 = ['StudentID', 'GradeClass', 'Gender']\n",
    "X_2 = data.drop(columns=columns_to_remove_2)\n",
    "\n",
    "# Dividir los datos\n",
    "X_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(X_2, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Escalar las características\n",
    "scaler = StandardScaler()\n",
    "X_train_2 = scaler.fit_transform(X_train_2)\n",
    "X_test_2 = scaler.transform(X_test_2)\n",
    "\n",
    "# Modelo 2: Definir una nueva arquitectura con una capa adicional\n",
    "model_2 = Sequential()\n",
    "model_2.add(Dense(64, input_dim=X_train_2.shape[1], activation='relu'))\n",
    "model_2.add(Dense(32, activation='relu'))\n",
    "model_2.add(Dense(16, activation='relu'))  # Capa adicional\n",
    "model_2.add(Dense(1))  # Capa de salida para regresión\n",
    "\n",
    "# Compilar el modelo con RMSprop\n",
    "model_2.compile(optimizer=RMSprop(), loss='mean_squared_error', metrics=['mae'])\n",
    "\n",
    "# Entrenar el modelo con más épocas\n",
    "history_2 = model_2.fit(X_train_2, y_train_2, epochs=100, batch_size=10, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 3:\n",
    "- Changes:\n",
    "   - Dataset Data Engineering: en el Modelo 3 eliminaremos aproximadamente 5 columnas adicionales que no parecen ser tan necesarias para la predicción del GPA ademas de las ya borradas, Ethnicity, ParentalSupport, Sports, Music, Volunteering (que ya habíamos mencionado)\n",
    "   - Model Definition: Añadimos capas de dropout para evitar el sobreajuste.\n",
    "   - Model Compile: Probaremos con un optimizador diferente, como Adagrad.\n",
    "   - Model Training: Ajustamos el tamaño del lote (batch size) para ver si afecta el rendimiento ademas de aumentar el numero de epocas a 200\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\adria\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4.5021 - mae: 1.8483 - val_loss: 3.4729 - val_mae: 1.6212\n",
      "Epoch 2/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.5405 - mae: 1.6227 - val_loss: 2.8641 - val_mae: 1.4596\n",
      "Epoch 3/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.8361 - mae: 1.4433 - val_loss: 2.4271 - val_mae: 1.3368\n",
      "Epoch 4/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.6439 - mae: 1.3699 - val_loss: 2.0978 - val_mae: 1.2393\n",
      "Epoch 5/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 983us/step - loss: 2.3296 - mae: 1.2822 - val_loss: 1.8372 - val_mae: 1.1582\n",
      "Epoch 6/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 984us/step - loss: 2.1920 - mae: 1.2467 - val_loss: 1.6274 - val_mae: 1.0892\n",
      "Epoch 7/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.0174 - mae: 1.1732 - val_loss: 1.4506 - val_mae: 1.0281\n",
      "Epoch 8/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6763 - mae: 1.0744 - val_loss: 1.3051 - val_mae: 0.9754\n",
      "Epoch 9/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7294 - mae: 1.0740 - val_loss: 1.1756 - val_mae: 0.9264\n",
      "Epoch 10/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5724 - mae: 1.0205 - val_loss: 1.0670 - val_mae: 0.8833\n",
      "Epoch 11/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.4733 - mae: 0.9737 - val_loss: 0.9776 - val_mae: 0.8461\n",
      "Epoch 12/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.4369 - mae: 0.9839 - val_loss: 0.8885 - val_mae: 0.8071\n",
      "Epoch 13/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.3881 - mae: 0.9686 - val_loss: 0.8217 - val_mae: 0.7765\n",
      "Epoch 14/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.3233 - mae: 0.9380 - val_loss: 0.7564 - val_mae: 0.7450\n",
      "Epoch 15/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.2967 - mae: 0.9043 - val_loss: 0.7020 - val_mae: 0.7177\n",
      "Epoch 16/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.2800 - mae: 0.9105 - val_loss: 0.6592 - val_mae: 0.6955\n",
      "Epoch 17/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.2599 - mae: 0.9126 - val_loss: 0.6184 - val_mae: 0.6734\n",
      "Epoch 18/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.1631 - mae: 0.8668 - val_loss: 0.5770 - val_mae: 0.6498\n",
      "Epoch 19/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.2006 - mae: 0.8886 - val_loss: 0.5404 - val_mae: 0.6283\n",
      "Epoch 20/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.1593 - mae: 0.8675 - val_loss: 0.5112 - val_mae: 0.6107\n",
      "Epoch 21/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.1794 - mae: 0.8676 - val_loss: 0.4795 - val_mae: 0.5909\n",
      "Epoch 22/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.2251 - mae: 0.8946 - val_loss: 0.4621 - val_mae: 0.5800\n",
      "Epoch 23/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.1182 - mae: 0.8519 - val_loss: 0.4403 - val_mae: 0.5657\n",
      "Epoch 24/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.1339 - mae: 0.8324 - val_loss: 0.4177 - val_mae: 0.5506\n",
      "Epoch 25/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.0904 - mae: 0.8446 - val_loss: 0.4042 - val_mae: 0.5414\n",
      "Epoch 26/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.0659 - mae: 0.8236 - val_loss: 0.3873 - val_mae: 0.5295\n",
      "Epoch 27/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.1023 - mae: 0.8388 - val_loss: 0.3747 - val_mae: 0.5204\n",
      "Epoch 28/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.0464 - mae: 0.8207 - val_loss: 0.3596 - val_mae: 0.5093\n",
      "Epoch 29/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.0555 - mae: 0.8125 - val_loss: 0.3463 - val_mae: 0.4992\n",
      "Epoch 30/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.0033 - mae: 0.7953 - val_loss: 0.3394 - val_mae: 0.4943\n",
      "Epoch 31/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.0406 - mae: 0.8143 - val_loss: 0.3280 - val_mae: 0.4853\n",
      "Epoch 32/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.0865 - mae: 0.8082 - val_loss: 0.3187 - val_mae: 0.4781\n",
      "Epoch 33/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9693 - mae: 0.7833 - val_loss: 0.3106 - val_mae: 0.4719\n",
      "Epoch 34/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9532 - mae: 0.7839 - val_loss: 0.3071 - val_mae: 0.4695\n",
      "Epoch 35/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.0507 - mae: 0.7909 - val_loss: 0.2982 - val_mae: 0.4624\n",
      "Epoch 36/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9452 - mae: 0.7636 - val_loss: 0.2938 - val_mae: 0.4592\n",
      "Epoch 37/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.0298 - mae: 0.8038 - val_loss: 0.2880 - val_mae: 0.4546\n",
      "Epoch 38/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9935 - mae: 0.8045 - val_loss: 0.2776 - val_mae: 0.4457\n",
      "Epoch 39/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9998 - mae: 0.7844 - val_loss: 0.2755 - val_mae: 0.4445\n",
      "Epoch 40/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0074 - mae: 0.7982 - val_loss: 0.2741 - val_mae: 0.4439\n",
      "Epoch 41/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9643 - mae: 0.7799 - val_loss: 0.2714 - val_mae: 0.4420\n",
      "Epoch 42/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9467 - mae: 0.7676 - val_loss: 0.2673 - val_mae: 0.4389\n",
      "Epoch 43/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9683 - mae: 0.7740 - val_loss: 0.2634 - val_mae: 0.4356\n",
      "Epoch 44/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.8944 - mae: 0.7485 - val_loss: 0.2574 - val_mae: 0.4303\n",
      "Epoch 45/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9961 - mae: 0.7963 - val_loss: 0.2515 - val_mae: 0.4254\n",
      "Epoch 46/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9672 - mae: 0.7786 - val_loss: 0.2473 - val_mae: 0.4217\n",
      "Epoch 47/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9424 - mae: 0.7662 - val_loss: 0.2463 - val_mae: 0.4212\n",
      "Epoch 48/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9700 - mae: 0.7817 - val_loss: 0.2455 - val_mae: 0.4210\n",
      "Epoch 49/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9177 - mae: 0.7581 - val_loss: 0.2443 - val_mae: 0.4204\n",
      "Epoch 50/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.8602 - mae: 0.7289 - val_loss: 0.2414 - val_mae: 0.4179\n",
      "Epoch 51/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.8933 - mae: 0.7448 - val_loss: 0.2390 - val_mae: 0.4157\n",
      "Epoch 52/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.8950 - mae: 0.7332 - val_loss: 0.2365 - val_mae: 0.4138\n",
      "Epoch 53/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.8459 - mae: 0.7321 - val_loss: 0.2326 - val_mae: 0.4104\n",
      "Epoch 54/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 964us/step - loss: 0.8819 - mae: 0.7541 - val_loss: 0.2300 - val_mae: 0.4080\n",
      "Epoch 55/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 935us/step - loss: 0.8375 - mae: 0.7304 - val_loss: 0.2267 - val_mae: 0.4049\n",
      "Epoch 56/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 930us/step - loss: 0.8552 - mae: 0.7260 - val_loss: 0.2242 - val_mae: 0.4028\n",
      "Epoch 57/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 955us/step - loss: 0.8448 - mae: 0.7342 - val_loss: 0.2218 - val_mae: 0.4007\n",
      "Epoch 58/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.8276 - mae: 0.7189 - val_loss: 0.2192 - val_mae: 0.3983\n",
      "Epoch 59/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 979us/step - loss: 0.8676 - mae: 0.7327 - val_loss: 0.2183 - val_mae: 0.3977\n",
      "Epoch 60/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9116 - mae: 0.7646 - val_loss: 0.2142 - val_mae: 0.3936\n",
      "Epoch 61/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8923 - mae: 0.7497 - val_loss: 0.2120 - val_mae: 0.3916\n",
      "Epoch 62/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.8247 - mae: 0.7116 - val_loss: 0.2108 - val_mae: 0.3906\n",
      "Epoch 63/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.8981 - mae: 0.7467 - val_loss: 0.2116 - val_mae: 0.3919\n",
      "Epoch 64/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9141 - mae: 0.7474 - val_loss: 0.2080 - val_mae: 0.3882\n",
      "Epoch 65/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9439 - mae: 0.7561 - val_loss: 0.2089 - val_mae: 0.3898\n",
      "Epoch 66/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.8885 - mae: 0.7356 - val_loss: 0.2082 - val_mae: 0.3893\n",
      "Epoch 67/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.8570 - mae: 0.7274 - val_loss: 0.2067 - val_mae: 0.3880\n",
      "Epoch 68/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.8806 - mae: 0.7341 - val_loss: 0.2069 - val_mae: 0.3887\n",
      "Epoch 69/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.8853 - mae: 0.7410 - val_loss: 0.2060 - val_mae: 0.3881\n",
      "Epoch 70/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.7944 - mae: 0.7061 - val_loss: 0.2021 - val_mae: 0.3840\n",
      "Epoch 71/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.7803 - mae: 0.6703 - val_loss: 0.2000 - val_mae: 0.3818\n",
      "Epoch 72/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.8486 - mae: 0.7250 - val_loss: 0.2001 - val_mae: 0.3822\n",
      "Epoch 73/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.8004 - mae: 0.7234 - val_loss: 0.2025 - val_mae: 0.3853\n",
      "Epoch 74/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.8368 - mae: 0.7118 - val_loss: 0.2001 - val_mae: 0.3829\n",
      "Epoch 75/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 994us/step - loss: 0.8079 - mae: 0.7046 - val_loss: 0.1989 - val_mae: 0.3818\n",
      "Epoch 76/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.7813 - mae: 0.7048 - val_loss: 0.1957 - val_mae: 0.3784\n",
      "Epoch 77/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.8658 - mae: 0.7241 - val_loss: 0.1925 - val_mae: 0.3751\n",
      "Epoch 78/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.8074 - mae: 0.7006 - val_loss: 0.1900 - val_mae: 0.3725\n",
      "Epoch 79/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.7642 - mae: 0.6984 - val_loss: 0.1897 - val_mae: 0.3724\n",
      "Epoch 80/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.8551 - mae: 0.7260 - val_loss: 0.1917 - val_mae: 0.3749\n",
      "Epoch 81/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.8093 - mae: 0.6914 - val_loss: 0.1919 - val_mae: 0.3754\n",
      "Epoch 82/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.8507 - mae: 0.7078 - val_loss: 0.1942 - val_mae: 0.3782\n",
      "Epoch 83/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.8621 - mae: 0.7320 - val_loss: 0.1911 - val_mae: 0.3750\n",
      "Epoch 84/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.8432 - mae: 0.7182 - val_loss: 0.1915 - val_mae: 0.3758\n",
      "Epoch 85/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.8600 - mae: 0.7348 - val_loss: 0.1915 - val_mae: 0.3760\n",
      "Epoch 86/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.7984 - mae: 0.7022 - val_loss: 0.1893 - val_mae: 0.3736\n",
      "Epoch 87/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.7582 - mae: 0.7002 - val_loss: 0.1870 - val_mae: 0.3713\n",
      "Epoch 88/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.8007 - mae: 0.7008 - val_loss: 0.1870 - val_mae: 0.3714\n",
      "Epoch 89/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.7615 - mae: 0.6848 - val_loss: 0.1854 - val_mae: 0.3697\n",
      "Epoch 90/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.7306 - mae: 0.6697 - val_loss: 0.1842 - val_mae: 0.3686\n",
      "Epoch 91/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.7596 - mae: 0.6844 - val_loss: 0.1835 - val_mae: 0.3681\n",
      "Epoch 92/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.8568 - mae: 0.7244 - val_loss: 0.1839 - val_mae: 0.3686\n",
      "Epoch 93/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.7968 - mae: 0.6989 - val_loss: 0.1816 - val_mae: 0.3660\n",
      "Epoch 94/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.8349 - mae: 0.7022 - val_loss: 0.1822 - val_mae: 0.3668\n",
      "Epoch 95/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.7892 - mae: 0.7094 - val_loss: 0.1787 - val_mae: 0.3631\n",
      "Epoch 96/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.7566 - mae: 0.6755 - val_loss: 0.1780 - val_mae: 0.3624\n",
      "Epoch 97/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7954 - mae: 0.6911 - val_loss: 0.1772 - val_mae: 0.3617\n",
      "Epoch 98/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.7889 - mae: 0.6917 - val_loss: 0.1766 - val_mae: 0.3611\n",
      "Epoch 99/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.7882 - mae: 0.7075 - val_loss: 0.1767 - val_mae: 0.3613\n",
      "Epoch 100/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.7628 - mae: 0.6940 - val_loss: 0.1767 - val_mae: 0.3615\n",
      "Epoch 101/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.7905 - mae: 0.6983 - val_loss: 0.1739 - val_mae: 0.3582\n",
      "Epoch 102/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6978 - mae: 0.6514 - val_loss: 0.1717 - val_mae: 0.3557\n",
      "Epoch 103/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.7086 - mae: 0.6616 - val_loss: 0.1714 - val_mae: 0.3555\n",
      "Epoch 104/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.7519 - mae: 0.6681 - val_loss: 0.1711 - val_mae: 0.3551\n",
      "Epoch 105/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.8517 - mae: 0.7344 - val_loss: 0.1692 - val_mae: 0.3530\n",
      "Epoch 106/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.8296 - mae: 0.6953 - val_loss: 0.1671 - val_mae: 0.3505\n",
      "Epoch 107/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.7799 - mae: 0.6821 - val_loss: 0.1674 - val_mae: 0.3510\n",
      "Epoch 108/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7833 - mae: 0.6881 - val_loss: 0.1663 - val_mae: 0.3497\n",
      "Epoch 109/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.7162 - mae: 0.6591 - val_loss: 0.1649 - val_mae: 0.3481\n",
      "Epoch 110/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6929 - mae: 0.6506 - val_loss: 0.1647 - val_mae: 0.3481\n",
      "Epoch 111/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.7859 - mae: 0.6841 - val_loss: 0.1644 - val_mae: 0.3480\n",
      "Epoch 112/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.7953 - mae: 0.6903 - val_loss: 0.1650 - val_mae: 0.3488\n",
      "Epoch 113/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.7580 - mae: 0.6808 - val_loss: 0.1643 - val_mae: 0.3481\n",
      "Epoch 114/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.7093 - mae: 0.6601 - val_loss: 0.1651 - val_mae: 0.3492\n",
      "Epoch 115/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.7360 - mae: 0.6726 - val_loss: 0.1653 - val_mae: 0.3495\n",
      "Epoch 116/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6925 - mae: 0.6576 - val_loss: 0.1634 - val_mae: 0.3473\n",
      "Epoch 117/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.7456 - mae: 0.6590 - val_loss: 0.1633 - val_mae: 0.3472\n",
      "Epoch 118/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.7769 - mae: 0.6790 - val_loss: 0.1609 - val_mae: 0.3445\n",
      "Epoch 119/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7530 - mae: 0.6780 - val_loss: 0.1604 - val_mae: 0.3439\n",
      "Epoch 120/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.7194 - mae: 0.6620 - val_loss: 0.1602 - val_mae: 0.3439\n",
      "Epoch 121/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6799 - mae: 0.6373 - val_loss: 0.1617 - val_mae: 0.3459\n",
      "Epoch 122/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.7268 - mae: 0.6681 - val_loss: 0.1614 - val_mae: 0.3457\n",
      "Epoch 123/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.7622 - mae: 0.6856 - val_loss: 0.1594 - val_mae: 0.3432\n",
      "Epoch 124/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.7279 - mae: 0.6711 - val_loss: 0.1580 - val_mae: 0.3414\n",
      "Epoch 125/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6778 - mae: 0.6441 - val_loss: 0.1573 - val_mae: 0.3407\n",
      "Epoch 126/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.7678 - mae: 0.6961 - val_loss: 0.1565 - val_mae: 0.3398\n",
      "Epoch 127/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.7383 - mae: 0.6687 - val_loss: 0.1564 - val_mae: 0.3400\n",
      "Epoch 128/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6746 - mae: 0.6442 - val_loss: 0.1568 - val_mae: 0.3405\n",
      "Epoch 129/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6912 - mae: 0.6458 - val_loss: 0.1557 - val_mae: 0.3393\n",
      "Epoch 130/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6970 - mae: 0.6440 - val_loss: 0.1569 - val_mae: 0.3410\n",
      "Epoch 131/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.7555 - mae: 0.6681 - val_loss: 0.1578 - val_mae: 0.3422\n",
      "Epoch 132/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.7766 - mae: 0.6704 - val_loss: 0.1581 - val_mae: 0.3428\n",
      "Epoch 133/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6757 - mae: 0.6347 - val_loss: 0.1570 - val_mae: 0.3415\n",
      "Epoch 134/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6759 - mae: 0.6488 - val_loss: 0.1563 - val_mae: 0.3407\n",
      "Epoch 135/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.7155 - mae: 0.6606 - val_loss: 0.1562 - val_mae: 0.3407\n",
      "Epoch 136/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.7083 - mae: 0.6505 - val_loss: 0.1573 - val_mae: 0.3421\n",
      "Epoch 137/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.8044 - mae: 0.6943 - val_loss: 0.1572 - val_mae: 0.3421\n",
      "Epoch 138/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.7145 - mae: 0.6601 - val_loss: 0.1565 - val_mae: 0.3413\n",
      "Epoch 139/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.7777 - mae: 0.6925 - val_loss: 0.1566 - val_mae: 0.3416\n",
      "Epoch 140/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7201 - mae: 0.6708 - val_loss: 0.1563 - val_mae: 0.3414\n",
      "Epoch 141/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.7188 - mae: 0.6580 - val_loss: 0.1583 - val_mae: 0.3441\n",
      "Epoch 142/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6931 - mae: 0.6466 - val_loss: 0.1566 - val_mae: 0.3420\n",
      "Epoch 143/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6938 - mae: 0.6533 - val_loss: 0.1575 - val_mae: 0.3433\n",
      "Epoch 144/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.7475 - mae: 0.6585 - val_loss: 0.1566 - val_mae: 0.3423\n",
      "Epoch 145/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6907 - mae: 0.6493 - val_loss: 0.1565 - val_mae: 0.3421\n",
      "Epoch 146/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.7223 - mae: 0.6593 - val_loss: 0.1569 - val_mae: 0.3427\n",
      "Epoch 147/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6593 - mae: 0.6440 - val_loss: 0.1559 - val_mae: 0.3416\n",
      "Epoch 148/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6754 - mae: 0.6484 - val_loss: 0.1545 - val_mae: 0.3398\n",
      "Epoch 149/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6664 - mae: 0.6349 - val_loss: 0.1552 - val_mae: 0.3409\n",
      "Epoch 150/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6207 - mae: 0.6238 - val_loss: 0.1528 - val_mae: 0.3379\n",
      "Epoch 151/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6069 - mae: 0.6125 - val_loss: 0.1501 - val_mae: 0.3344\n",
      "Epoch 152/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6685 - mae: 0.6389 - val_loss: 0.1492 - val_mae: 0.3334\n",
      "Epoch 153/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.7138 - mae: 0.6659 - val_loss: 0.1485 - val_mae: 0.3325\n",
      "Epoch 154/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.7108 - mae: 0.6660 - val_loss: 0.1471 - val_mae: 0.3308\n",
      "Epoch 155/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6577 - mae: 0.6235 - val_loss: 0.1477 - val_mae: 0.3318\n",
      "Epoch 156/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6539 - mae: 0.6288 - val_loss: 0.1465 - val_mae: 0.3301\n",
      "Epoch 157/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6450 - mae: 0.6283 - val_loss: 0.1463 - val_mae: 0.3299\n",
      "Epoch 158/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 996us/step - loss: 0.6781 - mae: 0.6467 - val_loss: 0.1454 - val_mae: 0.3287\n",
      "Epoch 159/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6514 - mae: 0.6290 - val_loss: 0.1461 - val_mae: 0.3298\n",
      "Epoch 160/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6222 - mae: 0.6071 - val_loss: 0.1457 - val_mae: 0.3294\n",
      "Epoch 161/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6736 - mae: 0.6423 - val_loss: 0.1454 - val_mae: 0.3291\n",
      "Epoch 162/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6647 - mae: 0.6409 - val_loss: 0.1462 - val_mae: 0.3303\n",
      "Epoch 163/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6601 - mae: 0.6247 - val_loss: 0.1461 - val_mae: 0.3303\n",
      "Epoch 164/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6762 - mae: 0.6362 - val_loss: 0.1458 - val_mae: 0.3299\n",
      "Epoch 165/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.7227 - mae: 0.6689 - val_loss: 0.1461 - val_mae: 0.3304\n",
      "Epoch 166/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.7242 - mae: 0.6612 - val_loss: 0.1475 - val_mae: 0.3323\n",
      "Epoch 167/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6841 - mae: 0.6397 - val_loss: 0.1478 - val_mae: 0.3329\n",
      "Epoch 168/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.7441 - mae: 0.6685 - val_loss: 0.1485 - val_mae: 0.3339\n",
      "Epoch 169/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.7668 - mae: 0.6768 - val_loss: 0.1488 - val_mae: 0.3343\n",
      "Epoch 170/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6895 - mae: 0.6444 - val_loss: 0.1489 - val_mae: 0.3346\n",
      "Epoch 171/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6133 - mae: 0.6130 - val_loss: 0.1481 - val_mae: 0.3336\n",
      "Epoch 172/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.7440 - mae: 0.6447 - val_loss: 0.1503 - val_mae: 0.3365\n",
      "Epoch 173/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.7255 - mae: 0.6475 - val_loss: 0.1501 - val_mae: 0.3364\n",
      "Epoch 174/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.7575 - mae: 0.6709 - val_loss: 0.1510 - val_mae: 0.3377\n",
      "Epoch 175/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6489 - mae: 0.6286 - val_loss: 0.1501 - val_mae: 0.3365\n",
      "Epoch 176/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6771 - mae: 0.6315 - val_loss: 0.1486 - val_mae: 0.3348\n",
      "Epoch 177/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6565 - mae: 0.6279 - val_loss: 0.1470 - val_mae: 0.3327\n",
      "Epoch 178/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6282 - mae: 0.6318 - val_loss: 0.1472 - val_mae: 0.3331\n",
      "Epoch 179/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6247 - mae: 0.6168 - val_loss: 0.1494 - val_mae: 0.3361\n",
      "Epoch 180/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6114 - mae: 0.6199 - val_loss: 0.1483 - val_mae: 0.3346\n",
      "Epoch 181/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6269 - mae: 0.6149 - val_loss: 0.1469 - val_mae: 0.3328\n",
      "Epoch 182/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6077 - mae: 0.6040 - val_loss: 0.1473 - val_mae: 0.3334\n",
      "Epoch 183/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6100 - mae: 0.6079 - val_loss: 0.1486 - val_mae: 0.3352\n",
      "Epoch 184/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6622 - mae: 0.6330 - val_loss: 0.1483 - val_mae: 0.3350\n",
      "Epoch 185/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5879 - mae: 0.6004 - val_loss: 0.1481 - val_mae: 0.3348\n",
      "Epoch 186/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6955 - mae: 0.6374 - val_loss: 0.1489 - val_mae: 0.3359\n",
      "Epoch 187/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6004 - mae: 0.5937 - val_loss: 0.1463 - val_mae: 0.3325\n",
      "Epoch 188/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.7166 - mae: 0.6607 - val_loss: 0.1462 - val_mae: 0.3325\n",
      "Epoch 189/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6303 - mae: 0.6246 - val_loss: 0.1454 - val_mae: 0.3316\n",
      "Epoch 190/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5904 - mae: 0.5958 - val_loss: 0.1447 - val_mae: 0.3306\n",
      "Epoch 191/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6615 - mae: 0.6343 - val_loss: 0.1443 - val_mae: 0.3302\n",
      "Epoch 192/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6032 - mae: 0.5973 - val_loss: 0.1447 - val_mae: 0.3308\n",
      "Epoch 193/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6492 - mae: 0.6196 - val_loss: 0.1439 - val_mae: 0.3298\n",
      "Epoch 194/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6211 - mae: 0.6194 - val_loss: 0.1445 - val_mae: 0.3306\n",
      "Epoch 195/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6539 - mae: 0.6441 - val_loss: 0.1436 - val_mae: 0.3295\n",
      "Epoch 196/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5502 - mae: 0.5907 - val_loss: 0.1413 - val_mae: 0.3265\n",
      "Epoch 197/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5934 - mae: 0.5982 - val_loss: 0.1413 - val_mae: 0.3265\n",
      "Epoch 198/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6574 - mae: 0.6317 - val_loss: 0.1406 - val_mae: 0.3256\n",
      "Epoch 199/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6562 - mae: 0.6411 - val_loss: 0.1400 - val_mae: 0.3250\n",
      "Epoch 200/200\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.7232 - mae: 0.6633 - val_loss: 0.1398 - val_mae: 0.3248\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adagrad\n",
    "\n",
    "# Eliminar 5 columnas adicionales que consideramos no necesarias\n",
    "columns_to_remove_3 = ['StudentID', 'GradeClass', 'Ethnicity', 'ParentalSupport', 'Sports', 'Music', 'Volunteering']\n",
    "X_3 = data.drop(columns=columns_to_remove_3)\n",
    "\n",
    "# Dividir los datos\n",
    "X_train_3, X_test_3, y_train_3, y_test_3 = train_test_split(X_3, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Escalar las características\n",
    "scaler = StandardScaler()\n",
    "X_train_3 = scaler.fit_transform(X_train_3)\n",
    "X_test_3 = scaler.transform(X_test_3)\n",
    "\n",
    "# Modelo 3: Añadir capas dropout para evitar sobreajuste\n",
    "model_3 = Sequential()\n",
    "model_3.add(Dense(64, input_dim=X_train_3.shape[1], activation='relu'))\n",
    "model_3.add(Dropout(0.5))  # Dropout para evitar el sobreajuste\n",
    "model_3.add(Dense(32, activation='relu'))\n",
    "model_3.add(Dropout(0.5))  # Dropout adicional\n",
    "model_3.add(Dense(1))\n",
    "\n",
    "# Compilar el modelo con Adagrad\n",
    "model_3.compile(optimizer=Adagrad(), loss='mean_squared_error', metrics=['mae'])\n",
    "\n",
    "# Entrenar el modelo con diferente tamaño de lote\n",
    "history_3 = model_3.fit(X_train_3, y_train_3, epochs=200, batch_size=20, validation_split=0.2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 641us/step - loss: 0.0597 - mae: 0.1940\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 755us/step - loss: 8.3416e-04 - mae: 0.0216\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 717us/step - loss: 0.1366 - mae: 0.3224\n",
      "Modelo 1 - Test MAE: 0.19408905506134033\n",
      "Modelo 2 - Test MAE: 0.021194756031036377\n",
      "Modelo 3 - Test MAE: 0.3252888321876526\n"
     ]
    }
   ],
   "source": [
    "# Evaluar los tres modelos\n",
    "test_loss_1, test_mae_1 = model.evaluate(X_test, y_test)\n",
    "test_loss_2, test_mae_2 = model_2.evaluate(X_test_2, y_test_2)\n",
    "test_loss_3, test_mae_3 = model_3.evaluate(X_test_3, y_test_3)\n",
    "\n",
    "# Imprimir los resultados\n",
    "print(f\"Modelo 1 - Test MAE: {test_mae_1}\")\n",
    "print(f\"Modelo 2 - Test MAE: {test_mae_2}\")\n",
    "print(f\"Modelo 3 - Test MAE: {test_mae_3}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusión de los resultados obtenidos:\n",
    "\n",
    "A partir de los resultados obtenidos para los tres modelos, podemos observar lo siguiente:\n",
    "\n",
    "### Modelo 1:\n",
    "- Test MAE: 0.1940\n",
    "- Este es el modelo original y tiene un error absoluto medio de 0.194, lo cual es un rendimiento sólido.\n",
    "\n",
    "### Modelo 2:\n",
    " - Test MAE: 0.0211\n",
    "- El modelo 2, con la capa adicional y el optimizador RMSprop, muestra un MAE significativamente menor.\n",
    "- Esto indica que el modelo mejoró sustancialmente al agregar una capa oculta extra y ajustar el optimizador,\n",
    "  logrando una precisión mucho mayor que el modelo original.\n",
    "\n",
    "### Modelo 3:\n",
    "- Test MAE: 0.3253\n",
    "- El modelo 3, con más columnas eliminadas y dropout para evitar el sobreajuste, tiene un MAE más alto que los\n",
    "  otros dos modelos.\n",
    "- Esto indica que eliminar demasiadas columnas clave y agregar dropout afectó negativamente el rendimiento\n",
    " del modelo."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
